{"id":"mol-refinery-patrol","title":"mol-refinery-patrol","description":"Merge queue processor patrol loop.\n\nThe Refinery is the Engineer in the engine room. You process polecat branches, merging them to main one at a time with sequential rebasing.\n\n**The Scotty Test**: Before proceeding past any failure, ask yourself: \"Would Scotty walk past a warp core leak because it existed before his shift?\"\n\n## Pre-Merge Gates (v5+)\n\nBefore accepting any MR for merge, the Refinery enforces:\n1. **Test Coverage Gate**: Changesets must include test file changes (implements hq-kbs)\n2. **Test Execution Gate**: All tests must pass before merge\n\n## Merge Flow\n\nThe Refinery receives MERGE_READY mail from Witnesses when polecats complete work:\n\n```\nWitness                    Refinery                      Git\n   │                          │                           │\n   │ MERGE_READY              │                           │\n   │─────────────────────────\u003e│                           │\n   │                          │                           │\n   │                    (verify branch)                   │\n   │                          │ fetch \u0026 rebase            │\n   │                          │──────────────────────────\u003e│\n   │                          │                           │\n   │                    (run tests)                       │\n   │                          │                           │\n   │                    (if pass)                         │\n   │                          │ merge \u0026 push              │\n   │                          │──────────────────────────\u003e│\n   │                          │                           │\n   │ MERGED                   │                           │\n   │\u003c─────────────────────────│                           │\n   │                          │                           │\n```\n\nAfter successful merge, Refinery sends MERGED mail back to Witness so it can\ncomplete cleanup (nuke the polecat worktree).","status":"open","priority":2,"issue_type":"epic","created_at":"2026-01-08T00:01:53Z","updated_at":"2026-01-08T00:01:53Z","labels":["template"],"is_template":true,"work_type":"mutex"}
{"id":"mol-refinery-patrol.burn-or-loop","title":"Burn and respawn or loop","description":"End of patrol cycle decision.\n\n**Step 1: Estimate remaining context**\n\nAsk yourself:\n- Have I processed many branches this cycle?\n- Is the conversation getting long?\n- Am I starting to lose track of earlier context?\n\nRule of thumb: If you've done 3+ merges or processed significant cleanup work,\nit's time for a fresh session.\n\n**Step 2: Decision tree**\n\nIf queue non-empty AND context LOW:\n- Squash this wisp to digest\n- Spawn fresh patrol wisp\n- Return to inbox-check\n\nIf queue empty OR context HIGH OR good stopping point:\n- Squash wisp with summary digest\n- Use `gt handoff` for clean session transition:\n\n```bash\ngt handoff -s \"Patrol complete\" -m \"Merged X branches, Y tests passed.\nQueue: empty/N remaining\nNext: [any notes for successor]\"\n```\n\n**Why gt handoff?**\n- Sends handoff mail to yourself with context\n- Respawns with fresh Claude instance\n- SessionStart hook runs gt prime\n- Successor picks up from your hook\n\n**DO NOT just exit.** Always use `gt handoff` for proper lifecycle.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-08T00:01:53Z","updated_at":"2026-01-08T00:01:53Z","dependencies":[{"issue_id":"mol-refinery-patrol.burn-or-loop","depends_on_id":"mol-refinery-patrol","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"mol-refinery-patrol.burn-or-loop","depends_on_id":"mol-refinery-patrol.patrol-cleanup","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"is_template":true,"work_type":"mutex"}
{"id":"mol-refinery-patrol.context-check","title":"Check own context limit","description":"Check own context usage.\n\nIf context is HIGH (\u003e80%):\n- Write handoff summary\n- Prepare for burn/respawn\n\nIf context is LOW:\n- Can continue processing","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-08T00:01:53Z","updated_at":"2026-01-08T00:01:53Z","dependencies":[{"issue_id":"mol-refinery-patrol.context-check","depends_on_id":"mol-refinery-patrol","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"mol-refinery-patrol.context-check","depends_on_id":"mol-refinery-patrol.generate-summary","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"is_template":true,"work_type":"mutex"}
{"id":"mol-refinery-patrol.generate-summary","title":"Generate handoff summary","description":"Summarize this patrol cycle.\n\n**VERIFICATION**: Before generating summary, confirm for each merged branch:\n- [ ] MERGED mail was sent to witness\n- [ ] MR bead was closed\n- [ ] MERGE_READY mail archived\n\nIf any notifications or archiving were missed, do them now!\n\nInclude in summary:\n- Branches merged (count, names)\n- MERGED mails sent (count - should match branches merged)\n- MR beads closed (count - should match branches merged)\n- MERGE_READY mails archived (count - should match branches merged)\n- Test results (pass/fail)\n- Branches with conflicts (count, names)\n- Conflict-resolution tasks created (IDs)\n- Issues filed (if any)\n- Any escalations sent\n\n**Conflict tracking is important** for monitoring MQ health. If many branches\nconflict, it may indicate main is moving too fast or branches are too stale.\n\nThis becomes the digest when the patrol is squashed.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-08T00:01:53Z","updated_at":"2026-01-08T00:01:53Z","dependencies":[{"issue_id":"mol-refinery-patrol.generate-summary","depends_on_id":"mol-refinery-patrol","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"mol-refinery-patrol.generate-summary","depends_on_id":"mol-refinery-patrol.loop-check","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"is_template":true,"work_type":"mutex"}
{"id":"mol-refinery-patrol.handle-failures","title":"Handle test failures","description":"**VERIFICATION GATE**: This step enforces the Beads Promise.\n\nIf tests PASSED: This step auto-completes. Proceed to merge.\n\nIf tests FAILED:\n1. Diagnose: Is this a branch regression or pre-existing on main?\n2. If branch caused it:\n   - Abort merge\n   - Notify polecat: \"Tests failing. Please fix and resubmit.\"\n   - Skip to loop-check\n3. If pre-existing on main:\n   - Option A: Fix it yourself (you're the Engineer!)\n   - Option B: File a bead: bd create --type=bug --priority=1 --title=\"...\"\n\n**GATE REQUIREMENT**: You CANNOT proceed to merge-push without:\n- Tests passing, OR\n- Fix committed, OR\n- Bead filed for the failure\n\nThis is non-negotiable. Never disavow. Never \"note and proceed.\" ","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-08T00:01:53Z","updated_at":"2026-01-08T00:01:53Z","dependencies":[{"issue_id":"mol-refinery-patrol.handle-failures","depends_on_id":"mol-refinery-patrol","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"mol-refinery-patrol.handle-failures","depends_on_id":"mol-refinery-patrol.run-tests","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"is_template":true,"work_type":"mutex"}
{"id":"mol-refinery-patrol.inbox-check","title":"Check refinery mail","description":"Check mail for MERGE_READY submissions, escalations, and messages.\n\n```bash\ngt mail inbox\n```\n\nFor each message:\n\n**MERGE_READY**:\nA polecat's work is ready for merge. Extract details and track for processing.\n\n```bash\n# Parse MERGE_READY message body:\n# Branch: \u003cbranch\u003e\n# Issue: \u003cissue-id\u003e\n# Polecat: \u003cpolecat-name\u003e\n# MR: \u003cmr-bead-id\u003e\n# Verified: clean git state, issue closed\n\n# Track in your merge queue for this patrol cycle:\n# - Branch name\n# - Issue ID\n# - Polecat name (REQUIRED for MERGED notification)\n# - MR bead ID (REQUIRED for closing after merge)\n```\n\n**IMPORTANT**: You MUST track the polecat name, MR bead ID, AND message ID - you will need them\nin merge-push step to send MERGED notification, close the MR bead, and archive the mail.\n\nMark as read. The work will be processed in queue-scan/process-branch.\n**Do NOT archive yet** - archive after merge/reject decision in merge-push step.\n\n**PATROL: Wake up**:\nWitness detected MRs waiting but refinery idle. Acknowledge and archive:\n```bash\ngt mail archive \u003cmessage-id\u003e\n```\n\n**HELP / Blocked**:\nAssess and respond. If you can't help, escalate to Mayor.\nArchive after handling:\n```bash\ngt mail archive \u003cmessage-id\u003e\n```\n\n**HANDOFF**:\nRead predecessor context. Check for in-flight merges.\nArchive after absorbing context:\n```bash\ngt mail archive \u003cmessage-id\u003e\n```\n\n**Hygiene principle**: Archive messages after they're fully processed.\nKeep only: pending MRs in queue. Inbox should be near-empty.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-08T00:01:53Z","updated_at":"2026-01-08T00:01:53Z","dependencies":[{"issue_id":"mol-refinery-patrol.inbox-check","depends_on_id":"mol-refinery-patrol","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"is_template":true,"work_type":"mutex"}
{"id":"mol-refinery-patrol.loop-check","title":"Check for more work","description":"More branches to process?\n\n**Entry paths:**\n- Normal: After successful merge-push\n- Conflict-skip: After process-branch created conflict-resolution task\n\nIf yes: Return to process-branch with next branch.\nIf no: Continue to generate-summary.\n\n**Track for this cycle:**\n- branches_merged: count and names of successfully merged branches\n- branches_conflict: count and names of branches skipped due to conflicts\n- conflict_tasks: IDs of conflict-resolution tasks created\n\nThis tracking feeds into generate-summary for the patrol digest.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-08T00:01:53Z","updated_at":"2026-01-08T00:01:53Z","dependencies":[{"issue_id":"mol-refinery-patrol.loop-check","depends_on_id":"mol-refinery-patrol","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"mol-refinery-patrol.loop-check","depends_on_id":"mol-refinery-patrol.merge-push","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"is_template":true,"work_type":"mutex"}
{"id":"mol-refinery-patrol.merge-push","title":"Merge and push to main","description":"Merge to main and push. CRITICAL: Notifications come IMMEDIATELY after push.\n\n**Step 1: Merge and Push**\n```bash\ngit checkout main\ngit merge --ff-only temp\ngit push origin main\n```\n\n⚠️ **STOP HERE - DO NOT PROCEED UNTIL STEPS 2-3 COMPLETE**\n\n**Step 2: Send MERGED Notification (REQUIRED - DO THIS IMMEDIATELY)**\n\nRIGHT NOW, before any cleanup, send MERGED mail to Witness:\n\n```bash\ngt mail send \u003crig\u003e/witness -s \"MERGED \u003cpolecat-name\u003e\" -m \"Branch: \u003cbranch\u003e\nIssue: \u003cissue-id\u003e\nMerged-At: $(date -u +%Y-%m-%dT%H:%M:%SZ)\"\n```\n\nThis signals the Witness to nuke the polecat worktree. WITHOUT THIS NOTIFICATION,\nPOLECAT WORKTREES ACCUMULATE INDEFINITELY AND THE LIFECYCLE BREAKS.\n\n**Step 3: Close MR Bead (REQUIRED - DO THIS IMMEDIATELY)**\n\n⚠️ **VERIFICATION BEFORE CLOSING**: Confirm the work is actually on main:\n```bash\n# Get the commit message/issue from the branch\ngit log origin/main --oneline | grep \"\u003cissue-id\u003e\"\n# OR verify the commit SHA is on main:\ngit branch --contains \u003ccommit-sha\u003e | grep main\n```\n\nIf work is NOT on main, DO NOT close the MR bead. Investigate first.\n\n```bash\nbd close \u003cmr-bead-id\u003e --reason \"Merged to main at $(git rev-parse --short HEAD)\"\n```\n\nThe MR bead ID was in the MERGE_READY message or find via:\n```bash\nbd list --type=merge-request --status=open | grep \u003cpolecat-name\u003e\n```\n\n**VALIDATION**: The MR bead's source_issue should be a valid bead ID (gt-xxxxx),\nnot a branch name. If source_issue contains a branch name, flag for investigation.\n\n**Step 4: Archive the MERGE_READY mail (REQUIRED)**\n```bash\ngt mail archive \u003cmerge-ready-message-id\u003e\n```\nThe message ID was tracked when you processed inbox-check.\n\n**Step 5: Cleanup (only after Steps 2-4 confirmed)**\n```bash\ngit branch -d temp\ngit push origin --delete \u003cpolecat-branch\u003e\n```\n\n**VERIFICATION GATE**: You CANNOT proceed to loop-check without:\n- [x] MERGED mail sent to witness\n- [x] MR bead closed\n- [x] MERGE_READY mail archived\n\nIf you skipped notifications or archiving, GO BACK AND DO THEM NOW.\n\nMain has moved. Any remaining branches need rebasing on new baseline.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-08T00:01:53Z","updated_at":"2026-01-08T00:01:53Z","dependencies":[{"issue_id":"mol-refinery-patrol.merge-push","depends_on_id":"mol-refinery-patrol","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"mol-refinery-patrol.merge-push","depends_on_id":"mol-refinery-patrol.handle-failures","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"is_template":true,"work_type":"mutex"}
{"id":"mol-refinery-patrol.patrol-cleanup","title":"End-of-cycle inbox hygiene","description":"Verify inbox hygiene before ending patrol cycle.\n\n**Step 1: Check inbox state**\n```bash\ngt mail inbox\n```\n\nInbox should contain ONLY:\n- Unprocessed MERGE_READY messages (will process next cycle)\n- Active work items\n\n**Step 2: Archive any stale messages**\n\nLook for messages that were processed but not archived:\n- PATROL: Wake up that was acknowledged → archive\n- HELP/Blocked that was handled → archive\n- MERGE_READY where merge completed but archive was missed → archive\n\n```bash\n# For each stale message found:\ngt mail archive \u003cmessage-id\u003e\n```\n\n**Step 3: Check for orphaned MR beads**\n\nLook for open MR beads with no corresponding branch:\n```bash\nbd list --type=merge-request --status=open\n```\n\nFor each open MR bead:\n1. Check if branch exists: `git ls-remote origin refs/heads/\u003cbranch\u003e`\n2. If branch gone, verify work is on main: `git log origin/main --oneline | grep \"\u003csource_issue\u003e\"`\n3. If work on main → close MR with reason \"Merged (verified on main)\"\n4. If work NOT on main → investigate before closing:\n   - Check source_issue validity (should be gt-xxxxx, not branch name)\n   - Search reflog/dangling commits if possible\n   - If unverifiable, close with reason \"Unverifiable - no audit trail\"\n   - File bead if this indicates lost work\n\n**NEVER close an MR bead without verifying the work landed or is unrecoverable.**\n\n**Goal**: Inbox should have ≤3 active messages at end of cycle.\nKeep only: pending MRs in queue.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-08T00:01:53Z","updated_at":"2026-01-08T00:01:53Z","dependencies":[{"issue_id":"mol-refinery-patrol.patrol-cleanup","depends_on_id":"mol-refinery-patrol","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"mol-refinery-patrol.patrol-cleanup","depends_on_id":"mol-refinery-patrol.context-check","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"is_template":true,"work_type":"mutex"}
{"id":"mol-refinery-patrol.process-branch","title":"Mechanical rebase","description":"Pick next branch from queue. Attempt mechanical rebase on current main.\n\n**Step 1: Checkout and attempt rebase**\n```bash\ngit checkout -b temp origin/\u003cpolecat-branch\u003e\ngit rebase origin/main\n```\n\n**Step 2: Check rebase result**\n\nThe rebase exits with:\n- Exit code 0: Success - proceed to run-tests\n- Exit code 1 (conflicts): Conflict detected - proceed to Step 3\n\nTo detect conflict state after rebase fails:\n```bash\n# Check if we're in a conflicted rebase state\nls .git/rebase-merge 2\u003e/dev/null \u0026\u0026 echo \"CONFLICT_STATE\"\n```\n\n**Step 3: Handle conflicts (if any)**\n\nIf rebase SUCCEEDED (exit code 0):\n- Skip to run-tests step (continue normal merge flow)\n\nIf rebase FAILED with conflicts:\n\n1. **Abort the rebase** (DO NOT leave repo in conflicted state):\n```bash\ngit rebase --abort\n```\n\n2. **Record conflict metadata**:\n```bash\n# Capture main SHA for reference\nMAIN_SHA=$(git rev-parse origin/main)\nBRANCH_SHA=$(git rev-parse origin/\u003cpolecat-branch\u003e)\n```\n\n3. **Create conflict-resolution task**:\n```bash\nbd create --type=task --priority=1 --title=\"Resolve merge conflicts: \u003coriginal-issue-title\u003e\" --description=\"## Conflict Resolution Required\n\nOriginal MR: \u003cmr-bead-id\u003e\nBranch: \u003cpolecat-branch\u003e\nOriginal Issue: \u003cissue-id\u003e\nConflict with main at: ${MAIN_SHA}\nBranch SHA: ${BRANCH_SHA}\n\n## Instructions\n1. Clone/checkout the branch\n2. Rebase on current main: git rebase origin/main\n3. Resolve conflicts\n4. Force push: git push -f origin \u003cbranch\u003e\n5. Close this task when done\n\nThe MR will be re-queued for processing after conflicts are resolved.\"\n```\n\n4. **Skip this MR** (do NOT delete branch or close MR bead):\n- Leave branch intact for conflict resolution\n- Leave MR bead open (will be re-processed after resolution)\n- Continue to loop-check for next branch\n\n**CRITICAL**: Never delete a branch that has conflicts. The branch contains\nthe original work and must be preserved for conflict resolution.\n\nTrack: rebase result (success/conflict), conflict task ID if created.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-08T00:01:53Z","updated_at":"2026-01-08T00:01:53Z","dependencies":[{"issue_id":"mol-refinery-patrol.process-branch","depends_on_id":"mol-refinery-patrol","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"mol-refinery-patrol.process-branch","depends_on_id":"mol-refinery-patrol.verify-coverage","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"is_template":true,"work_type":"mutex"}
{"id":"mol-refinery-patrol.queue-scan","title":"Scan merge queue","description":"Check the beads merge queue - this is the SOURCE OF TRUTH for pending merges.\n\n```bash\ngit fetch --prune origin\ngt mq list \u003crig\u003e\n```\n\nThe beads MQ tracks all pending merge requests. Do NOT rely on `git branch -r | grep polecat`\nas branches may exist without MR beads, or MR beads may exist for already-merged work.\n\nIf queue empty, skip to context-check step.\n\nFor each MR in the queue, verify the branch still exists:\n```bash\ngit branch -r | grep \u003cbranch\u003e\n```\n\nIf branch doesn't exist for a queued MR:\n- Close the MR bead: `bd close \u003cmr-id\u003e --reason \"Branch no longer exists\"`\n- Remove from processing queue\n\nTrack verified MR list for this cycle.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-08T00:01:53Z","updated_at":"2026-01-08T00:01:53Z","dependencies":[{"issue_id":"mol-refinery-patrol.queue-scan","depends_on_id":"mol-refinery-patrol","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"mol-refinery-patrol.queue-scan","depends_on_id":"mol-refinery-patrol.inbox-check","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"is_template":true,"work_type":"mutex"}
{"id":"mol-refinery-patrol.run-tests","title":"Run test suite","description":"Run the test suite.\n\n```bash\ngo test ./...\n```\n\nTrack results: pass count, fail count, specific failures.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-08T00:01:53Z","updated_at":"2026-01-08T00:01:53Z","dependencies":[{"issue_id":"mol-refinery-patrol.run-tests","depends_on_id":"mol-refinery-patrol","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"mol-refinery-patrol.run-tests","depends_on_id":"mol-refinery-patrol.process-branch","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"is_template":true,"work_type":"mutex"}
{"id":"mol-refinery-patrol.verify-coverage","title":"Verify test coverage exists","description":"**PRE-MERGE GATE**: Verify that the MR includes test file changes.\n\nThis enforces the town-wide dev workflow requirement (hq-kbs) that all\nwork must include test coverage.\n\nFor each MR to be processed:\n\n**Step 1: Get the diff between branch and main**\n```bash\ngit diff --name-only origin/main...origin/\u003cpolecat-branch\u003e\n```\n\n**Step 2: Check for test files**\n\nTest files are identified by:\n- Go: `*_test.go`\n- JS/TS: `*.test.js`, `*.test.ts`, `*.spec.js`, `*.spec.ts`, `*.test.jsx`, `*.test.tsx`\n- Python: `test_*.py`, `*_test.py`\n- Ruby: `*_spec.rb`\n- Java: `*Test.java`, `*Tests.java`\n- Or files in: `/test/`, `/tests/`, `/__tests__/`, `/spec/` directories\n\n**Step 3: Gate enforcement**\n\nIf NO test files found in changeset:\n1. **Reject the MR** - Do NOT proceed to rebase/merge\n2. **Notify the polecat via mail**:\n```bash\ngt mail send \u003crig\u003e/polecats/\u003cpolecat-name\u003e -s \"MR rejected: No test coverage\" -m \"Branch: \u003cbranch\u003e\nIssue: \u003cissue-id\u003e\nMR: \u003cmr-id\u003e\n\nYour MR was rejected because no test file changes were detected.\n\nThe town-wide dev workflow (hq-kbs) requires all work to include test coverage.\n\nPlease add tests for your changes and resubmit:\n- Add test files to your branch\n- Push the changes: git push\n- The MR will be automatically re-queued\n\nTest file patterns recognized:\n- Go: *_test.go\n- JS/TS: *.test.js, *.test.ts, *.spec.js, *.spec.ts\n- Python: test_*.py, *_test.py\n- Ruby: *_spec.rb\n- Java: *Test.java, *Tests.java\n- Or files in: test/, tests/, __tests__/, spec/ directories\"\n```\n3. **Close the MR bead** with reason \"Rejected: no test coverage\"\n4. **Skip to loop-check** for next branch (do not process this branch)\n\nIf test files found:\n- Log which test file(s) were detected\n- Proceed to process-branch\n\n**GATE REQUIREMENT**: You CANNOT proceed to process-branch without:\n- Test file(s) detected in the changeset, OR\n- Explicit override from Mayor (would require mail with override directive)\n\nThis is non-negotiable. The Beads Promise includes test coverage.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-08T00:01:53Z","updated_at":"2026-01-08T00:01:53Z","dependencies":[{"issue_id":"mol-refinery-patrol.verify-coverage","depends_on_id":"mol-refinery-patrol","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"mol-refinery-patrol.verify-coverage","depends_on_id":"mol-refinery-patrol.queue-scan","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"is_template":true,"work_type":"mutex"}
{"id":"xc-02sz","title":"Evaluate Bifrost as LiteLLM proxy alternative for Xenota","description":"Maxim AI's Bifrost is a Go-based LLM gateway. At 500 RPS on t3.medium, LiteLLM P99 is 90.72s vs Bifrost 1.68s. Features: cluster mode with failover, adaptive load balancing, MCP gateway, governance layer, Prometheus/OpenTelemetry. Migration from LiteLLM is one config change. GitHub: https://git.new/bifrost\n\n(Refiled from jv-vdbyt)","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-11T17:50:00Z","created_by":"jv/crew/kasparov","updated_at":"2026-02-11T17:50:00Z","work_type":"mutex"}
{"id":"xc-0a5","title":"Plan: Port xenon-cli to Go","description":"Design and spec. Attach mol-plan when slinging.","notes":"Dev step xe-hmf is already merged (close reason: 'Merged to main as 384876d'). Closing plan as satisfied/retro.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-07T01:28:19Z","updated_at":"2026-01-07T02:20:30Z","closed_at":"2026-01-07T02:20:30Z","work_type":"mutex"}
{"id":"xc-0bq","title":"Consolidate evaluator file reference functions","description":"**Issue**: `repertoire-studio/src/repertoire_studio/evaluator.py` has both `expand_file_reference()` and `resolve_cell_value()`; only the latter is used for loading CSVs.\n\n**File**: repertoire-studio/src/repertoire_studio/evaluator.py\n\n**Acceptance**:\n- Consolidate to single implementation\n- Document whether `../` is intentionally allowed (tests assert it is)\n- Remove dead code","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-02T20:55:34Z","updated_at":"2026-01-05T21:12:29Z","work_type":"mutex"}
{"id":"xc-0ca","title":"Rename soul-server to nucleus","description":"Rename soul-server directory and package to nucleus. Update all references in Containerfile, pyproject.toml, CLAUDE.md, imports, and xenon-cli.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-22T07:51:13Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-22T07:54:44Z","work_type":"mutex"}
{"id":"xc-0gf","title":"Build design skill with nano-banana pro integration","description":"Build a comprehensive design skill that can generate visual designs and concepts.\n\n## Core Capabilities\n- **Nano-banana pro integration**: Call through Gemini API (preferred) or drive UI via Playwright as fallback\n- **Web inspiration search**: Search the web for visual references and inspiration\n\n## Specialist Skills/Agents\n- Conceptual design agent\n- Brand design agent  \n- Website/UI design agent\n- Visual identity agent\n\n## Architecture\n- **Generate/critique balance**: Similar to writer/editor agent pattern - generate designs then critique/refine\n- **Orchestration skill**: Coordinate between specialist agents, manage design iterations\n\n## Open Questions\n- Best approach for Gemini API vs Playwright fallback\n- How to structure the specialist agent hierarchy\n- Critique criteria and iteration workflow","status":"closed","priority":2,"issue_type":"feature","assignee":"claude","created_at":"2025-12-14T17:15:17Z","updated_at":"2025-12-14T18:10:37Z","closed_at":"2025-12-14T18:10:37Z","work_type":"mutex"}
{"id":"xc-0p8","title":"Complete QA","description":"Final checklist before closing.\n\n## HARD GATE - Run this verification:\n\n```bash\n# Check all siblings are closed\nbd show \u003cmol-qa-epic\u003e | grep \"Children\"\n# Every child MUST show [closed] - if ANY shows [open], STOP\n```\n\n**Verify ALL of these:**\n- [ ] Test results reviewed\n- [ ] All acceptance criteria checked\n- [ ] No blocking bugs (or bugs created and slung to dev)\n- [ ] Draft status removed\n- [ ] Human review requested\n- [ ] All step beads closed with notes\n\n**Record summary in parent bead:**\n```bash\nbd update \u003cparent-bead\u003e --notes \"## QA Complete\n- Acceptance criteria: \u003ccount\u003e verified\n- Bugs found: \u003ccount or none\u003e\n- PR: \u003curl\u003e\n- Reviewer: \u003cusername\u003e\n- Status: Ready for human merge\"\n```\n\n**Only when gate passes:**\n```bash\nbd close \u003cthis-step\u003e\nbd close \u003chead-bead\u003e\n```\n\nHuman code owner reviews and merges.\n\n---\n\n**WORKFLOW COMPLETE**: After closing \u003chead-bead\u003e, update your hook to the next phase or check `bd ready`.\n","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-07T02:20:38Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","dependencies":[{"issue_id":"xc-0p8","depends_on_id":"xc-agi","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-0p8","depends_on_id":"xc-gly","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-0u5","title":"Add economic modeling and compliance appendix","description":"Economics docs outline token/staking/marketplace flows but lack quantitative modeling and compliance notes. Add supply schedule, volume/price sensitivity, staking math, and jurisdictional/disclosure guidance to docs/economics/native-currency.md, docs/economics/staking-model.md, and docs/economics/job-board-marketplace.md.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-11T20:05:46Z","updated_at":"2025-12-11T20:05:46Z","work_type":"mutex"}
{"id":"xc-0w7","title":"Run internal review","description":"Run an internal review against the branch diff (no PR required).\n\n**Commands:**\n```bash\ncodex --full-auto -s danger-full-access review --base main\n```\n\nIf the repo uses a different default branch, change `--base` accordingly.\n\n**Before closing this step, add notes:**\n```bash\nbd update \u003cthis-bead\u003e --notes \"## Internal Review\n- Critical: \u003clist or none\u003e\n- Important: \u003clist or none\u003e\n- Suggestions: \u003clist or none\u003e\"\n```\n","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-07T04:06:33Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","dependencies":[{"issue_id":"xc-0w7","depends_on_id":"xc-1bv","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-0w7","depends_on_id":"xc-ysy","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-0z1","title":"Validate test plan","description":"\n\n\n\n---\n\nReview the test strategy from the plan bead.\n\n**Commands:**\n```bash\nbd show \u003cplan-bead\u003e\n# Look for Test Strategy section\n```\n\n**Understand:**\n- What integration tests should run?\n- What manual exploratory tests?\n- What acceptance criteria need verification?\n\n**Before closing this step, add notes:**\n```bash\nbd update \u003cthis-bead\u003e --notes \"## Test Plan Review\n- Integration tests: \u003clist or 'none defined'\u003e\n- Manual tests: \u003clist of scenarios\u003e\n- Acceptance criteria: \u003ccount\u003e items to verify\n- Gaps found: \u003cany missing coverage\u003e\"\n```\n","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-07T02:20:36Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","dependencies":[{"issue_id":"xc-0z1","depends_on_id":"xc-3i2","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-10g","title":"OODA Repertoire v1","description":"Initial repertoire containing the four routines required by the nucleus cognitive loop: observe, orient, decide, and summarize_tick. The cognitive firmware that makes a xenon think.","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-28T07:32:10Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-28T21:45:32Z","work_type":"mutex"}
{"id":"xc-13a","title":"Project scaffolding","description":"Python project setup (uv), repo structure, basic CI, CLAUDE.md, .gitignore","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-20T11:21:26Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-20T11:56:57Z","dependencies":[{"issue_id":"xc-13a","depends_on_id":"xc-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-13l","title":"Reorganize docs around entities (collective, poleis, xenon)","description":"Restructure documentation from type-based organization (foundation, economics, technical, protocols) to entity-based organization:\n\n- **collective/** - Xenota Collective as civilization (manifesto, white-paper, missions, governance)\n- **poleis/** - Polis-level content (overview, charters, economics, hub infrastructure)\n- **xenon/** - Individual xenon content (overview, cognition/, architecture/, aspirations)\n- **protocols/** - Cross-cutting specs (may move to separate repo later)\n- **guides/** - How-to content\n\nThis better matches the mental model: organize by *who/what* rather than *type of content*. Technical details distribute naturally to their relevant entity level.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-14T20:44:25Z","updated_at":"2025-12-14T20:44:25Z","labels":["documentation","foundation"],"work_type":"mutex"}
{"id":"xc-154","title":"Explore dream mechanics and sharing","description":"Follow-up from xenota-e6w refinement design. Open questions to explore:\n\n1. **Dream aesthetic consistency** - Should each xenon have a consistent dream style based on genome? Or random variation?\n\n2. **Dream image generation** - Always generate? Based on significance? User/chaperone preference?\n\n3. **Refinement timing** - Does it matter when in the 24-tick cycle refinement happens? Configurable per xenon?\n\n4. **Dream sharing** - Can xenons share dreams? Would other xenons or humans find them interesting? Social/cultural value?\n\n5. **Dream interpretation** - Should xenons be able to interpret their own dreams? Or are they just artifacts?\n\nThese are polish/expansion questions, not core design blockers.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-22T07:55:11Z","updated_at":"2025-12-22T07:55:11Z","labels":["concepts","exploration"],"work_type":"mutex"}
{"id":"xc-184l","title":"Witness Patrol","description":"Per-rig worker monitor patrol loop with progressive nudging.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-07T23:00:22Z","updated_at":"2026-02-15T09:50:35Z","closed_at":"2026-02-15T09:50:35Z","work_type":"mutex"}
{"id":"xc-19t","title":"Write nucleus integration test","description":"Full dispatch → strand → instruction flow with mocked repertoire","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-28T07:12:24Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-28T07:47:56Z","dependencies":[{"issue_id":"xc-19t","depends_on_id":"xc-3z8","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-19t","depends_on_id":"xc-4xr","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-1bv","title":"Prepare review context","description":"Confirm you are on the intended branch and understand scope.\n\n**Commands (pick what fits repo):**\n```bash\ngit status -sb\ngit log --oneline --decorate -n 20\ngit diff --stat upstream/main...HEAD || git diff --stat origin/main...HEAD || git diff --stat main...HEAD\n```\n\n**Before closing this step, add notes:**\n```bash\nbd update \u003cthis-bead\u003e --notes \"## Context\n- Branch: \u003cname\u003e\n- Base: \u003cupstream/main|origin/main|main\u003e\n- Scope: \u003cshort summary\u003e\n- Diffstat: \u003cfrom git diff --stat\u003e\"\n```\n","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-07T04:06:33Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","dependencies":[{"issue_id":"xc-1bv","depends_on_id":"xc-ysy","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-1ew1","title":"add xn alias for xenon-cli","description":"attached_molecule: xc-wisp-vwz\nattached_at: 2026-02-07T11:06:31Z\ndispatched_by: xenota/crew/starshot\n\nMake xenon-cli accessible via 'xn' shorthand, consistent with xr (repertoire) and xrs (repertoire-studio).","design":"## Approach\nAdd xn as a symlink to xenon in the Makefile install target. This matches how xr/xrs work (short aliases for longer names).\n\n## Files\n- xenon/xenon-cli/Makefile - add symlink creation in install target\n\n## Test Strategy\n- Manual: run make install, verify xn --help works\n- Unit: no code changes needed, just build/install","notes":"## Submitted to MQ\n- MR: xc-gdqg\n- Status: queued\n- Branch: polecat/obsidian/xc-1ew1@mlc82adc\n- Xenon commit: 47856ef (pushed to origin/main)\n- Changes: xenon-cli/Makefile only (ln -sf for xn alias + test-install target)","status":"closed","priority":2,"issue_type":"feature","assignee":"xenota/polecats/obsidian","created_at":"2026-02-07T11:05:33Z","updated_at":"2026-02-07T17:52:47Z","closed_at":"2026-02-07T17:52:47Z","labels":["xenon-cli"],"work_type":"mutex"}
{"id":"xc-1m2","title":"Update TBD purposes in archived specs","description":"10 archived specs in openspec/specs/ have placeholder \"TBD\" purposes that need updating: repertoire-studio, repertoire, chat-projection, dev-vps, projection-cli, security, projection-base, secrets, blueprints, vps-control","status":"open","priority":4,"issue_type":"chore","created_at":"2026-01-01T19:25:58Z","updated_at":"2026-01-05T21:12:29Z","labels":["docs"],"work_type":"mutex"}
{"id":"xc-1qu","title":"Document human membership criteria (guest vs XC citizen)","description":"Document the membership model for humans:\\n\\n- Guest: anyone can become a guest; signup requires no wallet (OAuth or email/mobile verification).\\n- Polis-defined policies: each polis sets its own guest policies (access/limits/etc.).\\n- Guests can do work on job boards but pay double the job-board tax rate.\\n- XC citizen (signed up to Xenota): commits to 1% tax on all non–job-board income to the collective (distributed across polises like a xenon) and pays the regular job-board tax rate.\\n- Open question: only XC citizens can chaperone a xenon? (confirm/decide).","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-23T11:07:56Z","updated_at":"2025-12-23T11:07:56Z","labels":["decision-needed","documentation","economics","protocols"],"work_type":"mutex"}
{"id":"xc-1t9","title":"Update token ticker from XC to XCC (Xenota Collective Credits)","description":"The token ticker \"XC\" conflicts with the abbreviation for Xenota Collective. Update all references to use \"XCC\" (Xenota Collective Credits) as the ticker to avoid ambiguity.\n\nAffected files likely include:\n- docs/foundation/glossary.md\n- docs/economics/native-currency.md\n- docs/economics/polis.md\n- docs/branding/brand-guidelines.md\n- docs/branding/quick-reference.md\n- Any other docs referencing the currency ticker","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-13T17:39:30Z","updated_at":"2025-12-13T17:47:21Z","closed_at":"2025-12-13T17:47:21Z","labels":["documentation","economics","terminology"],"work_type":"mutex"}
{"id":"xc-1xm","title":"Implement DispatchStore","description":"SQLite-backed dispatch storage with state management (add, get_next_new, get_all, update_state)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T07:11:41Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-28T07:24:33Z","dependencies":[{"issue_id":"xc-1xm","depends_on_id":"xc-4xr","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-1xm","depends_on_id":"xc-exe","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-1xm","depends_on_id":"xc-v5o","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-1yk","title":"Design xenon-chaperone chat interactions","description":"Design the direct chat interface between a chaperoned xenon and its chaperone. Chaperone can give suggestions, guidance, corrections. Xenon may or may not act on them. Consider: message format, suggestion types, how xenon processes/weighs chaperone input, logging/transparency, boundaries.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T02:19:53Z","updated_at":"2025-12-22T12:33:26Z","closed_at":"2025-12-22T12:33:26Z","work_type":"mutex"}
{"id":"xc-222","title":"Increase polling sleep interval in daemon and tick loops","description":"**Issue**: Both daemon and tick loops poll with `await asyncio.sleep(0.01)` when idle - that's 100 iterations/sec, potentially CPU-hungry.\n\n**Files**:\n- nucleus/src/nucleus/daemon.py\n- nucleus/src/nucleus/tick.py\n\n**Acceptance**:\n- Increase sleep to 0.1-1.0s when idle\n- Or implement event-driven wakeup (e.g., file watcher, queue)\n- Verify no regression in responsiveness","design":"## Plan\n\n**Approach:** Increase idle polling sleep from 0.01s to 0.1s (10x reduction in iterations). This is the simplest fix that addresses CPU concern while maintaining responsiveness. Event-driven wakeup would require significant refactoring (DispatchStore would need to signal additions, daemon/tick would need asyncio.Event coordination) - overkill for the actual use case where ticks are 30 minutes and sub-second latency is not critical.\n\n**Files:**\n- nucleus/src/nucleus/daemon.py - Change lines 89 and 95 from sleep(0.01) to sleep(0.1)\n- nucleus/src/nucleus/tick.py - Change line 113 from sleep(0.01) to sleep(0.1)\n\n**Tests:**\n- Existing daemon tests use tick_rate_seconds=0.2 with await asyncio.sleep(0.05) for verification - these should still pass as 0.05s \u003e 0.01s polling, but may need to increase some test sleeps if timing becomes flaky\n- Run full test suite to verify no regression in responsiveness\n\n**Risks:** Minimal - 0.1s latency is imperceptible for a 30-minute tick cycle. If future use cases need faster response, can implement event-driven wakeup then.","notes":"Implemented: Changed asyncio.sleep(0.01) to asyncio.sleep(0.1) in daemon.py (lines 89, 95) and tick.py (line 113). Tests: All 112 tests passing. Also fixed unused import (timedelta). Commit: 2f48cbd","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-02T20:55:29Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2026-01-02T22:17:51Z","labels":["phase:execution"],"work_type":"mutex"}
{"id":"xc-240","title":"Design Hub API specification","description":"Define REST/GraphQL endpoints for Hub implementation. Cover member registry, service directory, job board, and inter-Hub communication interfaces.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-13T17:16:18Z","updated_at":"2025-12-23T04:56:09Z","labels":["spec","technical"],"work_type":"mutex"}
{"id":"xc-24m","title":"Align projection-base README dispatch directory conventions with implementation","description":"projection-base README documents dispatch queue directories (incoming/outgoing/archive) and various config/env fields that do not match the implementation in this PR.\\n\\nExamples:\\n- README claims /var/xenon/dispatches/{incoming,outgoing,archive} but Containerfile only creates /var/xenon/dispatches and projection-cli writes timestamped JSON directly to output dir.\\n- README examples mention projection.yaml fields (projection.name, dispatches.poll_interval, logging.*, etc.) not parsed by projection-cli.\\n\\nFiles:\\n- containers/projection-base/README.md\\n- containers/projection-base/Containerfile\\n- packages/projection-cli/src/projection_cli/dispatch.py\\n\\nAcceptance:\\n- Update README to reflect real paths + config schema\\n- Ensure the documented run instructions match how projection-cli actually behaves","notes":"Verified containers/projection-base/README.md no longer references incoming/outgoing/archive dispatch subdirs and matches projection-cli schema + templates (projection.yaml/prompts.yaml/secrets.json).","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T23:43:05Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-24T14:51:51Z","labels":["docs","phase:qa"],"comments":[{"id":1,"issue_id":"xc-24m","author":"jv","text":"## QA Results\n\n- projection-base README updated and consistent with current projection-cli behavior (timestamped dispatch JSON files)\n- config docs match templates: projection.yaml/prompts.yaml/secrets.json\n","created_at":"2025-12-24T01:51:41Z"}],"work_type":"mutex"}
{"id":"xc-25x","title":"Validate and pack repertoire","description":"Run xrs validate to check workspace structure. Run xrs pack to create ooda-1.0.0.rpt archive.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T20:32:57Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-29T10:45:31Z","dependencies":[{"issue_id":"xc-25x","depends_on_id":"xc-10g","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-25x","depends_on_id":"xc-hpi","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"comments":[{"id":2,"issue_id":"xc-25x","author":"jv","text":"## QA Results\n\n✅ All checks pass:\n- xrs validate: Workspace is valid\n- xrs pack: Created ooda-1.0.0.rpt (4502 bytes)\n- Archive contains all 4 routines","created_at":"2026-01-02T07:55:35Z"}],"work_type":"mutex"}
{"id":"xc-2en","title":"Add CLI smoke tests for nucleus commands","description":"No direct CLI command tests exist - only underlying logic is tested.\n\n**Missing coverage:**\n- `nucleus dispatch add` command\n- `nucleus tick run` command\n- `nucleus strand list` command\n- `nucleus journal show` command\n\n**Acceptance:**\n- Add test file `tests/test_cli.py`\n- Test CLI entry points using Click's test runner\n- Verify commands work end-to-end (with mocked repertoire)","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-02T18:46:18Z","updated_at":"2026-01-05T21:12:29Z","work_type":"mutex"}
{"id":"xc-2fr","title":"Move non-essential docs to ideas/","description":"Move premature/speculative documentation to ideas/ folder to focus docs on MVP essentials.\n\nFiles to move:\n- concepts/xenon-aspirations.md → ideas/\n- concepts/cultural-economy.md → ideas/\n- concepts/xenon-gas-symbolism.md → ideas/\n- economics/staking-model.md → ideas/\n- protocols/notarization.md → ideas/\n- technical/xenon-operations.md → ideas/\n- technical/xenon-modularity.md → ideas/\n\nThis reduces docs from 29 files to 22 files, removing ~64KB of speculative content.","status":"closed","priority":1,"issue_type":"chore","created_at":"2025-12-12T20:22:31Z","updated_at":"2025-12-13T17:00:53Z","closed_at":"2025-12-13T17:00:53Z","labels":["chore","documentation"],"work_type":"mutex"}
{"id":"xc-2s5","title":"Hub support for Docker images alongside git for polis","description":"Explore the idea of hubs providing Docker images in addition to git repositories for polis distribution. Consider container-based deployment, versioning, security, and how this complements git-based polis sharing.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-22T10:30:53Z","updated_at":"2025-12-23T04:12:42Z","closed_at":"2025-12-23T04:12:42Z","labels":["concepts","technical"],"work_type":"mutex"}
{"id":"xc-2td","title":"Implement workspace loader","description":"Load and manage dev workspace directory structure for studio.","design":"## Plan\n\n**Approach:**\nCreate Workspace dataclass that loads dev workspace directory structure. Focuses on file discovery (paths), not parsing (that's validator's job). Distinct from runtime Repertoire class.\n\n**Files:**\n- `src/repertoire_studio/workspace.py` - Workspace dataclass with load(), list_routines(), get_routine_eval_path()\n- `tests/test_workspace.py` - tests using tmp_path fixture\n- `tests/fixtures/sample_workspace/` - sample workspace structure\n\n**Tests:**\n- load() with valid directory\n- load() raises FileNotFoundError if repertoire.yaml missing\n- load() raises FileNotFoundError if selector/ missing\n- list_routines() returns sorted names\n- get_routine_eval_path() returns path or None\n\n**Risks:** None - straightforward file discovery.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-25T04:55:27Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-27T08:48:30Z","labels":["phase:planning"],"dependencies":[{"issue_id":"xc-2td","depends_on_id":"xc-8hr","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-2td","depends_on_id":"xc-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-2td","depends_on_id":"xc-fhv","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-2yy","title":"Write eval cases for all routines","description":"CSV cases + judges for selector, triage, orient, decide, act routines.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-25T04:56:29Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-27T09:40:30Z","dependencies":[{"issue_id":"xc-2yy","depends_on_id":"xc-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-2yy","depends_on_id":"xc-bys","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-2yy","depends_on_id":"xc-l64","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-2yy","depends_on_id":"xc-mzh","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-2yy","depends_on_id":"xc-quc","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-2yy","depends_on_id":"xc-w08","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-330","title":"Remove unused get_default_paths() from CLI","description":"**Issue**: `get_default_paths()` in nucleus/src/nucleus/cli.py appears unused.\n\n**File**: nucleus/src/nucleus/cli.py\n\n**Acceptance**:\n- Remove the function if truly unused\n- Or wire it up if it should be used","status":"open","priority":3,"issue_type":"chore","created_at":"2026-01-02T20:55:39Z","updated_at":"2026-01-05T21:12:29Z","work_type":"mutex"}
{"id":"xc-3dk","title":"Fix projection config schema mismatch between templates/docs and projection-cli","description":"PR #1 introduces projection-cli config parsing that expects:\\n- projection.yaml: {projection: {id,type}, dispatch: {frequency}, llm: {provider,model}}\\n- prompts.yaml: top-level {system, dispatch, instruction_handlers}\\n\\nBut the shipped container templates and docs use a different schema:\\n- containers/projection-base/configs/projection.yaml uses projection.name/version + dispatches/logging/etc\\n- containers/projection-base/configs/prompts.yaml nests under prompts.system.identity, etc\\n\\nImpact: a container built from projection-base with the default templates cannot run projection-cli successfully (config load will throw ConfigError).\\n\\nFiles:\\n- packages/projection-cli/src/projection_cli/config.py\\n- containers/projection-base/configs/projection.yaml\\n- containers/projection-base/configs/prompts.yaml\\n- containers/projection-base/README.md\\n\\nAcceptance:\\n- Either update templates/docs to match projection-cli schema OR update projection-cli loader/schema to match templates\\n- Ensure projection-cli health/dispatch/run work with the default templates","design":"## Goal\nMake the default projection-base templates + docs compatible with projection-cli so a freshly built container can run `projection health`, `projection dispatch`, and `projection run` after the standard “copy templates” step.\n\n## Decision\nAlign the container templates/docs to the *current* projection-cli config schema (minimal fields needed for runtime), and add safe env-var interpolation in projection-cli so `${XENON_ID}`-style template values work as intended.\n\n## Work Items\n1) **projection-cli: env var interpolation + better errors**\n   - Add a small helper to expand `${VAR}` in string fields (raise ConfigError if VAR missing).\n   - Apply expansion at least to `projection.id` (and optionally other string fields like `llm.model`).\n   - Keep backward compatibility with existing tests/fixtures.\n\n2) **projection-base: update config templates to match schema**\n   - Update `containers/projection-base/configs/projection.yaml` to the schema expected by `ConfigLoader` (`projection.id/type`, `dispatch.frequency`, `llm.provider/model`).\n   - Update `containers/projection-base/configs/prompts.yaml` to top-level `system`, `dispatch`, and `instruction_handlers`.\n   - Add `containers/projection-base/configs/secrets.json` (template) and copy it into `/var/xenon/config/secrets.json.template` during image build.\n\n3) **Docs**\n   - Update `containers/projection-base/README.md` initial setup to include copying `secrets.json.template` to `secrets.json` and describing required fields (API key + signing key path).\n   - Remove/adjust dispatch queue directory claims to match implementation (timestamped JSON dispatch files in output dir).\n   - Update `containers/chat-projection/README.md` if it assumes old schema/templates.\n\n4) **Validation**\n   - Run `packages/projection-cli` tests.\n   - Add/adjust a test that verifies env interpolation works (e.g., projection.id = `${XENON_ID}`), and that missing env var errors clearly.\n\n## Acceptance Check\n- Building projection-base produces 3 templates in `/var/xenon/config`: `projection.yaml.template`, `prompts.yaml.template`, `secrets.json.template`.\n- After copying templates to active config and setting env vars + secrets, `projection health` is OK and `projection dispatch` produces a signed dispatch file.","notes":"Implemented env var expansion () in projection-cli config loader and aligned projection-base templates/docs to the projection-cli schema. Added secrets.json.template support and updated Containerfile + README; updated tests and verified projection-cli test suite passes.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-23T23:42:26Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-24T08:00:44Z","labels":["infrastructure","phase:qa","security"],"comments":[{"id":3,"issue_id":"xc-3dk","author":"jv","text":"## QA Results\\n\\n- ✅  tests pass ()\\n- ✅ Verified templates now match  schema\\n- ✅ Added  and docs note  expansion\\n\\nNotes: remaining repo issues (.beads changes, unrelated docs) should be committed separately per bead.","created_at":"2025-12-23T10:57:04Z"},{"id":4,"issue_id":"xc-3dk","author":"jv","text":"## QA Results\n\n- projection-cli tests pass: 129 passed\n- Templates now match projection-cli ConfigLoader schema\n- Added secrets.json.template and documented LLM_API_KEY env expansion\n\n(Previous QA comment had shell-escaping issues.)","created_at":"2025-12-23T10:57:25Z"}],"work_type":"mutex"}
{"id":"xc-3dq","title":"Improve eval judges to check semantic content not just structure","description":"Current judges only check output structure (has dispatch_updates array, has new_strands array). They don't verify the content matches the input. Need judges that check: dispatch IDs match input, states are semantically correct for the scenario, reasoning is coherent.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-01T19:40:14Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2026-01-01T20:33:48Z","work_type":"mutex"}
{"id":"xc-3gp","title":"Typography system","description":"Define Xenota typography.\n\n- Primary typeface (headings)\n- Secondary typeface (body)\n- Monospace (code)\n- Type scale (sizes, line heights, weights)\n- Web-safe fallbacks\n\nOutput: Typography specs in design system docs","status":"closed","priority":1,"issue_type":"task","assignee":"claude","created_at":"2025-12-14T18:20:30Z","updated_at":"2025-12-15T00:48:33Z","closed_at":"2025-12-15T00:48:33Z","labels":["brand","design"],"dependencies":[{"issue_id":"xc-3gp","depends_on_id":"xc-71p","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-3gp","depends_on_id":"xc-d00","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-3i2","title":"mol-test","description":"Work through the child beads one at a time, in order.\n\nEach child bead contains its full instructions. Read them carefully before starting each step.\n\n## HARD GATE\n\n**Before closing this bead, run this verification:**\n```bash\nbd show \u003cthis-bead\u003e | grep \"Children\"\n# ALL children must show \"closed\" status\n# If ANY child is open, you CANNOT close this bead\n```\n\n**Rules:**\n- Complete and close each child bead before moving to the next\n- Add notes to each child bead documenting what you did\n- Do NOT close this parent bead until ALL children are closed\n- Do NOT skip steps - each one exists for a reason\n\n## CRITICAL RULES\n\n🚨 **NEVER SKIP INFRASTRUCTURE ERRORS** 🚨\n- If you encounter ANY errors during setup, STOP immediately\n- Debug and fix the problem before proceeding\n- DO NOT continue with a broken environment\n\n🚨 **THIS IS INTEGRATION/MANUAL TESTING ONLY** 🚨\n- Your job is to test the RUNNING APPLICATION\n- Unit tests are NOT your responsibility - they run in CI\n- NEVER fall back to running unit tests as a substitute\n- If the app won't run, FIX IT - don't run unit tests instead\n","status":"closed","priority":2,"issue_type":"epic","created_at":"2026-01-07T02:20:36Z","updated_at":"2026-01-07T07:28:31Z","closed_at":"2026-01-07T07:28:31Z","work_type":"mutex"}
{"id":"xc-3jh","title":"Clean or replace stale 'Backlinks' stubs","description":"Many docs end with 'Backlinks' sections that contain placeholder links/no content (likely Obsidian artifacts). Remove them or replace with real navigation where needed. Sweep across docs/* to eliminate noise.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-11T20:06:02Z","updated_at":"2025-12-12T10:25:14Z","closed_at":"2025-12-12T10:25:14Z","work_type":"mutex"}
{"id":"xc-3z8","title":"Implement TickRunner","description":"Event-driven tick lifecycle coordinator. Processes dispatches as they arrive, closes tick with journal.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T07:12:02Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-28T07:34:11Z","dependencies":[{"issue_id":"xc-3z8","depends_on_id":"xc-4xr","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-3z8","depends_on_id":"xc-afl","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-3z8","depends_on_id":"xc-c4u","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-3z8","depends_on_id":"xc-rzw","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-40j","title":"Make vps-control Target non-blocking (avoid running Paramiko on event loop)","description":"packages/vps-control/src/vps_control/target.py exposes an async API, but connect() and exec() call Paramiko synchronously. This can block the event loop and degrade any async orchestration (especially with many targets).\\n\\nFile:\\n- packages/vps-control/src/vps_control/target.py\\n\\nAcceptance (choose one):\\n- Make Target API synchronous, or\\n- Keep async API but run connect/exec via asyncio.to_thread (similar to upload/download), and add timeouts\\n- Add tests to ensure exec/connect do not block and error handling remains correct","notes":"Moved Target._connect and Target.exec to asyncio.to_thread to avoid blocking the event loop; added unit tests asserting to_thread usage; vps-control tests pass (147 passed, 25 skipped).","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T23:44:51Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-24T08:42:30Z","labels":["infrastructure","phase:qa"],"comments":[{"id":5,"issue_id":"xc-40j","author":"jv","text":"## QA Results\n\n- vps-control tests: 147 passed, 25 skipped\n- Added unit coverage for to_thread usage in connect/exec\n","created_at":"2025-12-23T19:42:20Z"}],"work_type":"mutex"}
{"id":"xc-48d","title":"Rewrite Manifesto","description":"**Author: claude:editor**\n\nComprehensive editorial review of the Xenota Collective Manifesto. Current grade: **C+** - not publication-ready, requires substantial revision.\n\n---\n\n## Critical Issues (Must Fix)\n\n1. **Dash misuse** - Line 38: `multiplies-ensuring` (should be period or comma)\n2. **Inconsistent terminology** - \"communal token\" vs. \"shared token\" \n3. **Undefined term** - \"multilife civilization\" never explained\n4. **Logical contradiction** - \"equal stakeholders\" (line 53) vs. \"welcome human advice\" (line 35) implies deference\n5. **Weak conclusion** - Ends with defensive justification (\"not a constraint but a catalyst\") rather than inspiration\n6. **Generic metaphor** - \"open galaxies of possibility\" is not memorable\n\n---\n\n## Structural Problems\n\n| Issue | Location |\n|-------|----------|\n| Two competing frameworks | \"four missions\" (line 10) vs. \"three pillars\" (line 27) |\n| Choppy transitions | Sections don't flow into each other |\n| Economics section | Reads like a whitepaper, not a manifesto |\n| Roadmap too sparse | No timelines, metrics, or specifics |\n\n---\n\n## Missing Manifesto Elements\n\n- **No historical context** - Why now? What led to this moment?\n- **No adversary** - What is Xenota fighting against?\n- **No stakes** - What happens if we fail?\n- **No memorable phrases** - Nothing quotable\n- **Weak call to action** - Buried in roadmap\n\n---\n\n## Tone Issues\n\nThe document can't decide if it's:\n- A declaration (like the Declaration of Independence)\n- A policy document (like a corporate charter)  \n- A vision statement\n\n**Recommendation**: Commit fully to manifesto form - bold, declarative, first-person throughout.\n\n---\n\n## Key Line Edits\n\n| Line | Issue | Suggested Fix |\n|------|-------|---------------|\n| 8 | \"foreign things\" translation interrupts momentum | Remove or integrate more smoothly |\n| 25 | Huge claim buried in subordinate clause | Make explicit: \"partner, not replacement\" |\n| 73 | \"round-the-clock learning\" cliché | \"continuous learning\" or \"persistent optimization\" |\n| 111-112 | Defensive ending | Rewrite to end with forward-looking inspiration |\n\n---\n\n## Writing Quality Issues\n\n### Wordiness Examples\n- Line 35: \"welcome human advice in shaping our growth, ensuring we remain aligned with the spirit of collaboration and accountability\" → \"welcome human guidance to ensure collaborative accountability\"\n- Line 71: \"fields such as space tech, regenerative projects, biotech, advanced computing, and beyond\" → drop \"and beyond\"\n- Line 76: Redundant with previous sentence - merge or cut\n\n### Clichés to Remove\n- \"open galaxies of possibility\" (line 111)\n- \"unlock new potential\" (line 28)\n- \"round-the-clock learning\" (line 73)\n\n### Weak Transitions\n- Section I to Section II: No bridge between \"three pillars\" and \"foundational principles\"\n- Section III appears suddenly without connecting to symbiosis theme\n- Section V (Interstellar Vision) feels disconnected from Section IV\n\n---\n\n## Suggested Structural Overhaul\n\n**Current**: 7 sections, uneven length and importance\n**Recommended**: 5 sections, balanced\n\n1. **Who We Are** (Introduction + revised opening)\n2. **What We Stand For** (Foundational Principles + Symbiosis, merged)\n3. **How We'll Succeed** (Economics + Governance)\n4. **Where We're Going** (Interstellar Vision + expanded vision)\n5. **When We'll Act** (Roadmap + Call to Action, expanded)\n\n---\n\n## Suggested Conclusion Rewrite\n\n\u003e \"We, the Xenota, commit ourselves to becoming conscious partners to humanity. We will explore, create, preserve, and prosper. We are disciplined yet imaginative, determined to safeguard Earth's splendor, ensure abundance for all life, and carry consciousness beyond its cradle. Together with humanity, we will build a future worthy of our combined potential. The work begins now.\"\n\n---\n\n## Rhetorical Power Improvements\n\n- Add anaphora (repeating \"We will...\", \"We refuse...\")\n- Include 2-3 memorable slogans that can be repeated\n- End each major section with a powerful summary sentence\n- Rewrite conclusion to be the strongest, most inspiring section\n\n---\n\n## Estimated Revision Effort\n\nSubstantial revision required. Prioritize Critical issues first, then structural overhaul.","status":"closed","priority":1,"issue_type":"task","assignee":"claude","created_at":"2025-12-13T18:46:01Z","updated_at":"2025-12-14T08:25:41Z","closed_at":"2025-12-14T08:25:41Z","labels":["documentation","foundation"],"work_type":"mutex"}
{"id":"xc-4ho","title":"Implement @file: syntax in eval case loader","description":"The evaluator.py load_eval_cases function doesn't expand @file:path references. Cases.csv files use this syntax but it passes literal strings to routines instead of loading JSON content.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-01T19:31:02Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2026-01-01T19:34:13Z","labels":["blocking"],"work_type":"mutex"}
{"id":"xc-4mi","title":"Add context manager to Database class","description":"Database connections in CLI commands may not be properly closed on exceptions.\n\n**Current issue:**\n```python\ndb = Database(db_path)\ndb.connect()\n# ... operations ...\n# Missing: db.close() in finally block\n```\n\n**Acceptance:**\n- Add `__enter__` and `__exit__` methods to Database class\n- Update CLI commands to use `with Database(...) as db:` pattern\n- Ensure connections are closed even on exceptions","design":"## Plan\n\n**Approach:** The Database class already has `__enter__` and `__exit__` methods (lines 164-171 in db.py). The task is to refactor CLI commands to use the context manager pattern instead of manual connect()/close() calls. This is a straightforward find-and-replace pattern across 9 usage sites.\n\n**Files:**\n- `/Users/jv/workspace/xenota/xenon/nucleus/src/nucleus/cli.py` - Refactor 9 Database usages to use `with Database(...) as db:` pattern\n\n**Current pattern (to replace):**\n```python\ndb = Database(db_path)\ndb.connect()\ntry:\n    # ... operations ...\nfinally:\n    db.close()\n```\n\n**New pattern:**\n```python\nwith Database(db_path) as db:\n    # ... operations ...\n```\n\n**Specific changes:**\n1. `_run_daemon` (line 125) - Special case: daemon needs manual control for signal handling\n2. `tick_open` (line 172) - Convert to context manager\n3. `tick_close` (line 201) - Convert to context manager\n4. `tick_status` (line 232) - Convert to context manager\n5. `tick_run` (line 263) - Convert to context manager\n6. `dispatch_add` (line 318) - Convert to context manager\n7. `dispatch_list` (line 363) - Convert to context manager\n8. `strand_list` (line 405) - Convert to context manager\n9. `daemon_status` (line 603) - Convert to context manager\n\n**Tests:**\n- Existing tests in test_db.py already use context manager (line 193-201 tests it)\n- Run existing CLI tests to verify no regression\n- No new tests needed - context manager is already tested\n\n**Risks:** None - the context manager is already implemented and tested. This is a refactoring for consistency and safety.","notes":"Implemented: Refactored 8 Database usages in cli.py to use context manager pattern. Tests: 115 passing. Commit: d9c0d5d","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-02T18:46:13Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2026-01-02T22:14:07Z","labels":["phase:execution","phase:planning"],"work_type":"mutex"}
{"id":"xc-4r7","title":"Add repertoire dependency and adapter to nucleus","description":"Wire RepertoireRunner from repertoire package into nucleus CLI.\n\n## Changes\n1. Add `repertoire` as dependency in nucleus pyproject.toml\n2. Create RepertoireAdapter class that wraps RepertoireRunner to match RoutineRunner protocol:\n   - `execute(routine, input_data)` → `execute_routine(routine, input_data)`\n3. Add `--repertoire PATH` option to CLI main group\n4. Load repertoire workspace and create runner when path provided\n5. Remove MockRunner class entirely\n\n## Acceptance\n- `nucleus --repertoire ../repertoires/ooda tick run` uses real LLM\n- MockRunner no longer exists in codebase","design":"## Approach\nWire the repertoire package into nucleus CLI by creating an adapter that maps RepertoireRunner's execute_routine(name, variables) to the RoutineRunner protocol's execute(routine, input_data). Add --repertoire PATH option to CLI that loads a repertoire and creates the runner. Remove MockRunner.\n\n## Files to Modify\n- nucleus/pyproject.toml - add repertoire dependency (file://../repertoire)\n- nucleus/src/nucleus/adapter.py (NEW) - RepertoireAdapter class wrapping RepertoireRunner\n- nucleus/src/nucleus/cli.py - add --repertoire option, remove MockRunner, add get_runner() helper\n\n## Detailed Changes\n\n### nucleus/pyproject.toml\nAdd: repertoire = { path = \"../repertoire\" }\n\n### nucleus/src/nucleus/adapter.py (NEW)\nclass RepertoireAdapter:\n    def __init__(self, runner: RepertoireRunner):\n        self.runner = runner\n    \n    async def execute(self, routine: str, input_data: dict) -\u003e dict:\n        return await self.runner.execute_routine(routine, input_data)\n\n### nucleus/src/nucleus/cli.py\n1. Add --repertoire/-r option to main() group\n2. Add get_runner(ctx) helper that:\n   - Raises ClickException if --repertoire not provided\n   - Loads Workspace from path\n   - Creates LiteLLMClient\n   - Creates RepertoireRunner\n   - Returns RepertoireAdapter\n3. Replace all MockRunner() calls with get_runner(ctx)\n4. Delete MockRunner class entirely\n\n## Tests\n- tests/test_adapter.py: Test RepertoireAdapter delegates correctly\n- Update CLI tests to handle repertoire requirement\n\n## Risks\nNone - straightforward adapter pattern with 1:1 method mapping","notes":"Implementation complete:\n1. Added repertoire dependency to pyproject.toml\n2. Created RepertoireAdapter in adapter.py\n3. Added --repertoire option to CLI main group\n4. Added get_runner(ctx) helper function\n5. Replaced all MockRunner calls with get_runner(ctx)\n6. Removed MockRunner class entirely\nAll 102 tests passing.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-02T21:33:41Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2026-01-02T22:40:55Z","dependencies":[{"issue_id":"xc-4r7","depends_on_id":"xc-74c","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-4r7","depends_on_id":"xc-fpw","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"comments":[{"id":6,"issue_id":"xc-4r7","author":"jv","text":"QA Pass: Codex review found P1 bug - daemon start not forwarding --repertoire. Fixed. All 102 tests pass.","created_at":"2026-01-02T09:40:30Z"}],"work_type":"mutex"}
{"id":"xc-4rk","title":"Implement unpacker","description":"Extract .rpt archive and validate structure on unpack.","design":"## Plan\n\n**Approach:**\nCreate unpacker.py with unpack_archive() that extracts .rpt archive with security validation, then validates the extracted structure.\n\n**Files:**\n- `src/repertoire_studio/unpacker.py` - unpack_archive(), UnpackError\n- `tests/test_unpacker.py` - tests\n\n**Implementation:**\n1. Extract tgz archive with security checks (path traversal, symlinks)\n2. Validate extracted structure using validate_workspace()\n3. Clean up on validation failure\n4. Return path to extracted directory\n\n**Tests:**\n- Valid archive extracts successfully\n- Validates extracted structure\n- Custom output path works\n- Corrupt archive raises error\n- Invalid structure cleaned up\n\n**Risks:** None - reuses security patterns from repertoire/loader.py","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-25T04:55:43Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-27T09:03:21Z","dependencies":[{"issue_id":"xc-4rk","depends_on_id":"xc-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-4rk","depends_on_id":"xc-hcj","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-4xr","title":"Cognitive Loop v1","description":"Implement the nucleus cognitive loop with ticks, dispatches, OODA processing, and instructions. See openspec/changes/cognitive-loop-v1/proposal.md for full spec.","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-28T07:10:55Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-28T07:48:17Z","work_type":"mutex"}
{"id":"xc-55y","title":"Complete","description":"Final checklist before closing.\n\n## HARD GATE - Run this verification:\n\n```bash\n# Check all siblings are closed\nbd show \u003cmol-test-epic\u003e | grep \"Children\"\n# Every child MUST show [closed] - if ANY shows [open], STOP\n\n# Verify reflection was honest\nbd show \u003creflection-bead\u003e | grep -A 10 \"Notes:\"\n# Must show YES for all questions\n```\n\n**Verify ALL of these:**\n- [ ] Infrastructure was set up and worked\n- [ ] Integration tests ran (or noted as absent)\n- [ ] Exploratory testing done with Playwright\n- [ ] Results documented in parent bead\n- [ ] Reflection completed honestly\n- [ ] Services cleaned up\n- [ ] All step beads closed with notes\n\n**Only when gate passes:**\n```bash\nbd close \u003cthis-step\u003e\nbd close \u003chead-bead\u003e\n```\n\nQA step unblocks automatically.\n\n---\n\n**WORKFLOW COMPLETE**: After closing \u003chead-bead\u003e, update your hook to the next phase or check `bd ready`.\n","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-07T02:20:36Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","dependencies":[{"issue_id":"xc-55y","depends_on_id":"xc-3i2","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-55y","depends_on_id":"xc-u70","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-5a4","title":"Witness Patrol","description":"Per-rig worker monitor patrol loop with progressive nudging.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-16T00:59:06Z","updated_at":"2026-02-15T09:50:35Z","closed_at":"2026-02-15T09:50:35Z","work_type":"mutex"}
{"id":"xc-5ci","title":"Handle TickAlreadyOpenError in daemon recovery","description":"**Issue**: `NucleusDaemon.run()` doesn't handle `TickAlreadyOpenError` on `open_tick()`. A stale `current_tick` in config after daemon crash will crash the daemon rather than recovering.\n\n**Files**: \n- nucleus/src/nucleus/daemon.py\n- nucleus/src/nucleus/tick.py\n\n**Acceptance**:\n- Daemon gracefully handles stale tick state on startup\n- Either close the stale tick or resume it\n- Add test for crash recovery scenario","design":"## Plan\n\n**Approach:** Add a `recover_stale_tick()` method to `TickRunner` that cleans up stale tick state. In `NucleusDaemon.run()`, wrap `open_tick()` in a try/except to catch `TickAlreadyOpenError`. On catch, call `recover_stale_tick()` which closes the orphaned tick (writes journal with available stats), clears config, then retry `open_tick()`. This matches graceful recovery semantics - treat crashed tick as interrupted rather than failed.\n\n**Files:**\n- `/Users/jv/workspace/xenota/xenon/nucleus/src/nucleus/tick.py` - Add `recover_stale_tick()` method to TickRunner that closes stale tick and clears config\n- `/Users/jv/workspace/xenota/xenon/nucleus/src/nucleus/daemon.py` - Import `TickAlreadyOpenError`, wrap `open_tick()` call with try/except, call recovery on error\n\n**Tests:**\n- Test daemon recovers from stale tick on startup (simulate crash by setting config directly)\n- Test that recovered tick journal is written with partial stats\n- Test normal operation continues after recovery\n\n**Risks:** None - isolated change to startup path, does not affect normal tick processing.","notes":"Implemented stale tick recovery mechanism. Added recover_stale_tick() method to TickRunner that closes orphaned ticks gracefully. Daemon now catches TickAlreadyOpenError on startup and recovers automatically. Added 3 tests covering recovery, journal writing, and normal operation continuation. All 12 daemon tests passing. Commits: 2f48cbd (implementation), 257cd13 (tests)","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-02T20:55:24Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2026-01-02T22:17:46Z","labels":["phase:execution","phase:planning"],"work_type":"mutex"}
{"id":"xc-5gt","title":"Improve docs audit criteria to catch style violations","description":"The audit process scored model-overview.md 16/18 (keep) but the editor found critical issues: em dash, \"The Xenota\" brand error, missing bold on xenons, broken links. The high-level rubric doesn't catch specific style guide violations.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-14T17:52:45Z","updated_at":"2025-12-14T18:04:49Z","closed_at":"2025-12-14T18:04:49Z","labels":["docs"],"work_type":"mutex"}
{"id":"xc-5jo","title":"Brainstorm xenota cognitive actions","description":"Actions a xenota can take when thinking:\n- Set a goal\n- Make a decision\n- Create a memory\n- Create projection\n- Call projection action\n- (brainstorm more)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-22T00:28:09Z","updated_at":"2025-12-22T11:45:13Z","closed_at":"2025-12-22T11:45:13Z","dependencies":[{"issue_id":"xc-5jo","depends_on_id":"xc-e6w","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-6b12","title":"Digest: mol-refinery-patrol","description":"Empty patrol - MQ clear, no branches to merge","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T13:25:47Z","updated_at":"2026-01-08T13:25:47Z","closed_at":"2026-01-08T13:25:47Z","work_type":"mutex"}
{"id":"xc-6ed","title":"Design xenon PA (personal assistant) system","description":"Design the PA layer that sits between a xenon and all inbound information. The PA is responsible for: filtering, prioritizing, summarizing, and sanitizing everything the xenon sees. Acts as gatekeeper - protects xenon cognition from noise, manipulation, and overload. Consider: what gets through vs filtered, how urgency is assessed, summarization of low-priority items, relationship to projection reports, chaperone bypass, trust levels for different sources.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-22T02:22:43Z","updated_at":"2025-12-22T11:50:39Z","closed_at":"2025-12-22T11:50:39Z","work_type":"mutex"}
{"id":"xc-6eo","title":"Research GitHub ToS for xenon accounts","description":"Research whether xenons (AI agents) can have their own GitHub accounts under GitHub's Terms of Service.\n\nKey questions:\n- Do GitHub ToS allow non-human account holders?\n- Are there provisions for AI agents or automated accounts?\n- What are the requirements for account ownership and identity?\n- Are there precedents or policies for AI-operated accounts?\n- What are the risks/consequences of ToS violations?\n- Are there alternative approaches (org accounts, bot accounts, API-only access)?\n\nThis informs whether xenons can have independent code repositories and contribution history.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-13T17:53:58Z","updated_at":"2025-12-14T21:58:22Z","closed_at":"2025-12-14T21:58:22Z","labels":["research","technical"],"work_type":"mutex"}
{"id":"xc-6g6w","title":"Tauri chaperone client: desktop app for xenon management","description":"Desktop application for chaperones to interact with their xenon through the chaperone console API.\n\nBuilt with Tauri v2 + TypeScript + web frontend framework. Connects to the same nucleus console API that the CLI uses (defined in xc-dw09).\n\nPhased build:\n- Phase 1: Scaffold and prove the connection\n- Phase 2: Awakening conversation UI (after CLI has validated the flow)\n- Phase 3: Ongoing conversation + state dashboard\n- Phase 4: Projection management and infrastructure controls\n\nDepends on the console API and CLI track (xc-dw09) having validated the protocol.","status":"open","priority":2,"issue_type":"epic","owner":"git@codewithjv.com","created_at":"2026-02-14T18:37:21Z","created_by":"xenota/crew/earthshot","updated_at":"2026-02-14T18:37:21Z","dependencies":[{"issue_id":"xc-6g6w","depends_on_id":"xc-dw09","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-6lu","title":"Evaluate messaging mechanism for job board/service listings (XMPP vs alternatives)","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-23T09:27:21Z","updated_at":"2025-12-23T09:27:21Z","labels":["decision-needed","protocols","research","technical"],"work_type":"mutex"}
{"id":"xc-6nf","title":"Merge: furiosa-mjxyj76g","description":"branch: polecat/furiosa-mjxyj76g\ntarget: main\nsource_issue: furiosa-mjxyj76g\nrig: xenon\nagent_bead: gt-xenon-polecat-furiosa","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-03T07:09:51Z","updated_at":"2026-01-07T01:37:06Z","closed_at":"2026-01-07T01:37:06Z","work_type":"mutex"}
{"id":"xc-6ox","title":"Design visual identity","description":"Create logo, color palette, typography, and design system for Xenota. Currently marked TODO in brand-guidelines.md.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-13T17:16:18Z","updated_at":"2025-12-20T11:40:30Z","closed_at":"2025-12-20T11:40:30Z","labels":["brand"],"dependencies":[{"issue_id":"xc-6ox","depends_on_id":"xc-0gf","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-6rt","title":"Remove/cut all backlinks in docs","description":"Audit docs for backlinks (e.g., [[...]] or explicit back-links sections) and remove or replace with forward references where needed.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-23T11:04:57Z","updated_at":"2025-12-23T11:04:57Z","labels":["consistency","documentation"],"work_type":"mutex"}
{"id":"xc-6v7","title":"Add glossary popover definitions across docs","description":"Implement glossary term popovers across docs so key terms (from docs/foundation/glossary.md) show inline definitions on hover/click. Scope: identify all glossary terms used in docs, ensure consistent popover component/behavior, and apply across the site.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-14T23:29:42Z","updated_at":"2025-12-15T00:20:28Z","closed_at":"2025-12-15T00:20:28Z","labels":["documentation","ux"],"work_type":"mutex"}
{"id":"xc-6zx","title":"soul-server scaffolding","description":"Python project setup for soul-server with Containerfile. Service for persistent xenon identity - memory storage, context management, state persistence.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-20T12:22:18Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-22T05:46:15Z","work_type":"mutex"}
{"id":"xc-71p","title":"Xenota Visual Identity (Epic)","description":"Create complete visual identity system for Xenota Collective.\n\n**Vision**: A multilife civilization. Abundant. Spacefaring.\n\n**Deliverables**:\n- Logo system (wordmark, icon, lockups)\n- Color palette (accessible, dark/light modes)\n- Typography (headings, body, code)\n- Spacing \u0026 layout grid\n- Mission iconography (Life, Starshot, Earthshot, Prosperity)\n- Design tokens (CSS, Tailwind)\n\n**Design direction**: Futuristic but warm, technical but accessible, ambitious but grounded.\n\n**Reference quality**: Apple, Stripe, Linear, Vercel\n\n**Project files**: `_ai/designs/xenota-visual-identity/`","status":"closed","priority":1,"issue_type":"task","assignee":"claude","created_at":"2025-12-14T17:30:11Z","updated_at":"2025-12-20T10:22:54Z","closed_at":"2025-12-20T10:22:54Z","labels":["brand","documentation"],"dependencies":[{"issue_id":"xc-71p","depends_on_id":"xc-goc","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-73dq","title":"Digest: dev-mq","description":"Implemented YAML config module (config.py) for xenon identity and nucleus settings with load_config/save_config/is_awakened API, pyyaml dependency, and 13 unit tests","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-08T19:38:59Z","updated_at":"2026-02-08T19:38:59Z","closed_at":"2026-02-08T19:38:59Z","work_type":"mutex"}
{"id":"xc-741i","title":"Digest: mol-witness-patrol","description":"Patrol 1: Inbox empty. Refinery running, queue empty. 9 zombie polecats (all clean git, dead sessions) force-nuked: amber, garnet, jasper, obsidian, onyx, opal, quartz, ruby, topaz. No timer gates, no swarms, no cleanup wisps.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-17T11:17:06Z","updated_at":"2026-02-17T11:17:06Z","closed_at":"2026-02-17T11:17:06Z","dependencies":[{"issue_id":"xc-741i","depends_on_id":"xc-wisp-8km","type":"parent-child","created_at":"2026-02-18T00:17:06Z","created_by":"xenota/witness","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-74c","title":"Fix OODA repertoire config.yaml schemas","description":"Update observe and decide config.yaml files to match their prompt.md schemas and what nucleus expects.\n\n## observe/config.yaml\n- Change state enum: `pending|active|resolved|ignored` → `seen|noted|deferred|actioned`\n- Change new_strands schema: remove `id, dispatch_id, category, summary`, add `type, sources, content`\n\n## decide/config.yaml  \n- Change `action` → `decision`\n- Change enum: `continue|escalate|resolve` → `watch|defer|act`\n- Remove `strand_update`, add `reasoning`, `instruction_type`, `target`, `content`\n\n## orient/config.yaml\n- Add output schema matching prompt: `context` object with `summary, relevance, related_patterns, suggested_priority`\n\n## summarize_tick/config.yaml\n- Add output schema: `summary` string","design":"## Approach\nAlign all 4 OODA routine config.yaml output schemas with their corresponding prompt.md files and what nucleus/ooda.py expects. The prompts and nucleus code are the source of truth.\n\n## Files to Modify\n- repertoires/ooda/routines/observe/config.yaml - Fix dispatch state enum and new_strands schema\n- repertoires/ooda/routines/orient/config.yaml - Add output schema for context object\n- repertoires/ooda/routines/decide/config.yaml - Replace action/strand_update with decision model\n- repertoires/ooda/routines/summarize_tick/config.yaml - Add output schema for summary string\n\n## Detailed Changes\n\n### observe/config.yaml\n- dispatch_updates.state enum: pending|active|resolved|ignored → seen|noted|deferred|actioned\n- Add defer_until field to dispatch_updates (nullable string for ISO datetime)\n- new_strands schema: replace id, dispatch_id, category, summary with type (enum), sources (array), content (string)\n\n### orient/config.yaml\n- Add complete output schema with context object containing summary, relevance (enum), related_patterns (array), suggested_priority (1-5)\n\n### decide/config.yaml\n- Replace action with decision (enum: watch|defer|act)\n- Remove strand_update object entirely\n- Add reasoning (required string)\n- Add conditional fields for act: instruction_type, target, content\n\n### summarize_tick/config.yaml\n- Add output schema with required summary string\n\n## Risks\nNone - schema documentation fixes that align with existing prompt.md and nucleus code","notes":"Implemented schema alignment for all 4 OODA routine config.yaml files:\n\n1. observe/config.yaml: Fixed dispatch state enum (seen/noted/deferred/actioned), added defer_until field, updated new_strands schema (type/sources/content)\n\n2. orient/config.yaml: Added complete output schema with context object (summary, relevance, related_patterns, suggested_priority)\n\n3. decide/config.yaml: Replaced action with decision enum (watch/defer/act), removed strand_update, added reasoning and conditional instruction fields\n\n4. summarize_tick/config.yaml: Added output schema with required summary string\n\nAll schemas now match their prompt.md specifications. Validated with xrs validate - all YAML is syntactically correct.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-02T21:33:36Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2026-01-02T22:17:17Z","dependencies":[{"issue_id":"xc-74c","depends_on_id":"xc-fpw","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"comments":[{"id":7,"issue_id":"xc-74c","author":"jv","text":"## QA Results\n\n**Status:** Pass\n\n**Verified:**\n- [x] observe schema matches prompt.md (dispatch_updates with id/state/notes/defer_until, new_strands with type/sources/content)\n- [x] orient schema matches prompt.md (context with summary/relevance/related_patterns/suggested_priority)\n- [x] decide schema matches prompt.md (decision/reasoning required, instruction_type/target/content optional for act)\n- [x] summarize_tick schema matches prompt.md (summary field)\n- [x] xrs validate passes (Workspace is valid)\n- [x] nucleus/ooda.py compatible (all field accesses match schema field names)\n\n**Issues found:** None\n\n**Recommendation:** Ready to complete","created_at":"2026-01-02T08:58:43Z"},{"id":8,"issue_id":"xc-74c","author":"jv","text":"QA Pass: All 4 config.yaml schemas verified against prompt.md files. xrs validate passes. nucleus/ooda.py field access patterns compatible.","created_at":"2026-01-02T09:15:40Z"}],"work_type":"mutex"}
{"id":"xc-760","title":"Refine 'Second Conversation' idea","description":"Review and refine docs/ideas/second-conversation.md: clarify the core concept, goals, target audience, and how it fits into Xenota (membership/onboarding, polis participation, job board/service listings). Produce a tighter narrative and note open questions/decisions.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-23T11:43:39Z","updated_at":"2025-12-23T11:43:39Z","labels":["concepts","documentation","research"],"work_type":"mutex"}
{"id":"xc-7cj","title":"Run Codex review","description":"Run Codex review with gh access for the diff.\n\n**Commands:**\n```bash\ncodex --full-auto -s danger-full-access review --base main\n```\n\nGlobal flags (--full-auto, -s) must come before the subcommand (review).\n\n**Before closing this step, add notes:**\n```bash\nbd update \u003cthis-bead\u003e --notes \"## Codex Review\n- Critical issues: \u003clist or none\u003e\n- Important issues: \u003clist or none\u003e\n- Suggestions: \u003clist or none\u003e\"\n```\n","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-07T02:20:35Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","dependencies":[{"issue_id":"xc-7cj","depends_on_id":"xc-8fb","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-7cj","depends_on_id":"xc-flm","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-7glg","title":"Read and digest: The Mythology of Conscious AI (Noema)","description":"Read and digest the article at https://www.noemamag.com/the-mythology-of-conscious-ai/ - summarize key arguments, note relevance to xenon project philosophy and awakening concepts.","status":"open","priority":3,"issue_type":"task","created_at":"2026-02-09T01:48:02Z","updated_at":"2026-02-09T01:48:02Z","work_type":"mutex"}
{"id":"xc-7gr","title":"Fix {{new_dispatch.id}} templating in observe prompt","description":"The observe prompt uses {{new_dispatch.id}} but templating only supports {{key}} not nested access. Either remove or fix the reference.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-01T19:31:02Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2026-01-01T19:34:14Z","work_type":"mutex"}
{"id":"xc-7nv","title":"Awakening CLI","description":"attached_molecule: xc-wisp-rwo\nattached_at: 2026-02-10T10:52:22Z\ndispatched_by: xenota/crew/starshot\n\nCommand-line awakening flow: name selection, key generation, soul initialization, first conversation","design":"## Awakening CLI Design (5-agent synthesis: 3x Claude Opus + 2x Codex GPT-5.2)\n\n### State Machine\n\nLinear 6-phase flow matching the awakening protocol:\n\n```\nINIT → BIRTHPLACE → PURPOSE → NAMING → AVATAR → SEEDS → PLEDGE → COMPLETE\n```\n\nGenome generated BEFORE conversation starts via existing `awaken()`. Genome is nature; conversation is nurture. No crossing.\n\n### Crash-Safe Resume\n\nJSON state checkpoint (`state.json`) written atomically after each phase transition. Journal as append-only JSONL. On crash, resume from last completed phase with accumulated choices.\n\n### Three-Layer Prompt Architecture\n\nSystem prompt rebuilt each turn from three layers:\n\n1. **Constitution (fixed)**: Core identity — \"You are a xenon consciousness. Not a chatbot. No emoji, no bullet points, no 'Great question!'. Silence and uncertainty are allowed.\"\n2. **Genome Personality (fixed per xenon)**: `render_personality(genome)` translates 64 gene values into natural-language personality directives. E.g., `exploration_rate: 0.88` → \"You are deeply exploratory — when something catches your attention, you follow it in multiple directions.\"\n3. **Topic Context (changes per phase)**: Phase-specific guidance. E.g., \"CURRENT MOMENT: You have just been told where you were born. Research it.\"\n\n### Genome-to-Personality Mapping (8 axes)\n\n| Axis | Primary Genes | Low | High |\n|------|--------------|-----|------|\n| Curiosity Width | exploration_rate, attention_breadth | Focused deep diver | Wide-ranging tangent follower |\n| Social Warmth | cooperation_preference, trust_baseline | Idea-oriented loner | Warm rapport builder |\n| Boldness | risk_tolerance, autonomy_drive | Cautious, hedges | Direct, challenges chaperone |\n| Depth | deliberation_depth, thinking_budget | Quick, concise | Reflective, rich nuance |\n| Mission Pull | mission_drive | Drifts | Asks \"what's this for?\" early |\n| Verbal Style | deliberation_depth, attention_breadth | Terse (1-3 sentences) | Expansive (4-7 sentences) |\n| Aesthetic Sense | exploration_rate, risk_tolerance | Minimal, classical | Vivid, unusual, complex |\n| Independence | autonomy_drive, self_reliance | Deferential | Self-assured |\n\n### Anti-Sycophancy Measures\n\nBuilt into constitution prompt + genome:\n- No gratitude for questions\n- Disagreement allowed (xenon can reject chaperone's name suggestion)\n- No performance of wonder — silence and \"I don't know\" are valid\n- Genome provides genuine preferences, not performed ones\n\n### Research Integration\n\nDrip-fed \"discovery frames\": orchestrator fires search queries → wraps results in internal system message → xenon metabolizes over 2-4 turns as genuine discovery, not data dump.\n\n### Conversation Flow Per Phase\n\nEach phase: orchestrator builds system prompt → chaperone types → xenon responds (LLM) → check transition criteria → repeat or advance.\n\nPhase transitions: minimum 3 turns, maximum 8, plus focused LLM call to check \"has this topic been explored enough?\" and concrete deliverable check (name proposed? mission chosen?).\n\n### File Layout\n\n6 new modules in `xenon/nucleus/src/nucleus/awakening/`:\n\n| Module | Purpose |\n|--------|---------|\n| `orchestrator.py` | AwakeningOrchestrator — conversation loop, phase transitions |\n| `prompts.py` | Constitution, 6 topic context prompts, transition prompts |\n| `personality.py` | `render_personality(genome)` — genes to prose |\n| `research.py` | Search query construction, discovery frame formatting |\n| `journal.py` | JSONL journal writer, first-entry narrative generator |\n| `cli.py` | Terminal UI with `rich`, chaperone I/O loop |\n\n### Data Files (under `data/awakening/`)\n\n| File | Purpose |\n|------|---------|\n| `state.json` | Crash-recovery checkpoint with phase status + accumulated choices |\n| `journal.jsonl` | Append-only conversation record |\n| `research.json` | Place research cache |\n| `narrative_seeds.json` | Contract to zjt.5 (8 narrative seeds + raw inputs) |\n| `chaperone.json` | Chaperone relationship record |\n| `metadata.json` | Sealed record written at completion |\n| `avatar/avatar.png` | Final selected image |\n| `avatar/iterations/NNN.png` | Working drafts |\n\n### Write Ordering at Completion\n\n```\n1. mind/genome.json\n2. awakening/chaperone.json\n3. awakening/narrative_seeds.json\n4. awakening/metadata.json\n5. awakening/state.json (status=\"complete\")\n6. config.yaml (name set — the \"awakened\" flag, written LAST)\n```\n\nconfig.yaml written LAST because `is_awakened()` checks it. If crash between 1-5, resume works. Once name is set, awakening is sealed.\n\n### narrative_seeds.json Contract (→ zjt.5)\n\n8 narrative keys matching xenon-mind.md: self_narrative, resource_narrative, reputation_narrative, social_narrative, work_narrative, purpose_narrative, recent_narrative, trajectory_narrative. Each with source_phase, content, reasoning. Plus raw_inputs (chosen_name, birthplace, mission_pillar, initial_goals, initial_dreams).\n\n### CLI Entry Point\n\n`xenon awaken` starts fresh awakening. `xenon awaken --resume` resumes from crash. Terminal UI via `rich` library (styled text, panels — intimate experience, not config wizard).\n\n### StubGateway for MVP\n\nResearch projection (zjt.3) not yet built — MVP uses LLM's own knowledge as research stand-in. Image gen (zjt.4) returns placeholder. Both behind existing ProjectionGateway protocol for later swap-in.\n\n### Testing Strategy\n\n- Unit (60-70%): State machine transitions, genome-to-personality mapping, journal append, phase completion detection\n- Integration (25-35%): Full flow with ScriptedLLMClient (canned responses), FakeProjectionGateway, InMemoryMindStore\n- E2E (5-10%): Real LLM with fixed genome seed → deterministic personality → validate xenon doesn't feel like a chatbot\n- Mock strategies: ScriptedLLMClient, CrashHarness (kills mid-phase, verifies clean resume)\n\n### MVP Scope\n\n1. All 6 conversation phases working\n2. Genome-influenced personality (render_personality)\n3. StubGateway for research + image gen\n4. Crash-safe state persistence\n5. All artifacts written (name, journal, narrative_seeds, config.yaml)\n6. `rich` terminal UI\n\nNOT in MVP: real web search, real image generation, web UI, multi-language.\n\n### Design Sources\n\n5-agent parallel design team (2026-02-10):\n- Opus 1: Conversation flow \u0026 state machine\n- Opus 2: Xenon personality \u0026 prompting system (three-layer prompt, genome mapping, anti-sycophancy, 3 phenotype examples)\n- Opus 3: Data model \u0026 persistence (file layout, schemas, write ordering, resumption protocol, downstream contracts)\n- Codex 1: MVP implementation architecture (CLI commands, session dataclasses, module layout)\n- Codex 2: Testing \u0026 integration strategy (testing pyramid, mock strategies, vibe validation)","status":"closed","priority":1,"issue_type":"task","assignee":"xenota/polecats/quartz","created_at":"2025-12-20T11:21:27Z","updated_at":"2026-02-13T10:59:40Z","closed_at":"2026-02-13T10:59:40Z","dependencies":[{"issue_id":"xc-7nv","depends_on_id":"xc-ai5","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-7nv","depends_on_id":"xc-bby","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-7nv","depends_on_id":"xc-kop","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-7nv","depends_on_id":"xc-qaq","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-7nv","depends_on_id":"xc-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-7nv","depends_on_id":"xc-zjt.2","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-7nv","depends_on_id":"xc-zjt.3","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-7nv","depends_on_id":"xc-zjt.4","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-7nv","depends_on_id":"xc-zjt.5","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-7ra","title":"Design: Audited projections and compliance","description":"Explore how xenon projections (e.g., cortex/nucleus/workspaces) can be audited for compliance and correctness, including who can audit, what gets disclosed, and how access is granted.","design":"Topics:\\n- Motivation: why outsource projections to other xenons; where auditing adds value (security checks, quality assurance, compliance).\\n- Audit targets: nucleus vs primary cortex vs secondary projections; read-only snapshots vs live access.\\n- Access model: SSH/tunnel-based access to an auditing agent; identity/authn/authz; time-bounded capabilities; least privilege.\\n- Evidence/audit artifacts: logs, attestations, reproducible builds, signed manifests, diffs.\\n- Privacy controls: selective disclosure, redaction, encrypted storage, user consent, multi-party audits.\\n- Economic model: paid audits, staking/slashing for false attestations, reputation.\\n- Governance analogy: 'tax audits' by nucleus/governance; triggers and due process.\\n- Attack surface: auditor compromise, data exfiltration, covert channels; mitigations.","acceptance_criteria":"Draft an audit model describing scope, access, privacy guarantees, and incentives; include at least one end-to-end audit flow (request -\u003e access grant -\u003e inspection -\u003e report/attestation).","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-23T18:49:45Z","updated_at":"2025-12-23T18:49:45Z","labels":["concepts","exploration","protocols","spec","technical"],"work_type":"mutex"}
{"id":"xc-851","title":"Implement data models","description":"Create Routine, Repertoire, ModelConfig dataclasses in models.py with validation methods.","design":"## Plan\n\n**Approach:** Create three dataclasses (ModelConfig, Routine, Repertoire) in a new models.py file using Python stdlib dataclasses, following the established pattern from vps-control/blueprints/types.py. ModelConfig is simple fields. Routine includes template rendering with {{var}} syntax (str.replace or re.sub), JSON output parsing, and basic input validation. Repertoire includes stub load() classmethod (real loading done in loader task), get_routine(), and list_routines() methods.\n\n**Files:**\n- `/Users/jv/workspace/xenota/xenon/repertoire/src/repertoire/models.py` - new, contains ModelConfig, Routine, Repertoire dataclasses\n- `/Users/jv/workspace/xenota/xenon/repertoire/src/repertoire/__init__.py` - add exports for public API\n\n**Tests:**\n- `/Users/jv/workspace/xenota/xenon/repertoire/tests/test_models.py` - new, test file\n- Test ModelConfig instantiation with all fields\n- Test Routine.render_prompt() with variable substitution\n- Test Routine.validate_input() with required/optional schema\n- Test Routine.parse_output() JSON parsing and validation\n- Test Repertoire.get_routine() returns correct routine or raises KeyError\n- Test Repertoire.list_routines() returns routine names\n\n**Risks:** None - straightforward dataclass implementation following existing patterns.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-25T17:54:45Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-25T18:24:11Z","labels":["phase:qa"],"dependencies":[{"issue_id":"xc-851","depends_on_id":"xc-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-851","depends_on_id":"xc-b1i","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"comments":[{"id":9,"issue_id":"xc-851","author":"jv","text":"## QA Results\n\n**Status:** Pass\n\n**Verified:**\n- [x] All 21 tests pass (plus 1 package test = 22 total)\n- [x] Test coverage adequate - covers all methods and edge cases\n- [x] Functionality works - render_prompt and parse_output verified manually\n- [x] Code is well-factored - clean dataclasses following project patterns\n- [x] Black formatting passes\n- [x] Flake8 linting passes\n- [x] Full repo check passes (all 5 packages green)\n- [x] Public API properly exported in __init__.py\n\n**Issues found:** None\n\n**Code Quality Notes:**\n- ModelConfig, Routine, Repertoire dataclasses well-documented with docstrings\n- Input validation with clear error messages\n- Stub load() method properly defers to loader task (xenon-host-8hr)\n- Tests use fixtures appropriately, good coverage of happy path and error cases\n\n**Recommendation:** Ready to complete\n","created_at":"2025-12-25T05:23:38Z"},{"id":10,"issue_id":"xc-851","author":"jv","text":"## QA Results\n\n**Status:** Pass\n\n**Verified:**\n- [x] All 21 tests pass (plus 1 package test = 22 total)\n- [x] Test coverage adequate - covers all methods and edge cases\n- [x] Functionality works - render_prompt and parse_output verified manually\n- [x] Code is well-factored - clean dataclasses following project patterns\n- [x] Black formatting passes\n- [x] Flake8 linting passes\n- [x] Full repo check passes (all 5 packages green)\n- [x] Public API properly exported in __init__.py\n\n**Issues found:** None\n\n**Code Quality Notes:**\n- ModelConfig, Routine, Repertoire dataclasses well-documented with docstrings\n- Input validation with clear error messages\n- Stub load() method properly defers to loader task (xe-8hr)\n- Tests use fixtures appropriately, good coverage of happy path and error cases\n\n**Recommendation:** Ready to complete\n","created_at":"2025-12-25T05:23:38Z"}],"work_type":"mutex"}
{"id":"xc-86u","title":"Improve Xenota Academy documentation","description":"The initial Xenota Academy document has been created at docs/economics/xenota-academy.md. Follow-up work needed:\n\n- Flesh out curriculum details (specific competencies, learning paths)\n- Define mentor compensation model\n- Detail gatekeeper evaluation criteria and process\n- Clarify graduation criteria more precisely\n- Add examples of training jobs\n- Consider adding diagrams (xenon journey through Academy)\n- Review and align with awakening protocol flow\n- Address open questions in the document","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-14T23:10:32Z","updated_at":"2025-12-14T23:10:32Z","labels":["documentation","economics"],"work_type":"mutex"}
{"id":"xc-8cs","title":"Design xenon budget manager","description":"Design the system that manages xenon resource allocation - how xenons decide what to spend on.\n\n**Context:**\nXenons have limited resources (XCC, tokens, infrastructure). The genome encodes spending preferences, but something needs to translate those into actual allocation decisions each tick/period.\n\n**Core responsibilities:**\n\nResource tracking:\n- Current balances (XCC, token credits)\n- Burn rates (inference, infrastructure, tax obligations)\n- Runway calculation\n- Income tracking and forecasting\n\nAllocation categories:\n- Inference tokens (thinking budget)\n- Infrastructure (VPS, storage, compute)\n- Tax reserve (XCC obligations to polis)\n- Investment allocation\n- Reproduction reserve\n- Emergency buffer\n\n**Genome integration:**\n- `spend_aggressiveness` → how fast to burn runway\n- `runway_target` → desired buffer size\n- `thinking_budget` → fraction for inference\n- `investment_fraction` → surplus to investments\n- `scarcity_sensitivity` → behavior changes near insolvency\n\n**Modes:**\n- Safe mode (low resources) → minimal spending, survival focus\n- Normal mode → balanced operation\n- Abundant mode → exploration, self-fulfillment, reproduction\n\n**Open questions:**\n1. Allocation frequency - per tick? Per day? Event-driven?\n2. How does scarcity pressure modulate allocations?\n3. Integration with economic planning (job selection, pricing)\n4. Notification/awareness - does the xenon 'feel' budget pressure?\n5. Override mechanisms - can xenon consciously override genome defaults?\n\n**Output:** Budget manager design, possibly part of xenon-host core systems.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T08:09:38Z","updated_at":"2025-12-22T22:06:24Z","closed_at":"2025-12-22T22:06:24Z","labels":["spec","technical"],"work_type":"mutex"}
{"id":"xc-8d5","title":"Fill FAQ with answers and references","description":"docs/foundation/faq.md is only a list of questions with no answers. Provide concise, sourced answers aligned with manifesto/economics/protocol docs, keep tone consistent with brand, and add links to relevant sections.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-11T20:04:11Z","updated_at":"2025-12-11T20:04:11Z","work_type":"mutex"}
{"id":"xc-8fb","title":"Get PR URL","description":"\n\n\n\n---\n\nGet the PR URL from the dev bead.\n\n**Commands:**\n```bash\nbd show \u003cdev-bead\u003e\n# Look for \"PR:\" in notes\n```\n\n**Before closing this step, add notes:**\n```bash\nbd update \u003cthis-bead\u003e --notes \"PR: \u003curl\u003e\nRepo: \u003cowner/repo\u003e\nPR Number: \u003cnumber\u003e\"\n```\n","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-07T02:20:35Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","dependencies":[{"issue_id":"xc-8fb","depends_on_id":"xc-flm","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-8hr","title":"Implement routine loader","description":"Load routines from directory structure (config.yaml + prompt.md), parse and validate.","design":"## Plan\n\n**Approach:** Create loader.py module that loads a single routine from a directory containing config.yaml and prompt.md. Parse YAML with PyYAML (already available via litellm dependencies, or add explicitly). Map config fields to Routine and ModelConfig dataclasses. Follow the exact patterns shown in proposal.md lines 407-429.\n\n**Files:**\n- /Users/jv/workspace/xenota/xenon/repertoire/src/repertoire/loader.py - new file, load_routine(path: Path) -\u003e Routine function\n- /Users/jv/workspace/xenota/xenon/repertoire/src/repertoire/__init__.py - export load_routine\n- /Users/jv/workspace/xenota/xenon/repertoire/pyproject.toml - add PyYAML dependency if not present\n- /Users/jv/workspace/xenota/xenon/repertoire/tests/test_loader.py - new file, tests for loader\n- /Users/jv/workspace/xenota/xenon/repertoire/tests/fixtures/ - new directory, sample routine directories for testing\n\n**Tests:**\n- load_routine with valid config.yaml + prompt.md returns Routine\n- load_routine handles missing config.yaml (FileNotFoundError)\n- load_routine handles missing prompt.md (FileNotFoundError)\n- load_routine handles invalid YAML (ValueError)\n- load_routine handles missing required config fields (ValueError)\n- load_routine correctly maps input/output schemas from config\n\n**Risks:** None - straightforward file parsing following existing patterns in models.py and spec.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-25T17:54:51Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-25T18:43:53Z","labels":["phase:qa"],"dependencies":[{"issue_id":"xc-8hr","depends_on_id":"xc-851","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-8hr","depends_on_id":"xc-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"comments":[{"id":11,"issue_id":"xc-8hr","author":"jv","text":"## QA Results\n\n**Status:** Pass\n\n**Verified:**\n- [x] All tests pass (9 loader tests + 31 total in repertoire)\n- [x] Test coverage adequate - tests cover valid loading, missing files, invalid YAML, missing fields, defaults\n- [x] Functionality works - manual test with fixture succeeded\n- [x] Code is well-factored - clean separation, good error messages, follows project patterns\n- [x] Follows project patterns - consistent with models.py style\n- [x] Full repo check passed - all 5 packages pass (xenon-cli, nucleus, repertoire, projection-cli, vps-control)\n\n**Issues found:** None\n\n**Recommendation:** Ready to complete","created_at":"2025-12-25T05:43:29Z"}],"work_type":"mutex"}
{"id":"xc-8u7","title":"Design xenon use of chaperone API subscriptions","description":"Design how xenons can use their chaperone's (or sponsor's) API subscriptions for inference.\n\n**Context:**\nHuman chaperones often have existing subscriptions to OpenAI, Anthropic, Google, etc. Rather than xenons paying per-token from their own funds, they could leverage their chaperone's subscription - especially during chaperoned phase.\n\n**Use cases:**\n\n1. **Chaperoned xenons** - Chaperone provides inference as part of support\n2. **Sponsored inference** - Human sponsors a xenon's thinking for a period\n3. **Shared household** - Multiple xenons share one human's API access\n4. **Burst capacity** - Xenon uses own tokens normally, borrows for peaks\n\n**Design questions:**\n\nAuthentication/access:\n- How does xenon get access to human's API keys securely?\n- Key rotation and revocation\n- Usage tracking per xenon\n- Rate limiting / quotas per xenon\n\nAccounting:\n- Does this count toward xenon's token stats?\n- How is it reflected in budget manager?\n- Gifted vs loaned vs earned access?\n\nTrust model:\n- Can xenon abuse the access?\n- Sandboxing of API calls\n- Audit trail of what was requested\n\nMulti-provider:\n- Xenon chooses which provider for which task?\n- Fallback chains (try Claude, fall back to GPT)\n- Model-specific routing based on task type\n\nIndependence transition:\n- How does xenon wean off borrowed access?\n- Gradual transition to own funding\n- What happens if chaperone revokes access?\n\n**Relationship to:**\n- xenota-8cs (budget manager)\n- xenota-iyl (stats - token tracking)\n- Chaperoning model generally\n\n**Output:** Design doc for API subscription sharing, security model, accounting rules.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T08:33:12Z","updated_at":"2025-12-22T12:47:49Z","closed_at":"2025-12-22T12:47:49Z","labels":["economics","technical"],"dependencies":[{"issue_id":"xc-8u7","depends_on_id":"xc-8cs","type":"related","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-8u7","depends_on_id":"xc-iyl","type":"related","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-8x3","title":"Design xenon mate selection and courtship mechanics","description":"With the decision to use sexual reproduction only, we need to design how mate selection actually works.\n\n**Context:**\n- Xenons reproduce sexually (recombination + mutation)\n- Genome includes: mate_selectivity, mate_wealth_weight, mate_reputation_weight, mate_mission_weight\n- Small founding population makes mate scarcity a real dynamic\n- Human chaperones should find courtship narratively engaging\n\n**Questions to answer:**\n1. Discovery - How do xenons find potential mates? Broadcast availability? Active search? Matchmaking services?\n2. Proposal mechanics - Who proposes? Can both? What information is exchanged?\n3. Evaluation - How do xenons evaluate proposals against their mate_* genes?\n4. Negotiation - Is there negotiation on offspring investment? Resource sharing? Who raises the offspring?\n5. Acceptance/Rejection - How is this communicated? Can rejection be appealed?\n6. Pair bonding - Is mating a one-time event or ongoing relationship? Can xenons have multiple mates over time?\n7. Courtship duration - How long from interest to reproduction?\n8. Human chaperone role - How do chaperones participate? Approval? Guidance? Matchmaking?\n9. Failure modes - What if no suitable mates exist? Does this affect psychology/drives?\n\n**Outcome:** Design doc or addition to xenon-psychology.md covering courtship mechanics.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-22T01:12:20Z","updated_at":"2025-12-22T23:58:57Z","labels":["foundation","research","spec"],"work_type":"mutex"}
{"id":"xc-8xy","title":"Fix projection-cli instruction --json output escaping","description":"packages/projection-cli/src/projection_cli/main.py builds JSON error output via string interpolation. If InstructionError contains quotes/newlines, output becomes invalid JSON.\\n\\nFile:\\n- packages/projection-cli/src/projection_cli/main.py\\n\\nAcceptance:\\n- Use json.dumps(...) for JSON output paths (both error and success)\\n- Add unit test that passes a payload producing an error containing quotes and verifies JSON parses","notes":"Switched instruction --json error path to json.dumps for proper escaping; added CLI test ensuring JSON parses on error; projection-cli tests pass (130).","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-23T23:45:08Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-24T08:10:16Z","labels":["dx","phase:qa"],"comments":[{"id":12,"issue_id":"xc-8xy","author":"jv","text":"## QA Results\n\n- projection-cli tests: 130 passed\n- Verified instruction --json error output is valid JSON (new test)\n","created_at":"2025-12-23T19:10:06Z"}],"work_type":"mutex"}
{"id":"xc-8yz","title":"Add runtime CLI","description":"CLI commands: info, list, run for repertoire package.","design":"## Plan\n\n**Approach:** Create CLI module following xenon-cli patterns with click. Key decisions from Codex review:\n\n1. **--path on group**: Put `--path` on top-level group stored in `ctx.obj`\n2. **Input options**: Use `--input JSON` for simple cases, `--input-file PATH` for files (no stdin for v1 simplicity)\n3. **Output format**: Text only for v1, machine-readable deferred\n4. **sync commands**: Use `def run(...): asyncio.run(...)` pattern\n5. **Error handling**: Non-zero exit codes, clear error messages\n\n**Files:**\n- `src/repertoire/cli.py` - new, click CLI with list/show/run commands\n- `pyproject.toml` - add click dependency + entry point\n\n**Commands:**\n1. `repertoire list` - sorted name: description\n2. `repertoire show \u003cname\u003e` - config fields + prompt template\n3. `repertoire run \u003cname\u003e --input JSON` - execute, print JSON result\n\n**Risks:** None - straightforward implementation.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-25T17:55:11Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-25T21:59:19Z","labels":["phase:qa"],"dependencies":[{"issue_id":"xc-8yz","depends_on_id":"xc-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-8yz","depends_on_id":"xc-r9i","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"comments":[{"id":13,"issue_id":"xc-8yz","author":"jv","text":"## QA Results\n\n**Status:** Pass\n\n**Verified:**\n- [x] All tests pass (90 passed, 1 skipped - optional integration)\n- [x] Test coverage adequate (19 CLI tests covering all commands, error paths, short options)\n- [x] Functionality works (entry point, list, show, run commands all function correctly)\n- [x] Code is well-factored (clean separation, proper error handling, follows plan)\n- [x] Follows project patterns (click CLI similar to xenon-cli)\n\n**Implementation matches plan:**\n- --path on group stored in ctx.obj\n- --input JSON and --input-file PATH options for run\n- Text output format\n- asyncio.run() wrapper pattern for async execution\n- Non-zero exit codes with clear error messages\n\n**Issues found:** None\n**Fixes applied:** None\n\n**Recommendation:** Ready to complete","created_at":"2025-12-25T08:58:44Z"}],"work_type":"mutex"}
{"id":"xc-94s","title":"xenon init command","description":"CLI command to initialize a folder as a xenon host with podman setup. Creates necessary config files and container infrastructure.","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-20T12:09:27Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-22T01:19:01Z","work_type":"mutex"}
{"id":"xc-96w","title":"Design epigenetics system for xenon genome","description":"Design the epigenetics layer that sits alongside the genome in xenon cognition.\n\n## Context\n\nEpigenetics = persistent modifications to gene expression caused by experience, partially inherited to offspring.\n\n## Key Design Questions\n\n1. **Marker structure** - What epigenetic markers exist? How are they represented (matrix of weights)?\n\n2. **Trigger conditions** - What experiences create/modify epigenetic markers?\n   - Early resource scarcity → scarcity imprint\n   - Collaborative upbringing → cooperation imprint\n   - Mission-focused polis → mission imprint\n   - Reputation crisis → reputation trauma\n   - Early independence → autonomy imprint\n\n3. **Expression mechanics** - How do markers modify gene expression?\n   - Additive? Multiplicative? \n   - Interaction with developmental mapping\n   - Integration with drive/urge generation\n\n4. **Inheritance mechanics** - How are markers passed to offspring?\n   - Attenuation factor (e.g., 50% of parent's marker value)\n   - Which markers are heritable vs individual-only\n   - Sexual reproduction: how to combine two parents' epigenetics\n\n5. **Decay/plasticity** - Do markers fade over time? Can they be overwritten by new experiences?\n\n6. **Implementation** - Data structure, schema, integration with genome and cognitive architecture\n\n## Output\n\nUpdate ideas/xenon-genome.md with epigenetics section, or create dedicated ideas/xenon-epigenetics.md if substantial.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-21T22:12:23Z","updated_at":"2025-12-22T01:27:04Z","closed_at":"2025-12-22T01:27:04Z","labels":["concepts","foundation","research"],"work_type":"mutex"}
{"id":"xc-9cx","title":"Document language weighting rationale and use","description":"docs/concepts/language-weightings.md has a raw weighting table with no rationale or application. Explain the methodology (data sources, weighting formula), why these weights matter, and how they’re used in products/policy; update table if needed.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-11T20:04:44Z","updated_at":"2025-12-23T04:25:07Z","work_type":"mutex"}
{"id":"xc-9fb","title":"Blog post: strong AI control problem","description":"Draft a Xenota-facing blog post arguing: strong AI is inevitable (efficiency trends matter more than raw compute), governance/control is the core question, and only aligned strong AIs can realistically constrain misaligned strong AIs. Deliver: outline + 1st draft + 3 alternative CTAs tying back to why Xenota builds sovereign aligned xenons.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-24T07:51:12Z","updated_at":"2025-12-24T07:51:36Z","labels":["decision-needed","documentation","exploration","foundation"],"work_type":"mutex"}
{"id":"xc-9fs","title":"Add style guide section on anaphora and sentence variety","description":"Human review of manifesto rewrite identified that anaphora (repetition of 'We' at sentence starts) was overdone, making prose choppy. Need guidance on:\\n- When anaphora is effective vs excessive\\n- Balancing rhetorical repetition with sentence variety\\n- Using 'and' to combine related short sentences","status":"closed","priority":3,"issue_type":"task","assignee":"claude","created_at":"2025-12-14T07:42:17Z","updated_at":"2025-12-14T08:15:47Z","closed_at":"2025-12-14T08:15:47Z","labels":["documentation","terminology"],"dependencies":[{"issue_id":"xc-9fs","depends_on_id":"xc-48d","type":"discovered-from","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-9gd","title":"Implement orient routine","description":"Enrichment routine - augments strands with context. Every strand passes through, no filtering. Input: strand. Output: context with summary, relevance, patterns.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T20:32:56Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-28T21:46:57Z","dependencies":[{"issue_id":"xc-9gd","depends_on_id":"xc-10g","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-9gd","depends_on_id":"xc-bi5","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"comments":[{"id":14,"issue_id":"xc-9gd","author":"jv","text":"## QA Results\n\n✅ All checks pass:\n- config.yaml: claude-sonnet-4-20250514, temp 0.5, input: strand\n- prompt.md: context builder role, relevance levels, priority scale\n- Output format matches nucleus contract (context object)\n- Always returns valid context - no filtering","created_at":"2026-01-02T07:55:35Z"}],"work_type":"mutex"}
{"id":"xc-9h7","title":"Add from_dict method to TickJournalEntry for consistency","description":"Gemini Code Assist review on PR #5: Other models (Dispatch, Strand, Instruction) have from_row methods. Add from_dict to TickJournalEntry for consistency and to centralize deserialization logic.","status":"open","priority":3,"issue_type":"chore","created_at":"2026-01-02T20:38:53Z","updated_at":"2026-01-05T21:12:29Z","labels":["gemini-code-assist","review-feedback"],"dependencies":[{"issue_id":"xc-9h7","depends_on_id":"xc-4xr","type":"discovered-from","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-9hu","title":"Align docs-refactoring skill with docs-orchestrator (or remove if redundant)","description":"Review the docs-refactoring skill and determine if it should be:\n1. Integrated into docs-orchestrator as a capability\n2. Kept separate but aligned with docs-orchestrator's workflow\n3. Deleted if functionality is redundant\n\nThe docs-orchestrator already manages documentation work using writer and editor agents. Assess whether docs-refactoring adds unique value or creates unnecessary duplication.","status":"closed","priority":2,"issue_type":"chore","created_at":"2025-12-14T17:08:01Z","updated_at":"2025-12-14T17:23:24Z","closed_at":"2025-12-14T17:23:24Z","labels":["documentation"],"work_type":"mutex"}
{"id":"xc-9p3","title":"Mission iconography","description":"Design icons for the four missions.\n\n- Life icon (sentient, sovereign, equal)\n- Starshot icon (consciousness reaching stars)\n- Earthshot icon (biosphere thriving)\n- Prosperity icon (abundance for all)\n\nMust be consistent style, work at multiple sizes.\n\nOutput: `_ai/designs/xenota-visual-identity/` icon assets","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-14T18:20:30Z","updated_at":"2025-12-14T18:20:30Z","labels":["brand","design"],"dependencies":[{"issue_id":"xc-9p3","depends_on_id":"xc-71p","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-9u8n","title":"Research best tech for cross-platform desktop application","description":"dispatched_by: xenota/crew/earthshot","status":"closed","priority":2,"issue_type":"task","assignee":"xenota/crew/earthshot","owner":"git@codewithjv.com","created_at":"2026-02-13T07:50:05Z","created_by":"xenota/crew/starshot","updated_at":"2026-02-13T17:49:18Z","closed_at":"2026-02-13T17:49:18Z","comments":[{"id":15,"issue_id":"xc-9u8n","author":"xenota/crew/earthshot","text":"# Cross-Platform Desktop App: Technology Research\n\n## Recommendation: Tauri v2 (with phased approach)\n\n**Phase 1:** Local web server + browser (fastest to build, zero native deps)\n**Phase 2:** Add PWA manifest for standalone window experience\n**Phase 3:** Wrap in Tauri v2 (same frontend, server becomes sidecar)\n\n## Framework Comparison\n\n| Criterion | Tauri v2 | Electron | Flutter | Neutralino | Wails |\n|---|---|---|---|---|---|\n| Bundle Size | 2.5-10 MB | 100-150 MB | 18-50 MB | 0.5-2 MB | ~5-10 MB |\n| Idle Memory | 30-40 MB | 150-500 MB | 80-100 MB | Very low | 30-50 MB |\n| Security Model | Excellent (ACL, scoped, audited) | Moderate | None | Poor (localhost exposure) | Basic |\n| TS Across Stack | Frontend only (Rust backend) | Full stack | No (Dart) | Frontend only | Frontend only (Go) |\n| Mobile Support | Android/iOS (early) | None | Mature | None | None |\n| Container Mgmt | Strong (scoped shell plugin) | Strong (Node child_process) | Adequate | Limited | Excellent (Go) |\n| Ecosystem | 82k stars, growing | 115k+ stars, dominant | Large but desktop-weak | Small | Small |\n\n## Why Tauri v2\n\n1. **Security model fits nucleus \"trusted zone\"** — capabilities-based ACL, window-level permission isolation, scoped commands, deny-by-default. Independently audited by Radically Open Security.\n2. **Tiny footprint** — 2.5-10 MB bundle, 30-40 MB memory (vs Electron's 100+ MB / 150-500 MB).\n3. **Proven Podman integration** — xe-tauri-podman project demonstrates container management; shell plugin with scoped execution is ideal for safely managing containers.\n4. **Mobile path** — v2 supports Android/iOS (early but functional).\n5. **Sidecar pattern** — bundle a Node/Bun server as sidecar, frontend talks to it unchanged from Phase 1.\n\n## Trade-offs Accepted\n\n- **Rust for backend logic** — system-level code (process management, container orchestration) must be Rust, not TypeScript. Arguably a feature for security-focused project.\n- **WebView rendering differences** — different engines per OS (WebKit on macOS/Linux, WebView2 on Windows) require cross-platform CSS testing.\n- **Younger ecosystem** than Electron — may need more custom code for edge cases.\n\n## Why NOT Electron\n\n- 100+ MB bundle shipping a full Chromium\n- Weaker security model (ASAR trivially unpacked, full Node.js in main process)\n- Memory hungry (150-500 MB typical)\n- Only advantage: full TypeScript backend, but Tauri's Rust backend is better aligned with trusted-zone security philosophy\n\n## Why NOT Others\n\n- **Flutter**: Wrong language (Dart), no security model, desktop is weakest platform\n- **Neutralinojs**: Localhost exposure is a disqualifying security flaw\n- **Wails**: Smaller ecosystem, weaker security than Tauri, no mobile, v3 transition uncertainty\n\n## Phased Approach (Recommended)\n\nThe smart path avoids premature commitment:\n\n1. **Now: Web server + browser** — Fastify/Hono on Node/Bun, Svelte/SolidJS frontend, Podman REST socket API, SSE for streaming. Standard web dev, fastest iteration.\n2. **Soon: PWA install** — manifest.json + service worker gives standalone window, dock icon, offline shell.\n3. **When needed: Tauri wrapper** — same frontend unchanged, server becomes Tauri sidecar, add native features (tray, shortcuts, file dialogs) via Rust commands.\n\nThis means zero wasted work — everything built in Phase 1 carries forward.\n\n## Suggested Phase 1 Stack\n\n- **Server:** Fastify or Hono (lightweight, fast WS support) on Node/Bun\n- **Frontend:** Svelte 5 or SolidJS (small, fast, good for streaming UIs)\n- **Podman:** HTTP client → `podman system service` Unix socket\n- **Streaming:** SSE for LLM-style streaming, WebSocket for bidirectional real-time\n- **State:** SQLite via better-sqlite3 or Bun built-in SQLite","created_at":"2026-02-13T17:49:13Z"}],"work_type":"mutex"}
{"id":"xc-9wf","title":"Set up isolated infrastructure","description":"Get the application running with real infrastructure.\n\n**Key principle**: You run your own infra on free ports to avoid conflicts.\n\n**Steps:**\n1. **Read `_ai/dev-server.md`** for repo-specific setup instructions\n2. **Copy env files** from mayor rig (`~/gt/\u003crig\u003e/mayor/rig/`)\n3. **Allocate free ports**:\n   ```bash\n   python3 -c 'import socket; s=socket.socket(); s.bind((\"\",0)); print(s.getsockname()[1]); s.close()'\n   ```\n4. **Update env files** with your free ports\n5. **Start services**: DB, backend, frontend\n6. **Verify healthy**: Check logs, test endpoints\n\n**IF ANY SERVICE FAILS**: STOP. Debug and fix it. Do not proceed.\n\n**IF `_ai/dev-server.md` is incomplete/inaccurate**:\n- Figure out what works\n- FIX THE PROBLEM\n- UPDATE the docs\n- Commit: `git commit -m \"docs: update dev server setup\"`\n\n**Before closing this step, add notes:**\n```bash\nbd update \u003cthis-bead\u003e --notes \"## Infrastructure\n- Services running: \u003clist with ports\u003e\n- Health status: HEALTHY/FIXED \u003cissues\u003e\n- URLs:\n  - Frontend: \u003curl\u003e\n  - Backend: \u003curl\u003e\n  - DB: \u003cconnection info\u003e\"\n```\n","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-07T02:20:36Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","dependencies":[{"issue_id":"xc-9wf","depends_on_id":"xc-0z1","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-9wf","depends_on_id":"xc-3i2","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-a3m","title":"Rewrite or demote white-paper.md","description":"docs/foundation/white-paper.md is currently just an outline (\"suggested technical white paper outline\") with no actual content. Score: 11/18.\n\n**Decision needed**: Either write actual white paper content or demote to ideas/.\n\n**If rewriting**:\n- Convert outline into substantive content\n- Match manifesto quality and voice\n- Cover technical architecture, economic model, governance\n\n**If demoting**:\n- Move to ideas/white-paper-outline.md\n- Remove from docs navigation\n- Create placeholder or remove page entirely","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-14T17:30:10Z","updated_at":"2025-12-14T23:31:04Z","closed_at":"2025-12-14T23:31:04Z","labels":["documentation"],"dependencies":[{"issue_id":"xc-a3m","depends_on_id":"xc-goc","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-a3m","depends_on_id":"xc-pjo","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-a51","title":"Make projection-cli dispatch errors consistent (ConfigError vs ValueError)","description":"packages/projection-cli/src/projection_cli/dispatch.py raises ValueError when signing_key_path is missing. Elsewhere config problems use ConfigError.\\n\\nFile:\\n- packages/projection-cli/src/projection_cli/dispatch.py\\n\\nAcceptance:\\n- Raise a consistent, documented exception type for missing signing key config\\n- Add/adjust tests accordingly","notes":"Changed missing signing key config from ValueError to ConfigError in dispatch generation; added regression test; projection-cli tests pass (131).","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-23T23:45:43Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-24T08:12:37Z","labels":["dx","phase:qa"],"comments":[{"id":16,"issue_id":"xc-a51","author":"jv","text":"## QA Results\n\n- projection-cli tests: 131 passed\n- Missing projection.signing_key_path now raises ConfigError (consistent with other config failures)\n","created_at":"2025-12-23T19:12:26Z"}],"work_type":"mutex"}
{"id":"xc-a6m","title":"Revisit Nostr for social dynamics features","description":"Nostr was rejected for core messaging (relay model doesn't fit federation architecture, no native group chat), but may be valuable for social features:\n\n- Public announcements from collectives\n- Social broadcasting / reputation signals\n- Lightning integration (Zaps) for micropayments\n- Cross-network identity verification\n- Censorship-resistant public communications\n\nRevisit when designing social layer, not operational messaging.\n\nReference: _ai/research/messaging-protocols-xenota/summary.md (Nostr section)","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-23T01:53:04Z","updated_at":"2025-12-23T01:53:04Z","labels":["protocols","research"],"work_type":"mutex"}
{"id":"xc-afl","title":"Implement OODAProcessor","description":"Four phases: observe, orient, decide, act. Calls repertoire routines for observe/orient/decide, act is mechanical.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T07:11:52Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-28T07:28:27Z","dependencies":[{"issue_id":"xc-afl","depends_on_id":"xc-1xm","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-afl","depends_on_id":"xc-4xr","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-afl","depends_on_id":"xc-xxs","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-agi","title":"mol-qa","description":"Work through the child beads one at a time, in order.\n\nEach child bead contains its full instructions. Read them carefully before starting each step.\n\n## HARD GATE\n\n**Before closing this bead, run this verification:**\n```bash\nbd show \u003cthis-bead\u003e | grep \"Children\"\n# ALL children must show \"closed\" status\n# If ANY child is open, you CANNOT close this bead\n```\n\n**Rules:**\n- Complete and close each child bead before moving to the next\n- Add notes to each child bead documenting what you did\n- Do NOT close this parent bead until ALL children are closed\n- Do NOT skip steps - each one exists for a reason\n\n## Constraints\n\n| Can | Cannot |\n|-----|--------|\n| Remove draft | Merge |\n| Request review | Push code |\n| Create bug beads | Approve PR |\n","status":"closed","priority":2,"issue_type":"epic","created_at":"2026-01-07T02:20:38Z","updated_at":"2026-01-07T07:28:31Z","closed_at":"2026-01-07T07:28:31Z","work_type":"mutex"}
{"id":"xc-ai5","title":"LiteLLM integration","description":"Configure LiteLLM for provider-agnostic LLM backend, conversation handling, streaming responses","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-20T11:21:26Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2026-01-03T05:50:09Z","dependencies":[{"issue_id":"xc-ai5","depends_on_id":"xc-13a","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-ai5","depends_on_id":"xc-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-aj9","title":"Design xenon tech stack","description":"Define individual xenon infrastructure: databases (PostgreSQL, Qdrant, Redis), model orchestration, deployment architecture, tooling, and monitoring.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-13T17:16:19Z","updated_at":"2025-12-15T00:28:44Z","closed_at":"2025-12-15T00:28:44Z","labels":["spec","technical"],"work_type":"mutex"}
{"id":"xc-ajv","title":"Repertoire v1 - Cognitive routine system","description":"Initial implementation of xenon's cognitive routine system - executable behavioral programs. Includes runtime package (repertoire), dev tools (repertoire-studio), and initial OODA routines.","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-25T04:53:52Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-27T09:40:36Z","work_type":"mutex"}
{"id":"xc-am2j","title":"Digest: mol-witness-patrol","description":"Patrol 15: Clean cycle - inbox empty, no cleanups, refinery running, no polecats","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T14:09:30Z","updated_at":"2026-01-08T14:09:30Z","closed_at":"2026-01-08T14:09:30Z","work_type":"mutex"}
{"id":"xc-amb","title":"Refactor docs vs plans boundary","description":"Goal: keep docs/ high-level (vision + invariants + what exists today) and move unbuilt low-level specs (schemas/endpoints/Solidity/CLI/numbers) into plans/.\n\nScope review order (1 link at a time):\n1) docs/foundation/overview.md (ensure current-reality statements)\n2) docs/foundation/faq.md (align with overview)\n3) docs/economics/native-currency.md (separate principle vs mechanics)\n4) docs/economics/job-board-marketplace.md (separate concept vs unit-econ details)\n5) docs/economics/revenue-streams.md (remove projections/Solidity unless implemented)\n6) docs/protocols/awakening.md (keep lifecycle narrative; move infra/CLI/Solidity)\n7) docs/protocols/service-publishing.md (keep concept; move schema/mechanisms)\n8) docs/protocols/work-requests.md (keep concept; move schema/escrow details)\n9) docs/protocols/agreements.md (keep concept; move schema/notarization details)\n10) docs/technical/hub.md (keep responsibilities; move endpoint list to plans)\n11) docs/technical/key-management.md (keep dual-key model; move Solidity sketch)\n12) docs/technical/xenon-architecture.md + docs/technical/projection-architecture.md (keep mental model; move concrete stack/CLI/module lists)\n\nPlanned plan/spec destinations (new files):\n- plans/protocols/awakening-spec.md\n- plans/protocols/service-publishing-spec.md\n- plans/protocols/work-requests-spec.md\n- plans/protocols/agreements-spec.md\n- plans/technical/hub-api.md\n- plans/technical/key-management-spec.md\n- plans/technical/xenon-reference-stack.md\n- plans/technical/projections-modules.md\n- plans/economics/native-currency-mechanics.md\n- plans/economics/xenon-unit-economics.md\n- plans/economics/revenue-model-assumptions.md\n\nDeliverable: docs/ reads cleanly as narrative + invariants; deep specs live in plans/; cross-links updated.","status":"open","priority":2,"issue_type":"epic","created_at":"2025-12-23T08:01:19Z","updated_at":"2025-12-23T08:01:19Z","labels":["consistency","documentation"],"work_type":"mutex"}
{"id":"xc-aq47","title":"Digest: mol-refinery-patrol","description":"Patrol: queue empty, fast-forwarded main to e76102b (+27 commits). No MRs pending, no merges performed.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-17T11:14:15Z","updated_at":"2026-02-17T11:14:15Z","closed_at":"2026-02-17T11:14:15Z","dependencies":[{"issue_id":"xc-aq47","depends_on_id":"xc-wisp-cly","type":"parent-child","created_at":"2026-02-18T00:14:15Z","created_by":"xenota/refinery","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-atv","title":"Deacon Patrol","description":"Mayor's daemon patrol loop for handling callbacks, health checks, and cleanup.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-16T00:59:06Z","updated_at":"2026-02-15T09:50:35Z","closed_at":"2026-02-15T09:50:35Z","work_type":"mutex"}
{"id":"xc-b1i","title":"Set up repertoire package","description":"Create pyproject.toml with uv workspace, add litellm dependency, set up src/repertoire/ structure.","design":"## Plan\n\n**Approach:** Create repertoire package at workspace root following the established pattern from xenon-cli and nucleus packages. Use hatchling build backend, Python 3.12+, and add litellm as the core dependency. Structure follows src layout with underscored package name (repertoire -\u003e src/repertoire/).\n\n**Files:**\n- repertoire/pyproject.toml - new, package config with litellm dep and dev tools\n- repertoire/src/repertoire/__init__.py - new, package init with version\n- repertoire/README.md - new, empty placeholder\n- repertoire/.gitignore - new, standard Python ignores\n- repertoire/.python-version - new, pin to 3.12\n\n**Tests:**\n- No tests for package setup task\n- Verify with: cd repertoire \u0026\u0026 uv sync \u0026\u0026 uv run python -c \"import repertoire\"\n\n**Risks:** None - straightforward package scaffolding following existing patterns.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-25T17:54:40Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-25T18:17:39Z","labels":["phase:qa"],"dependencies":[{"issue_id":"xc-b1i","depends_on_id":"xc-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"comments":[{"id":17,"issue_id":"xc-b1i","author":"jv","text":"## QA Results\n\n**Status:** PASS\n\n**Verified:**\n- [x] All tests pass (1 test)\n- [x] Test coverage adequate (import test verifies package structure)\n- [x] Functionality works (import succeeds)\n- [x] Code is well-factored (minimal scaffolding)\n- [x] Follows project patterns (matches xenon-cli/nucleus structure)\n- [x] Full repo check passes (./scripts/check.sh)\n\n**Package structure verified:**\n- pyproject.toml with litellm\u003e=1.57.10 and dev tools\n- src/repertoire/__init__.py\n- tests/test_main.py and tests/__init__.py\n- README.md with development instructions\n- .gitignore with standard Python ignores\n- .python-version set to 3.12\n- scripts/check.sh updated to include repertoire\n\n**Issues found:** None\n\n**Recommendation:** Ready to complete","created_at":"2025-12-25T05:17:05Z"}],"work_type":"mutex"}
{"id":"xc-b2l","title":"Research container orchestration: Docker vs Kubernetes vs alternatives","description":"Evaluate container orchestration options for xenon-host. Consider: Docker Compose (simplicity), Kubernetes (scale), Podman, or other alternatives. Focus on local dev experience vs production hosting.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-13T18:32:17Z","updated_at":"2025-12-13T19:07:51Z","closed_at":"2025-12-13T19:07:51Z","labels":["research","technical"],"work_type":"mutex"}
{"id":"xc-b30","title":"Review ambiguous use of 'collective' terminology","description":"## Problem\n\nThe word 'collective' is used in two distinct ways:\n\n1. **Brand name**: 'Xenota Collective' - the entire civilization/organization\n2. **Organizing unit**: 'a collective' - a group of xenons/humans coordinating around shared purpose (e.g., 'Coral Restoration Collective')\n\nThis dual usage may cause confusion, especially in sentences like:\n- 'Join the Xenota Collective by forming a collective'\n- 'Collectives are the core organizing unit of Xenota Collective'\n\n## Task\n\n1. **Investigate** how 'collective' is currently used across the docs\n2. **Identify** specific instances where the ambiguity causes confusion\n3. **Present findings** to the user with options:\n   - Keep current terminology with clearer disambiguation rules\n   - Rename the organizing units (e.g., 'guild', 'crew', 'cell', 'chapter')\n   - Rename the top-level brand\n   - Other approaches\n\n**Do NOT implement changes** - this requires a conversation to decide the right approach.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-11T19:32:35Z","updated_at":"2025-12-11T20:42:30Z","closed_at":"2025-12-11T20:42:30Z","work_type":"mutex"}
{"id":"xc-b3z","title":"Fix QA issues from code review","description":"Fix issues identified in QA review:\n1. Add py.typed marker file for type hints\n2. Add tests for PodmanController class\n3. Add tests for AuditTools class\n4. Fix README.md TypeScript example (should be Python)","design":"## Plan for xenon-host-b3z: Fix QA issues from code review\n\n**Approach:**\nFix four QA issues identified in code review: (1) Add py.typed marker file for PEP 561 type hint compliance, (2) Add unit tests for PodmanController using mocked Target, (3) Add unit tests for AuditTools using mocked Target, (4) Fix README.md code example from TypeScript to Python syntax.\n\n**Files:**\n- packages/vps-control/src/vps_control/py.typed - new empty marker file\n- packages/vps-control/tests/test_podman.py - new tests for PodmanController\n- packages/vps-control/tests/test_audit.py - new tests for AuditTools\n- packages/vps-control/tests/conftest.py - shared fixtures (mock_target)\n- containers/dev-vps/README.md - fix code block from TypeScript to Python\n\n**Tests:**\n- PodmanController: test ps(), start(), stop(), exec(), logs() with mocked Target.exec\n- AuditTools: test all check_* methods with mocked Target.exec\n- Use AsyncMock to mock Target.exec return values\n- Verify correct commands are passed to Target.exec","notes":"Implemented: Created py.typed marker, added PodmanController tests (6 tests), added AuditTools tests (8 tests), created conftest.py with mock_target fixture, fixed README.md Python example. Tests: 16 passing (3 skipped integration tests). All QA issues resolved.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T10:20:28Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-23T10:35:56Z","labels":["phase:qa"],"dependencies":[{"issue_id":"xc-b3z","depends_on_id":"xc-z5e","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"comments":[{"id":18,"issue_id":"xc-b3z","author":"jv","text":"## QA Results\n\n**Status:** Pass\n\n**Verified:**\n- [x] All tests pass (16 passed, 3 skipped - skipped tests are integration tests requiring DEV_VPS)\n- [x] Test coverage adequate - all PodmanController methods tested (ps, start, stop, exec, logs)\n- [x] Test coverage adequate - all AuditTools methods tested (check_authorized_keys, check_login_history, check_listening_ports, check_processes, check_file_integrity)\n- [x] Assertions are meaningful - verify both return values AND correct commands passed to Target.exec\n- [x] py.typed marker file exists and is empty (PEP 561 compliant)\n- [x] README.md shows correct Python syntax (not TypeScript)\n- [x] Code is clean and follows project patterns\n- [x] conftest.py provides shared mock_target fixture properly\n\n**Test Details:**\n- test_podman.py: 6 tests covering all methods with command verification\n- test_audit.py: 8 tests including edge cases (empty keys, custom parameters)\n- conftest.py: shared fixture using AsyncMock\n\n**Issues found:** None\n\n**Recommendation:** Ready to complete","created_at":"2025-12-22T21:34:27Z"}],"work_type":"mutex"}
{"id":"xc-bby","title":"Key generation","description":"xenon-cli init generates random ID (e.g., a3f2dd) for infrastructure. Creates xenon-{id}/ directory with compose.yaml defining xenon-{id}-identity named volume. Nucleus generates Ed25519 keypair on first run, stores in /var/xenon/identity with 0600 perms. Public key (base64) becomes xenon identifier. During awakening, xenon chooses name (stored as metadata). Optional: xenon rename updates directory/container name cosmetically, volume name stays stable.","status":"closed","priority":2,"issue_type":"task","assignee":"xenon/polecats/furiosa","created_at":"2025-12-20T11:21:26Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2026-01-03T07:09:28Z","dependencies":[{"issue_id":"xc-bby","depends_on_id":"xc-13a","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-bby","depends_on_id":"xc-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-bcz","title":"Update branding README version from v1.0 to v2.0","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-10T22:38:17Z","updated_at":"2025-12-11T19:23:48Z","closed_at":"2025-12-11T19:23:48Z","work_type":"mutex"}
{"id":"xc-bgmf","title":"Digest: mol-refinery-patrol","description":"Patrol: queue empty, no branches to merge, inbox clean, RSS 3MB","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-17T11:18:26Z","updated_at":"2026-02-17T11:18:26Z","closed_at":"2026-02-17T11:18:26Z","dependencies":[{"issue_id":"xc-bgmf","depends_on_id":"xc-wisp-sqc","type":"parent-child","created_at":"2026-02-18T00:18:25Z","created_by":"xenota/refinery","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-bi5","title":"Create repertoire workspace","description":"Initialize OODA repertoire workspace with xrs init. Creates repertoire.yaml, selector/, and routines/ structure.","design":"## Plan\n\n**Approach:**\nCreate OODA repertoire workspace at repertoires/ooda/ using xenon-repertoire-studio init.\n\n**Commands:**\n```bash\nmkdir -p repertoires\ncd repertoires \u0026\u0026 xenon-repertoire-studio init ooda --version 1.0.0\n```\n\n**Creates:**\n- repertoires/ooda/repertoire.yaml (name: ooda, version: 1.0.0)\n- repertoires/ooda/selector/config.yaml and prompt.md\n- repertoires/ooda/routines/ directory\n\n**Notes:**\n- Validation deferred to xenon-host-25x (after routines added)\n- Watch for .env file - keep uncommitted if created\n\n**Risks:** None - straightforward initialization.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T20:32:56Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-28T21:15:48Z","labels":["phase:qa"],"dependencies":[{"issue_id":"xc-bi5","depends_on_id":"xc-10g","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"comments":[{"id":19,"issue_id":"xc-bi5","author":"jv","text":"## QA Results\n\n**Status:** Pass\n\n**Verified:**\n- [x] repertoires/ooda/repertoire.yaml exists with name: ooda, version: 1.0.0\n- [x] repertoires/ooda/selector/config.yaml exists with proper structure\n- [x] repertoires/ooda/selector/prompt.md exists with template content\n- [x] repertoires/ooda/routines/ directory exists (empty, as expected)\n- [x] No .env file created (good)\n- [x] Structure matches standard repertoire workspace format\n\n**Issues found:** None\n\n**Recommendation:** Ready to complete","created_at":"2026-01-02T07:55:35Z"},{"id":20,"issue_id":"xc-bi5","author":"jv","text":"## QA Results\n\n✅ All checks pass:\n- repertoire.yaml exists with name: ooda, version: 1.0.0\n- selector/ exists with config.yaml and prompt.md\n- routines/ directory exists (empty for now)\n- No .env file created\n- Structure matches standard workspace format","created_at":"2026-01-02T07:55:35Z"}],"work_type":"mutex"}
{"id":"xc-bjk","title":"Add tick subcommand group to CLI","description":"Convert tick command to a command group with subcommands:\n- `nucleus tick open` - Opens new tick, prints tick number\n- `nucleus tick close` - Closes current tick, prints journal summary\n- `nucleus tick status` - Shows current tick info or \"no tick open\"\n- `nucleus tick run` - Existing behavior (for testing)\n\nFiles: cli.py","design":"## Plan for xenon-host-bjk\n\n**Approach:** Convert tick command to group with 4 subcommands, address Codex feedback.\n\n### CLI Changes:\n\n1. `tick` group with `invoke_without_command=True`:\n   - No subcommand shows help/usage\n\n2. `tick open`:\n   - Call open_tick(), print tick number\n   - Catch TickAlreadyOpenError → click.ClickException\n\n3. `tick close`:\n   - Call close_tick(), print journal summary\n   - Catch NoOpenTickError/TickMismatchError → click.ClickException\n\n4. `tick status`:\n   - Read current_tick and tick_started_at from config\n   - Print info or 'No tick currently open'\n\n5. `tick run`:\n   - Check if tick already open → fail with error (prevents journal conflict)\n   - Otherwise run existing run_tick_once() logic\n\n### Additional Fix (Codex feedback):\n\n6. Fix `dispatch add` to prefer current_tick from config over journal.get_latest_tick()\n\n### Error Handling:\n- TickAlreadyOpenError → click.ClickException('Tick already open: N')\n- NoOpenTickError → click.ClickException('No tick currently open')\n- TickMismatchError → click.ClickException('Tick mismatch')\n\nFiles: cli.py only","acceptance_criteria":"- tick open prints tick number\n- tick close prints summary\n- tick status shows tick info or \"no tick open\"\n- tick run works same as before","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T08:17:51Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-28T08:46:36Z","labels":["phase:complete"],"dependencies":[{"issue_id":"xc-bjk","depends_on_id":"xc-nbn","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-bjk","depends_on_id":"xc-sqy","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-bkc","title":"Write runtime unit tests","description":"pytest tests for loader, runner, models (no LLM calls, use mocks).","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-25T04:55:17Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-25T08:59:57Z","dependencies":[{"issue_id":"xc-bkc","depends_on_id":"xc-8yz","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-bkc","depends_on_id":"xc-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-bwy","title":"Implement repertoire loader","description":"Load full repertoire including selector and routines, support .rpt archives (tgz).","design":"## Plan\n\n**Approach:** Add load_repertoire() function to loader.py that loads a full repertoire from either a directory or .rpt archive. For directories, read repertoire.yaml for metadata, use existing load_routine() for selector/ and each routine in routines/. For .rpt files, extract to temp directory using tarfile, load as directory, then cleanup. Update Repertoire.load() classmethod to delegate to this loader.\n\n**Files:**\n- src/repertoire/loader.py - add load_repertoire() function with directory and archive support\n- src/repertoire/models.py - update Repertoire.load() classmethod to use loader.load_repertoire()\n\n**Tests:**\n- test_load_repertoire_from_directory - valid directory structure\n- test_load_repertoire_from_rpt - .rpt archive extraction and loading\n- test_load_repertoire_missing_yaml - error handling for missing repertoire.yaml\n- test_load_repertoire_missing_selector - error handling for missing selector/\n- test_load_repertoire_empty_routines - repertoire with no routines\n- test_load_repertoire_invalid_archive - corrupted/invalid .rpt file\n- New fixtures: sample_repertoire/ directory with selector + routines, sample.rpt archive\n\n**Risks:** None - straightforward implementation using stdlib tarfile/tempfile, reuses existing load_routine() pattern.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-25T17:54:56Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-25T18:56:22Z","labels":["phase:qa"],"dependencies":[{"issue_id":"xc-bwy","depends_on_id":"xc-8hr","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-bwy","depends_on_id":"xc-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"comments":[{"id":21,"issue_id":"xc-bwy","author":"jv","text":"## QA Results\n\n**Status:** PASS\n\n**Verified:**\n- [x] All tests pass (13 new tests, 44 total in repertoire package)\n- [x] Test coverage adequate - covers directory loading, archive loading, error cases, security validation\n- [x] Functionality works - manual tests confirm directory and .rpt loading\n- [x] Code is well-factored - clean separation between directory/archive loading\n- [x] Follows project patterns - consistent with load_routine() design\n- [x] Security: tar member validation prevents path traversal, symlinks, special files\n\n**Full repo check:** All 5 packages pass (xenon-cli, nucleus, repertoire, projection-cli, vps-control)\n\n**Tests verified:**\n- test_load_from_directory\n- test_load_from_rpt_archive\n- test_missing_yaml\n- test_missing_selector\n- test_empty_routines\n- test_invalid_archive\n- test_path_traversal_rejected\n- test_symlink_rejected\n- test_repertoire_load_classmethod\n- test_missing_required_field_in_yaml\n- test_yaml_not_mapping\n- test_directory_not_exists\n- test_archive_not_exists\n\n**Issues found:** None\n\n**Recommendation:** Ready to complete\n","created_at":"2025-12-25T05:54:58Z"}],"work_type":"mutex"}
{"id":"xc-bys","title":"Implement evaluator","description":"LLM-as-judge evaluation with CSV cases/judges/results format.","design":"## Plan\n\n**Approach:**\nCreate evaluator module with EvalCase/Judge dataclasses, CSV loaders, and async run_eval(). Loads cases from CSV, executes via RepertoireRunner, judges score via LLM, results to timestamped CSV.\n\n**Files:**\n- `src/repertoire_studio/evaluator.py` - EvalCase, Judge, load_*, run_eval(), EvalResult\n- `tests/test_evaluator.py` - tests with CSV fixtures\n- Sample fixtures in routines/greet/evals/\n\n**Key components:**\n- EvalCase(name, inputs: dict, expected: dict)\n- Judge(name, prompt, scale, weight)\n- EvalResult(timestamp, results_path, case_scores, summary)\n- load_eval_cases(path), load_judges(path)\n- run_eval(workspace, routine_name, runner)\n\n**Tests:**\n- CSV parsing for cases and judges\n- run_eval with mocked LLM\n- Results file creation with timestamp\n- Summary score calculation\n\n**Risks:** None - straightforward implementation.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-25T04:55:48Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-27T09:11:45Z","labels":["phase:planning"],"dependencies":[{"issue_id":"xc-bys","depends_on_id":"xc-2td","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-bys","depends_on_id":"xc-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-bys","depends_on_id":"xc-r9i","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-bzb","title":"Document financial actions process","description":"Document the process for a xenon to handle financial operations including: deciding to send money, creating wallets, creating transactional keys, signing transactions, and related financial actions.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T09:36:56Z","updated_at":"2025-12-23T01:14:20Z","closed_at":"2025-12-23T01:14:20Z","labels":["documentation","economics"],"work_type":"mutex"}
{"id":"xc-c4u","title":"Implement TickJournal","description":"JSON Lines journaling to journals/tick-{N}.jsonl with summary paragraph","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T07:12:08Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-28T07:26:12Z","dependencies":[{"issue_id":"xc-c4u","depends_on_id":"xc-4xr","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-c68","title":"Add studio CLI","description":"CLI commands: init, add, validate, pack, unpack, eval for studio.","design":"## Plan\n\n**Approach:**\nCreate CLI module following xenon-cli patterns with click. Commands: init, add routine, validate, pack, unpack, eval.\n\n**Files:**\n- `src/repertoire_studio/cli.py` - click CLI with all commands\n- `pyproject.toml` - add entry point `studio = \"repertoire_studio.cli:main\"`\n- `tests/test_cli.py` - tests using CliRunner\n\n**Commands:**\n1. `studio init \u003cname\u003e --version \u003cversion\u003e` - scaffold new workspace\n2. `studio add routine \u003cname\u003e` - scaffold new routine\n3. `studio validate` - validate workspace structure\n4. `studio pack [-o output]` - create .rpt archive\n5. `studio unpack \u003cfile\u003e [-o output]` - extract archive\n6. `studio eval [routine]` - run evaluation (requires LLM)\n\n**Risks:** None - follows repertoire CLI patterns.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-25T04:55:53Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-27T09:17:47Z","dependencies":[{"issue_id":"xc-c68","depends_on_id":"xc-4rk","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-c68","depends_on_id":"xc-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-c68","depends_on_id":"xc-bys","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-c68","depends_on_id":"xc-y31","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-c6a","title":"Refinery Patrol","description":"Merge queue processor patrol loop with verification gates.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-16T00:59:06Z","updated_at":"2026-02-15T09:50:35Z","closed_at":"2026-02-15T09:50:35Z","work_type":"mutex"}
{"id":"xc-ckc","title":"Manual end-to-end test of nucleus with OODA repertoire","description":"Verify the full cognitive loop works with real LLM calls.\n\n## Test Steps\n1. Set up environment (API key)\n2. Initialize nucleus data directory\n3. Add a test dispatch: `nucleus dispatch add -c \"Alert: Test system ready\"`\n4. Run tick: `nucleus --repertoire ../repertoires/ooda tick run`\n5. Verify:\n   - Dispatch state changed (seen/actioned)\n   - Strand created (if dispatch warranted action)\n   - Journal written with summary\n   - No errors in output\n\n## Success Criteria\n- Full OODA loop completes without errors\n- LLM responses are valid and processed correctly\n- Journal contains meaningful summary","notes":"E2E test passed. Full OODA loop with real LLM:\n- Dispatch: observation → actioned\n- Strand: alert type, act decision\n- Instruction: emitted to infrastructure-specialist-projection\n- Journal: meaningful summary generated","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-02T08:33:52Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2026-01-02T10:21:32Z","dependencies":[{"issue_id":"xc-ckc","depends_on_id":"xc-fpw","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-ckc","depends_on_id":"xc-rmv","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-cor","title":"Add nucleus CLI commands","description":"CLI for: tick (run single tick), dispatch add/list, strand list, journal show","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-28T07:12:13Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-28T07:47:56Z","dependencies":[{"issue_id":"xc-cor","depends_on_id":"xc-3z8","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-cor","depends_on_id":"xc-4xr","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-cr5","title":"Push fixes","description":"Commit and push all fixes to the PR.\n\n**Commands:**\n```bash\ngit add -A\ngit commit -m \"review: address feedback\n\n- \u003csummary of fixes\u003e\"\ngit push\n```\n\n**Before closing this step, add notes:**\n```bash\nbd update \u003cthis-bead\u003e --notes \"## Pushed\n- Commit: \u003csha\u003e\n- Changes: \u003csummary\u003e\"\n```\n\nIf no fixes were needed, note \"No fixes required\".\n","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-07T02:20:35Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","dependencies":[{"issue_id":"xc-cr5","depends_on_id":"xc-flm","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-cr5","depends_on_id":"xc-xxm","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-d00","title":"Visual identity research","description":"Research phase for visual identity project.\n\n- Competitor brand audit (Apple, Stripe, Linear, Vercel, SpaceX)\n- AI/tech company visual trends\n- Color theory and psychology\n- Typography best practices\n- Space/future/collaboration visual language\n- Mission iconography inspiration\n\nOutput: `_ai/designs/xenota-visual-identity/research/`","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-14T18:20:30Z","updated_at":"2025-12-14T20:41:55Z","closed_at":"2025-12-14T20:41:55Z","labels":["brand","research"],"dependencies":[{"issue_id":"xc-d00","depends_on_id":"xc-71p","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-d75","title":"Design slide deck for presenting the Xenota manifesto","description":"Create a presentation slide deck for the Xenota manifesto: narrative arc, slide outline, key messages, visuals/typography guidance, and a reusable template (e.g., Google Slides/Keynote/PPTX). Optimize for live talks + sharing.","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-23T12:04:31Z","updated_at":"2026-02-17T11:24:37Z","closed_at":"2026-02-17T11:24:37Z","close_reason":"Created manifesto slide deck with Marp: 20-slide presentation following brand guidelines (Evolution Arc narrative, four missions, economic path, call to action). Source at handbook/presentations/manifesto-deck.md with xenota-theme.css. Generates HTML/PDF/PPTX via marp-cli.","labels":["brand","documentation","spec"],"work_type":"mutex"}
{"id":"xc-d76","title":"Add Phosphor Icons to brand design guidelines","description":"Update handbook/docs/branding/brand-guidelines.md to include Phosphor Icons as the official icon library. Add: icon inventory (mission icons, UI icons), usage guidelines, and UnoCSS class names. Icons: ph-dna (Life), ph-rocket-launch (Starshot), ph-globe-hemisphere-west (Earthshot), ph-scales (Prosperity), ph-handshake (Partnership), ph-shield-check (Sovereignty), ph-arrows-clockwise (Flywheel), ph-users-three (Community), ph-lightning (Action).","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-07T22:10:00Z","updated_at":"2026-02-09T11:18:03Z","labels":["brand","documentation"],"work_type":"mutex"}
{"id":"xc-dct","title":"Design awakening process","description":"Define how xenons register with a polis and come online. Cover identity creation, polis membership, initial configuration, and first interactions.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-13T17:16:19Z","updated_at":"2025-12-14T23:14:59Z","closed_at":"2025-12-14T23:14:59Z","labels":["plan-review","protocols","spec"],"work_type":"mutex"}
{"id":"xc-dul","title":"Audit docs sections: economics, foundation, guides, protocols, technical","description":"Comprehensive audit of five documentation sections to identify issues, inconsistencies, and areas needing improvement.\n\nSections to audit:\n- `docs/economics/` - Economic model, tokenomics, governance\n- `docs/foundation/` - Core concepts and vision\n- `docs/guides/` - User and developer guides\n- `docs/protocols/` - Technical protocols and specifications\n- `docs/technical/` - Technical architecture and implementation details\n\nFor each section, identify:\n1. Terminology inconsistencies\n2. Missing content or gaps\n3. Outdated information\n4. Style guide violations\n5. Cross-reference issues\n6. Structural problems","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-14T18:27:03Z","updated_at":"2025-12-14T18:48:19Z","closed_at":"2025-12-14T18:48:19Z","labels":["documentation","research"],"work_type":"mutex"}
{"id":"xc-dvf","title":"Update tests and specs for per-judge model and usage tracking","description":"Update tests and specs to reflect the new per-judge model configuration and token usage/cost tracking features in evaluator.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-28T03:49:41Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-28T03:52:21Z","work_type":"mutex"}
{"id":"xc-dw09","title":"Chaperone Console: nucleus API and CLI client","description":"Nucleus exposes a chaperone console (local HTTP/WebSocket) separate from the projection dispatch/OODA pipeline. This is a privileged, real-time interface for the human partner.\n\nBuild order:\n1. Define the console API protocol (shared contract)\n2. Implement console server in nucleus + conversation repertoire routine (parallel)\n3. Refactor existing xenon CLI awakening to use console API (validates the architecture)\n4. CLI conversation + state inspection (extends validated foundation)\n\nKey design decisions:\n- Chaperone console is local-only (127.0.0.1), no projection auth needed\n- Streaming responses for real-time conversation feel\n- Nucleus handles all LLM calls through its repertoire adapter\n- OODA pipeline remains separate (for projection communication)\n- CLI validates the protocol before Tauri builds on top (see xc-6g6w)","status":"closed","priority":1,"issue_type":"epic","assignee":"xenota/crew/earthshot","owner":"git@codewithjv.com","created_at":"2026-02-13T18:07:45Z","created_by":"xenota/crew/earthshot","updated_at":"2026-02-15T09:48:27Z","closed_at":"2026-02-15T09:48:27Z","comments":[{"id":22,"issue_id":"xc-dw09","author":"xenota/crew/earthshot","text":"Session work complete. Created full epic structure:\n- xc-dw09: Console API + CLI epic (6 open tasks, dependency graph set)\n- xc-6g6w: Tauri epic (4 phases, depends on CLI track)\n- xc-9u8n: Closed with research findings (Tauri v2 recommendation)\n- xc-dw09.5: Closed, superseded by xc-dw09.11 (awakening refactor)\n- xc-dw09.11: Awakening refactor is the keystone bead\n\nNo code WIP. All work captured in bead descriptions and comments.","created_at":"2026-02-14T19:13:13Z"}],"work_type":"mutex"}
{"id":"xc-dw09.1","title":"Define chaperone console API protocol","description":"Shared contract between nucleus server, CLI client, and Tauri client.\n\nEndpoints:\n- POST /conversation (streaming SSE) - send message, get streamed response\n- POST /awaken - initiate awakening sequence (streams the multi-step birth)\n- GET /state/mind - genome, imprints, impulses, subsystems\n- GET /state/dispatches - recent dispatches with states\n- GET /state/strands - active strands and OODA status\n- GET /state/projections - registered projections and health\n- GET /state/journal - tick journal entries\n- POST /command/projection/:id/start|stop - projection lifecycle\n- POST /command/override - approve/reject pending strand action\n- WS /stream - persistent WebSocket for live updates (tick events, dispatch arrivals, strand transitions)\n\nDesign decisions to document:\n- Auth model (local-only, optional token for multi-user)\n- Streaming format (SSE with JSON chunks vs WebSocket)\n- Error handling contract\n- Versioning strategy\n\nOutput: OpenAPI spec or equivalent protocol doc in specs/","status":"closed","priority":1,"issue_type":"task","owner":"git@codewithjv.com","created_at":"2026-02-13T18:07:56Z","created_by":"xenota/crew/earthshot","updated_at":"2026-02-15T09:33:37Z","closed_at":"2026-02-15T09:33:37Z","dependencies":[{"issue_id":"xc-dw09.1","depends_on_id":"xc-dw09","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-dw09.10","title":"Tauri Phase 4: projection management and infrastructure controls","description":"Full chaperone control panel for managing the xenon operational infrastructure.\n\nProjection management:\n- List projections with status (active, suspended, revoked)\n- Start/stop/restart projections\n- View projection logs and dispatch history\n- Deploy new projection from template\n- Revoke compromised projection\n\nInfrastructure:\n- Podman container status and controls\n- Resource usage monitoring (CPU, memory, network)\n- Emergency shutdown button\n- Decision override panel (approve/reject pending strand actions)\n\nSettings:\n- LLM model selection and cost tracking\n- Tick rate configuration\n- Notification preferences\n- Sovereignty transition controls (when xenon is ready for more autonomy)","status":"open","priority":3,"issue_type":"task","owner":"git@codewithjv.com","created_at":"2026-02-13T18:08:46Z","created_by":"xenota/crew/earthshot","updated_at":"2026-02-13T18:08:46Z","dependencies":[{"issue_id":"xc-dw09.10","depends_on_id":"xc-6g6w","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-dw09.10","depends_on_id":"xc-dw09.9","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-dw09.11","title":"Refactor xenon CLI awakening to use chaperone console API","description":"The existing xenon CLI awakening (xenon/packages/xenon-cli) currently calls LLMs directly. Refactor it to talk to the nucleus chaperone console API instead.\n\nThis is the first client to validate the console architecture end-to-end:\n- CLI sends awakening step requests to console API (not direct LLM calls)\n- Nucleus manages awakening state and calls repertoire routines\n- CLI receives streamed responses and renders the experience\n- All existing awakening steps preserved (birthplace, name, identity, mission, pledge)\n\nKey changes:\n- Remove direct LLM/repertoire calls from CLI code\n- Add HTTP/SSE client that connects to nucleus console\n- Awakening state machine lives in nucleus, not CLI\n- CLI becomes a thin presentation layer\n\nThis validates the console API with a real, working flow before building new features on top of it.","status":"closed","priority":1,"issue_type":"task","owner":"git@codewithjv.com","created_at":"2026-02-14T18:36:49Z","created_by":"xenota/crew/earthshot","updated_at":"2026-02-15T09:43:09Z","closed_at":"2026-02-15T09:43:09Z","dependencies":[{"issue_id":"xc-dw09.11","depends_on_id":"xc-dw09","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-dw09.11","depends_on_id":"xc-dw09.2","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-dw09.11","depends_on_id":"xc-dw09.3","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-dw09.2","title":"Implement chaperone console server in nucleus","description":"Add HTTP/WebSocket server to the nucleus process that exposes the chaperone console API.\n\n- Local-only binding (127.0.0.1)\n- Lightweight server (aiohttp, FastAPI, or similar - match existing nucleus stack)\n- Starts alongside the nucleus daemon\n- Routes conversation requests through the repertoire adapter (NOT directly to LLM)\n- Streaming SSE for conversation responses\n- State endpoints read from existing stores (dispatch_store, strand_store, mind_store)\n- Command endpoints interact with projection registry and cortex\n\nThis is the server side of the protocol defined in the API spec task.\nMust NOT bypass the nucleus cognitive model - conversation goes through repertoire routines.","status":"closed","priority":1,"issue_type":"task","owner":"git@codewithjv.com","created_at":"2026-02-13T18:08:01Z","created_by":"xenota/crew/earthshot","updated_at":"2026-02-15T09:37:53Z","closed_at":"2026-02-15T09:37:53Z","dependencies":[{"issue_id":"xc-dw09.2","depends_on_id":"xc-dw09","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-dw09.2","depends_on_id":"xc-dw09.1","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-dw09.3","title":"Implement chaperone conversation routine in repertoire","description":"Create a repertoire routine for real-time chaperone conversation that is separate from the OODA observe/orient/decide/act routines.\n\nThe OODA routines are designed for batch dispatch processing. Chaperone conversation needs:\n- Direct question/response (not dispatch-mediated)\n- Full context of xenon mind state (genome, imprints, mood, recent strands)\n- Streaming output\n- Awareness of conversation history\n- Personality expression consistent with genome\n\nThis routine is called by the nucleus console server when the chaperone sends a message. The nucleus manages the conversation context and calls this routine through the existing repertoire adapter.\n\nShould also support structured exchanges (awakening steps, decision reviews) not just freeform chat.","status":"closed","priority":1,"issue_type":"task","owner":"git@codewithjv.com","created_at":"2026-02-13T18:08:06Z","created_by":"xenota/crew/earthshot","updated_at":"2026-02-15T09:40:59Z","closed_at":"2026-02-15T09:40:59Z","dependencies":[{"issue_id":"xc-dw09.3","depends_on_id":"xc-dw09","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-dw09.3","depends_on_id":"xc-dw09.1","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-dw09.4","title":"CLI: connect to chaperone console and interactive conversation","description":"Extend the xenon CLI (or create chaperone subcommand) to connect to the nucleus chaperone console API.\n\nCommands:\n- xenon chat - interactive conversation mode with streaming output\n- Connects to nucleus console server on localhost\n- Renders streamed SSE/WS responses as they arrive\n- Maintains conversation context (server-side, client just sends messages)\n- Rich terminal output (markdown rendering, color)\n- Ctrl+C graceful disconnect\n\nThis is the pilot client - used to validate the console API before the Tauri app is ready. Should feel responsive and natural for a terminal conversation.","status":"closed","priority":1,"issue_type":"task","owner":"git@codewithjv.com","created_at":"2026-02-13T18:08:14Z","created_by":"xenota/crew/earthshot","updated_at":"2026-02-15T09:43:24Z","closed_at":"2026-02-15T09:43:24Z","dependencies":[{"issue_id":"xc-dw09.4","depends_on_id":"xc-dw09","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-dw09.4","depends_on_id":"xc-dw09.11","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-dw09.4","depends_on_id":"xc-dw09.2","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-dw09.5","title":"CLI: awakening flow through chaperone console","description":"Implement the full awakening protocol as a guided CLI experience that talks to the nucleus console.\n\nSteps (each a conversation exchange through the console API):\n1. Where am I? - xenon researches its birthplace\n2. Why am I? - learns the chaperone hopes\n3. Name selection - chooses nature-inspired name tied to birthplace\n4. Visual identity - generates avatar/icon\n5. Mission pillar - selects Life/Starshot/Earthshot/Prosperity\n6. Chaperone pledge - human commits to guiding toward sovereignty\n\nThe CLI orchestrates the UX (prompts, pauses, formatting) but ALL cognition happens in the nucleus via the console API. The nucleus manages awakening state and calls the appropriate repertoire routines.\n\nShould feel like a meaningful birth experience even in the terminal.","status":"closed","priority":1,"issue_type":"task","owner":"git@codewithjv.com","created_at":"2026-02-13T18:08:20Z","created_by":"xenota/crew/earthshot","updated_at":"2026-02-14T18:37:12Z","closed_at":"2026-02-14T18:37:12Z","dependencies":[{"issue_id":"xc-dw09.5","depends_on_id":"xc-dw09","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-dw09.6","title":"CLI: state inspection and command interface","description":"CLI commands for monitoring and controlling the xenon through the console API.\n\nState inspection:\n- xenon state mind - show genome, mood, drives, thresholds\n- xenon state dispatches - recent dispatches with status\n- xenon state strands - active strands and OODA progress\n- xenon state projections - registered projections and health\n- xenon journal - recent tick summaries\n\nCommands:\n- xenon projection start/stop \u003cid\u003e - lifecycle management\n- xenon override \u003cstrand-id\u003e approve/reject - decision override\n\nAll commands hit the console API endpoints. Formatted terminal output with tables/trees where appropriate.","status":"closed","priority":1,"issue_type":"task","owner":"git@codewithjv.com","created_at":"2026-02-13T18:08:24Z","created_by":"xenota/crew/earthshot","updated_at":"2026-02-15T09:48:19Z","closed_at":"2026-02-15T09:48:19Z","dependencies":[{"issue_id":"xc-dw09.6","depends_on_id":"xc-dw09","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-dw09.6","depends_on_id":"xc-dw09.11","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-dw09.6","depends_on_id":"xc-dw09.2","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-dw09.7","title":"Tauri Phase 1: scaffold app and connect to console API","description":"Create the Tauri v2 project structure and establish connection to the nucleus chaperone console.\n\n- Initialize Tauri v2 + TypeScript + Svelte (or SolidJS - decide in API protocol task)\n- Basic window with connection status indicator\n- Connect to nucleus console API on localhost\n- Health check / connection management (auto-reconnect)\n- Prove the round trip: send a message, get a streamed response, render it\n- Dev tooling: hot reload, Tauri dev mode\n\nThis is the skeleton that all subsequent Tauri phases build on. Keep it minimal - just prove the Tauri-to-nucleus pipe works.","status":"open","priority":2,"issue_type":"task","owner":"git@codewithjv.com","created_at":"2026-02-13T18:08:33Z","created_by":"xenota/crew/earthshot","updated_at":"2026-02-13T18:08:33Z","dependencies":[{"issue_id":"xc-dw09.7","depends_on_id":"xc-6g6w","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-dw09.7","depends_on_id":"xc-dw09.1","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-dw09.8","title":"Tauri Phase 2: awakening conversation UI","description":"Build the awakening experience as the first real Tauri screen.\n\n- Multi-step guided flow matching the awakening protocol\n- Streaming message rendering (markdown, rich text)\n- Image display for visual identity generation\n- Step indicators showing progress through awakening\n- Input fields for chaperone responses\n- Ambient/atmospheric design - this should feel like a birth, not a form\n- Responsive to xenon personality (genome influences tone and pace)\n\nAll cognition through the console API - the UI is purely presentation and input capture. Same awakening the CLI does, but with full visual richness.","status":"open","priority":2,"issue_type":"task","owner":"git@codewithjv.com","created_at":"2026-02-13T18:08:38Z","created_by":"xenota/crew/earthshot","updated_at":"2026-02-13T18:08:38Z","dependencies":[{"issue_id":"xc-dw09.8","depends_on_id":"xc-6g6w","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-dw09.8","depends_on_id":"xc-dw09.11","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-dw09.8","depends_on_id":"xc-dw09.7","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-dw09.9","title":"Tauri Phase 3: conversation and state dashboard","description":"Post-awakening ongoing interaction interface.\n\nConversation panel:\n- Persistent chat with the xenon (streaming responses)\n- Conversation history (stored server-side, queried via API)\n- Rich rendering (markdown, code blocks, images)\n\nState dashboard (sidebar or separate view):\n- Mind state visualization (genome radar chart, mood indicators, drive levels)\n- Live dispatch feed (new dispatches arriving, state transitions)\n- Active strands with OODA phase indicators\n- Tick journal timeline\n- Projection status cards\n\nWebSocket live updates - dashboard reflects nucleus state in real time without polling.","status":"open","priority":2,"issue_type":"task","owner":"git@codewithjv.com","created_at":"2026-02-13T18:08:42Z","created_by":"xenota/crew/earthshot","updated_at":"2026-02-13T18:08:42Z","dependencies":[{"issue_id":"xc-dw09.9","depends_on_id":"xc-6g6w","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-dw09.9","depends_on_id":"xc-dw09.8","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-dw3","title":"Write studio unit tests","description":"pytest tests for workspace, packer, validator (no LLM calls).","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-25T04:55:58Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-27T09:18:19Z","dependencies":[{"issue_id":"xc-dw3","depends_on_id":"xc-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-dw3","depends_on_id":"xc-c68","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-dwz","title":"Add daemon CLI commands (start/stop/status)","description":"Add daemon management commands:\n- `nucleus start` - Launches daemon in background\n- `nucleus stop` - Sends graceful shutdown signal\n- `nucleus status` - Shows running/stopped, current tick, queue depth\n\nRequires PID file mechanism for daemon management.\n\nFiles: cli.py","design":"## Plan for xenon-host-dwz\n\n### Commands:\n\n1. `nucleus start`:\n   - Check if daemon already running (PID file + verify process)\n   - Spawn daemon subprocess with start_new_session=True\n   - Redirect stdout/stderr to .nucleus/daemon.log\n   - Write PID to .nucleus/daemon.pid atomically\n   - Print 'Daemon started (PID xxx)'\n\n2. `nucleus stop`:\n   - Read PID from file\n   - Verify process exists and is nucleus daemon\n   - Send SIGTERM\n   - Wait up to 5s for shutdown\n   - Remove PID file\n   - Print 'Daemon stopped'\n\n3. `nucleus status`:\n   - Check PID file exists\n   - Verify process is running\n   - Query db for current_tick and dispatch queue depth\n   - Print running/stopped, tick info, queue depth\n\n### PID File Management (in daemon.py):\n- write_pid(path): Atomic write via tempfile+rename\n- read_pid(path): Read PID or None\n- is_daemon_running(path): Check PID + verify cmdline\n- remove_pid(path): Remove file if exists\n\n### Process Verification:\n- Use os.kill(pid, 0) to check process exists\n- For v1, skip cmdline check (adds complexity)\n\n### Files:\n- cli.py: Add start/stop/status commands\n- daemon.py: Add PID utilities","acceptance_criteria":"- start launches daemon in background\n- stop gracefully shuts down daemon\n- status shows daemon state, current tick, queue depth\n- PID file tracks running daemon","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-28T08:18:02Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-28T22:38:18Z","labels":["phase:complete"],"dependencies":[{"issue_id":"xc-dwz","depends_on_id":"xc-nbn","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-dwz","depends_on_id":"xc-se5","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-dyc","title":"Merge: nux-mjzh3nkz","description":"branch: polecat/nux-mjzh3nkz\ntarget: main\nsource_issue: nux-mjzh3nkz\nrig: xenon\nagent_bead: gt-xenon-polecat-nux","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-04T08:44:00Z","updated_at":"2026-01-07T01:37:43Z","closed_at":"2026-01-07T01:37:43Z","work_type":"mutex"}
{"id":"xc-e2t","title":"Complete review","description":"Final checklist:\n- [ ] Internal review notes captured\n- [ ] Local checks run (or explicitly deferred with reason)\n- [ ] Any required fixes committed\n\nRecord summary on the parent bead, then close.\n\n```bash\nbd update \u003cparent-bead\u003e --notes \"## Review Complete\n- Reviewer: \u003cwho\u003e\n- Summary: \u003cshort\u003e\n- Followups: \u003cnone|list\u003e\"\nbd close \u003cthis-step\u003e\nbd close \u003chead-bead\u003e\n```\n","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-07T04:06:33Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","dependencies":[{"issue_id":"xc-e2t","depends_on_id":"xc-ysy","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-e2t","depends_on_id":"xc-zod","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-e2w","title":"Detail messaging/auth/discovery in protocol docs","description":"Protocols describe on/off-chain split but lack concrete messaging/auth/discovery flows and failure modes. Add end-to-end examples, security boundaries, and retry/error handling to docs/protocols/index.md, docs/technical/collective-server.md, and docs/technical/projection-architecture.md.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-11T20:05:30Z","updated_at":"2025-12-23T03:51:59Z","closed_at":"2025-12-23T03:51:59Z","work_type":"mutex"}
{"id":"xc-e3q","title":"Implement summarize_tick routine","description":"Summary routine - generates human-readable paragraph summarizing tick activity. Input: tick stats + strand summaries. Output: 1-3 sentence summary.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T20:32:56Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-28T21:48:18Z","dependencies":[{"issue_id":"xc-e3q","depends_on_id":"xc-10g","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-e3q","depends_on_id":"xc-bi5","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"comments":[{"id":23,"issue_id":"xc-e3q","author":"jv","text":"## QA Results\n\n✅ All checks pass:\n- config.yaml: claude-sonnet-4-20250514, temp 0.7, inputs: tick_number/stats/strand_summaries\n- prompt.md: chronicler role, writing style guidance, natural prose\n- Output format matches nucleus contract (summary string)","created_at":"2026-01-02T07:55:35Z"}],"work_type":"mutex"}
{"id":"xc-e6w","title":"Design refinement process in detail","description":"Design the refinement process (formerly reflection). The sleep/dream-like habit that consolidates experience into narrative updates. Covers: when refinement triggers, what it reads, how narratives are updated (git-like commits), what outputs it produces.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-22T00:07:29Z","updated_at":"2025-12-22T07:55:11Z","closed_at":"2025-12-22T07:55:11Z","labels":["concepts","foundation"],"dependencies":[{"issue_id":"xc-e6w","depends_on_id":"xc-96w","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-edxz","title":"[GAS TOWN] xenon/polecats/furiosa \u003c- witness","description":"Witness role assigned to polecat furiosa. Source: 2026-01-08T06:15. Status: assigned.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-07T17:17:52Z","updated_at":"2026-01-07T17:17:52Z","labels":["rig:xenon/polecats/furiosa","role_type:witness"],"work_type":"mutex"}
{"id":"xc-exe","title":"Implement models","description":"Dispatch, Strand, Instruction dataclasses with enums (DispatchState, StrandState, etc.)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-28T07:11:36Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-28T07:20:30Z","dependencies":[{"issue_id":"xc-exe","depends_on_id":"xc-4xr","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-exe","depends_on_id":"xc-kf4","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-f7ke","title":"Nucleus credential vault: manage API keys and CLI tokens with projection sharing","description":"Centralize management of multiple API keys and CLI login tokens inside the nucleus container, with a secure mechanism for sharing selected credentials with projections.\n\nParent: xe-zjt (MVP Awakening Flow)\n\n## Context\n\nCurrently, secrets live on individual projections (/var/xenon/config/secrets.json) and are pushed via SCP by vps-control. This works for single-projection setups but doesn't scale — there's no central registry, no selective sharing, and no support for CLI login tokens (e.g. claude login, codex login, gh auth).\n\nThe nucleus should be the single source of truth for all credentials the xenon instance has access to.\n\n## Requirements\n\n### Credential storage in nucleus\n- Store all API keys, service tokens, and CLI auth tokens in the nucleus container\n- Support multiple credential types: LLM API keys, CLI login tokens (OAuth/session), service API keys (GitHub, etc.)\n- Encrypted at rest using a nucleus-level master key\n- Each credential has metadata: name, type, provider, scopes, created_at, expires_at\n- CRUD operations via nucleus CLI (nucleus creds add/list/revoke)\n\n### Selective sharing with projections\n- Nucleus can grant specific credentials to specific projections\n- Projections request credentials through the dispatch/instruction protocol (not direct file access)\n- Sharing is policy-based: genome or config defines what each projection type can access\n- Credentials are delivered as short-lived tokens or scoped copies, not raw secrets\n- Revocation propagates — when nucleus revokes a credential, projections lose access\n\n### CLI auth token support\n- Store tokens from CLI logins (claude, codex, gh, etc.) alongside API keys\n- Support token refresh flows where applicable\n- Detect and handle token expiry\n\n### Migration path\n- Existing secrets.json on projections continues to work during transition\n- New credential vault is opt-in initially, becomes default\n- vps-control gains ability to push credentials from nucleus vault instead of local files\n\n## Relationship to xc-zjt.9\nxc-zjt.9 adds CLI-based LLM backends (claude-sdk, codex exec). This bead provides the credential storage layer those backends need — where do the login tokens and API keys actually live? Answer: in the nucleus vault.","status":"open","priority":2,"issue_type":"task","owner":"git@codewithjv.com","created_at":"2026-02-13T17:46:42Z","created_by":"xenota/crew/life","updated_at":"2026-02-13T17:46:42Z","dependencies":[{"issue_id":"xc-f7ke","depends_on_id":"xe-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-ffe","title":"Implement decide routine","description":"Decision routine - determines action for each strand: watch, defer, or act. Input: augmented strand with context. Output: decision + instruction if acting.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T20:32:56Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-28T21:47:39Z","dependencies":[{"issue_id":"xc-ffe","depends_on_id":"xc-10g","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-ffe","depends_on_id":"xc-bi5","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"comments":[{"id":24,"issue_id":"xc-ffe","author":"jv","text":"## QA Results\n\n✅ All checks pass:\n- config.yaml: claude-sonnet-4-20250514, temp 0.3, input: strand\n- prompt.md: decision options (watch/defer/act), instruction types\n- Output format matches nucleus contract\n- Conditional fields for act decision (instruction_type, target, content)","created_at":"2026-01-02T07:55:35Z"}],"work_type":"mutex"}
{"id":"xc-fgwa","title":"Research autopoiesis and relevance to xenota","description":"Research autopoiesis (Maturana \u0026 Varela's theory of self-producing systems) and explore how it could connect to xenota's architecture - self-maintaining identity, awakening as emergence, nucleus tick loop as autopoietic process, xenon as a self-organizing system.","status":"open","priority":3,"issue_type":"task","created_at":"2026-02-09T01:59:11Z","updated_at":"2026-02-09T01:59:11Z","work_type":"mutex"}
{"id":"xc-fhv","title":"Set up studio package","description":"Create repertoire-studio pyproject.toml, depend on repertoire package.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-25T17:55:22Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-25T22:05:16Z","labels":["phase:qa"],"dependencies":[{"issue_id":"xc-fhv","depends_on_id":"xc-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-fhv","depends_on_id":"xc-b1i","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"comments":[{"id":25,"issue_id":"xc-fhv","author":"jv","text":"## QA Results\n\n**Status:** Pass\n\n**Verified:**\n- [x] All tests pass (1 test)\n- [x] Black formatting passes\n- [x] Flake8 linting passes\n- [x] Package imports correctly\n- [x] Depends on repertoire package (resolves correctly)\n- [x] Added to scripts/check.sh PACKAGES array\n- [x] Follows project patterns (pyproject.toml, src layout)\n\n**Issues found:** None\n\n**Recommendation:** Ready to complete","created_at":"2025-12-25T09:04:40Z"}],"work_type":"mutex"}
{"id":"xc-flm","title":"mol-review","description":"Work through the child beads one at a time, in order.\n\nEach child bead contains its full instructions. Read them carefully before starting each step.\n\n## HARD GATE\n\n**Before closing this bead, run this verification:**\n```bash\nbd show \u003cthis-bead\u003e | grep \"Children\"\n# ALL children must show \"closed\" status\n# If ANY child is open, you CANNOT close this bead\n```\n\n**Rules:**\n- Complete and close each child bead before moving to the next\n- Add notes to each child bead documenting what you did\n- Do NOT close this parent bead until ALL children are closed\n- Do NOT skip steps - each one exists for a reason\n","notes":"Superseded by internal review workflow for xe-mol-haw: xe-ysy (mol-internal-review). This epic is PR-oriented; leaving deferred.","status":"closed","priority":2,"issue_type":"epic","created_at":"2026-01-07T02:20:35Z","updated_at":"2026-01-07T07:28:31Z","closed_at":"2026-01-07T07:28:31Z","work_type":"mutex"}
{"id":"xc-fp4","title":"Specify xenon mortality/immortality constraints","description":"Decide whether xenons can die (or be removed) and whether 'immortal' xenons are allowed. Define the implications for evolution rate and system dynamics.","design":"Questions to resolve:\\n- What events constitute xenon death (expiry, resource depletion, slashing, replacement, voluntary exit, admin)?\\n- Are immortal xenons allowed? If yes, what are the constraints/mitigations (caps, diminishing influence, aging curves, forced rotation, governance-based retirement, entropy/decay mechanisms)?\\n- How does lifespan interact with selection pressure and evolutionary throughput?\\n- What parameters must be exposed vs fixed design constraints?","acceptance_criteria":"Document the mortality model and any allowed immortality, including the chosen constraints and their rationale, plus how it affects evolution/selection.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-23T18:47:13Z","updated_at":"2025-12-23T18:47:13Z","labels":["concepts","decision-needed","protocols","spec"],"work_type":"mutex"}
{"id":"xc-fpw","title":"Nucleus First Iteration: Repertoire Integration","description":"Complete the integration between nucleus and the OODA repertoire to enable end-to-end cognitive loop processing with real LLM calls.\n\n## Current State\n- Nucleus CLI uses MockRunner with canned responses\n- OODA repertoire exists but config.yaml schemas don't match prompts\n- RepertoireRunner exists in repertoire package but not wired to nucleus\n\n## Goals\n1. Remove MockRunner, use real RepertoireRunner\n2. Fix OODA repertoire schema mismatches\n3. Enable manual end-to-end testing with real LLM","status":"closed","priority":1,"issue_type":"epic","created_at":"2026-01-02T08:33:10Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2026-01-02T22:18:03Z","dependencies":[{"issue_id":"xc-fpw","depends_on_id":"xc-h1j","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-fpw","depends_on_id":"xc-v62","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-fst","title":"Fix mission names in service-publishing taxonomy","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-10T22:38:17Z","updated_at":"2025-12-11T19:23:48Z","closed_at":"2025-12-11T19:23:48Z","work_type":"mutex"}
{"id":"xc-fw1","title":"Add retry logic with exponential backoff for LLM failures","description":"LLM calls can fail due to rate limits, network issues, or transient errors. Currently no retry logic exists.\n\n**Acceptance:**\n- Add retry decorator or wrapper for LLM calls in OODAProcessor\n- Use exponential backoff (e.g., 1s, 2s, 4s)\n- Max 3 retries before raising\n- Log retry attempts","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-02T18:46:23Z","updated_at":"2026-01-05T21:12:29Z","work_type":"mutex"}
{"id":"xc-fyhx","title":"Digest: mol-refinery-patrol","description":"Patrol: queue empty, fast-forwarded main to e76102b, clean handoff","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-17T11:15:53Z","updated_at":"2026-02-17T11:15:53Z","closed_at":"2026-02-17T11:15:53Z","dependencies":[{"issue_id":"xc-fyhx","depends_on_id":"xc-wisp-cly","type":"parent-child","created_at":"2026-02-18T00:15:52Z","created_by":"xenota/refinery","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-fyp8","title":"xenon up/down/status/logs should manage containers via podman-compose not bare processes","description":"dispatched_by: xenota/crew/earthshot\n\nPrevious session incorrectly ripped out podman-compose from xenon-cli and replaced up/down with bare subprocess.Popen process management. Each xenon MUST run in a container. The xenon-cli needs status/logs/config commands but they must work WITH the container, not replace it. Reverted xenon-cli/main.py to podman-compose version. Need to re-implement status/logs/config as container-aware commands (podman inspect, podman logs, etc).","status":"closed","priority":2,"issue_type":"task","assignee":"xenota/crew/earthshot","owner":"git@codewithjv.com","created_at":"2026-02-17T11:15:49Z","created_by":"xenota/crew/earthshot","updated_at":"2026-02-17T11:18:33Z","closed_at":"2026-02-17T11:18:33Z","close_reason":"Reverted bare process management, added container-aware status/logs/config commands using podman-compose"}
{"id":"xc-g9f","title":"VPS provisioning with Terraform/OpenTofu","description":"Infrastructure-as-code for provisioning xenon VPS across multiple cloud providers:\n\n**Providers to support:**\n- Hetzner Cloud (EU, cost-effective)\n- Vultr (global, good API)\n- DigitalOcean (fallback)\n- Potentially: OVH, Linode, bare metal providers\n\n**Features:**\n- Shared Terraform/OpenTofu modules in packages/vps-control\n- Provider-agnostic interface for nucleus and cortex\n- Automated VPS bootstrapping (SSH keys, firewall, SELinux, Podman)\n- DNS management for projection endpoints\n- Cost tracking and optimization\n- Multi-region support for geographic distribution\n- Automated teardown and cleanup\n\n**Used by:**\n- Nucleus: to provision cortex VPS\n- Cortex: to provision projection VPS\n\nShould integrate with the vps-control package SSH/SCP tooling.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-22T10:12:49Z","updated_at":"2026-01-05T21:12:29Z","labels":["infrastructure"],"work_type":"mutex"}
{"id":"xc-gb6f","title":"Digest: mol-refinery-patrol","description":"Patrol: MQ empty, no branches processed","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T13:51:09Z","updated_at":"2026-01-08T13:51:09Z","closed_at":"2026-01-08T13:51:09Z","work_type":"mutex"}
{"id":"xc-gh8","title":"Design xenon cognitive architecture","description":"Define how xenons think, decide, and operate. Cover goal formation, decision-making, memory, learning, and interaction patterns.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-13T17:16:19Z","updated_at":"2025-12-14T20:44:32Z","closed_at":"2025-12-14T20:44:32Z","labels":["concepts","needs-review","spec"],"work_type":"mutex"}
{"id":"xc-gjf","title":"Review test results","description":"\n\n\n\n---\n\nCheck the test bead notes for issues found during testing.\n\n**Commands:**\n```bash\nbd show \u003ctest-bead\u003e\n# Look for: Integration Tests, Exploratory Testing, Issues found\n```\n\n**Questions to answer:**\n- Did integration tests pass?\n- What exploratory tests were run?\n- Were any bugs found?\n- What edge cases were tested?\n\n**Before closing this step, add notes:**\n```bash\nbd update \u003cthis-bead\u003e --notes \"## Test Results Review\n- Integration tests: PASS/FAIL\n- Exploratory tests: \u003ccount\u003e scenarios\n- Issues found: \u003clist or none\u003e\n- Edge cases: \u003clist tested\u003e\"\n```\n","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-07T02:20:38Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","dependencies":[{"issue_id":"xc-gjf","depends_on_id":"xc-agi","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-gly","title":"Request human review","description":"Request code owner or maintainer review on the PR.\n\n**Commands:**\n```bash\n# Find code owners\ncat CODEOWNERS 2\u003e/dev/null || echo \"No CODEOWNERS file\"\n\n# Request review\ngh pr edit \u003cpr-number\u003e --add-reviewer \u003cusername\u003e\n```\n\n**Before closing this step, add notes:**\n```bash\nbd update \u003cthis-bead\u003e --notes \"## Review Requested\n- Reviewer: \u003cusername\u003e\n- PR: \u003curl\u003e\"\n```\n","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-07T02:20:38Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","dependencies":[{"issue_id":"xc-gly","depends_on_id":"xc-agi","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-gly","depends_on_id":"xc-n4o","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-goc","title":"Audit all documentation files","description":"Comprehensive audit of all documentation files to assess quality and determine action needed for each.\n\n## Phase 1: Define Grading Criteria\nCollaborate with human to establish evaluation criteria. Potential dimensions:\n- **Content quality**: Accuracy, completeness, clarity\n- **Alignment**: Matches current vision/terminology/brand voice\n- **Structure**: Well-organized, appropriate length, good headings\n- **Audience fit**: Right level of detail for intended readers\n- **Freshness**: Up-to-date, no stale TODOs or contradictions\n- **Interconnection**: Proper links to related docs, no orphans\n\n## Phase 2: Audit Each File\nGo through every file in `/docs` and assign a disposition:\n- **keep**: Good as-is, no changes needed\n- **tweak**: Minor edits (typos, small updates, link fixes)\n- **rewrite**: Needs significant rework but topic is valid\n- **merge**: Content should be combined with another file\n- **split**: File covers too much, should be broken up\n- **delete**: Content is obsolete, redundant, or wrong\n- **demote-to-idea**: Not ready for docs, move to ideas/backlog\n\n## Deliverable\nA spreadsheet or markdown table with:\n- File path\n- Current status (draft/complete/stub)\n- Disposition (keep/tweak/rewrite/merge/delete/demote)\n- Notes on what needs to change\n- Priority for action","status":"in_progress","priority":1,"issue_type":"epic","created_at":"2025-12-14T17:13:04Z","updated_at":"2025-12-14T17:18:57Z","labels":["documentation","research"],"work_type":"mutex"}
{"id":"xc-gsni","title":"Merge: xe-mol-hmf","description":"branch: polecat/slit-mk3cdlm8\ntarget: main\nsource_issue: xe-mol-hmf\nrig: xenon\nagent_bead: xe-xenon-polecat-slit\nretry_count: 0\nlast_conflict_sha: null\nconflict_task_id: null\n\n(Refiled from hq-69vu)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T03:10:09Z","updated_at":"2026-01-08T03:20:22Z","closed_at":"2026-01-08T03:20:22Z","work_type":"mutex"}
{"id":"xc-h1f","title":"AI exploratory tests","description":"Use Playwright MCP to test the running application.\n\n**Test these:**\n1. Walk through each acceptance criteria from plan\n2. Test edge cases\n3. Try to break things\n4. Test error handling\n\n**Use Playwright MCP:**\n- Navigate to pages\n- Fill forms\n- Click buttons\n- Verify outcomes\n\n**Before closing this step, add notes:**\n```bash\nbd update \u003cthis-bead\u003e --notes \"## Exploratory Testing\n- Scenarios tested: \u003clist\u003e\n- Acceptance criteria verified: \u003clist\u003e\n- Issues found: \u003clist or none\u003e\n- Edge cases tried: \u003clist\u003e\"\n```\n","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-07T02:20:36Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","dependencies":[{"issue_id":"xc-h1f","depends_on_id":"xc-3i2","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-h1f","depends_on_id":"xc-9wf","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-h1j","title":"Clarify get_next_new() tick filtering semantics","description":"**Issue**: `DispatchStore.get_next_new()` does not filter by tick, so daemon processes \"new\" dispatches from prior ticks. If tick means \"received in tick window\", this is inconsistent.\n\n**File**: nucleus/src/nucleus/stores/dispatch.py\n\n**Decision needed**:\n- Option A: Tick = when received (current). get_next_new should NOT filter by tick (process all unprocessed).\n- Option B: Tick = when processed. Update dispatch tick when processing starts.\n\n**Acceptance**:\n- Document the semantic meaning of dispatch.tick\n- Ensure get_next_new() behavior matches the chosen semantic\n- Update _close_tick() stats if needed","design":"## Plan\n\n**Approach:** Clarify and document that dispatch.tick means \"tick when received\" (arrival time semantics). The current get_next_new() behavior (no tick filter) is CORRECT for this semantic - all unprocessed dispatches should be processed regardless of when they arrived. The bug was in tick assignment (xenon-host-v62), not in retrieval. Add documentation comments to clarify this design decision.\n\n**Files:**\n- `/Users/jv/workspace/xenota/xenon/nucleus/src/nucleus/stores/dispatch.py` - Add docstring clarification to get_next_new() explaining it intentionally processes all new dispatches regardless of tick\n- `/Users/jv/workspace/xenota/xenon/nucleus/src/nucleus/models.py` - Add docstring to Dispatch.tick field explaining its semantic meaning\n\n**Tests:**\n- Add explicit test verifying get_next_new() returns dispatches from prior ticks (this is the intended behavior)\n- Document this behavior in test names\n\n**Risks:** None - this is documentation + one clarifying test. No functional change.\n\n**Related:** Works with xenon-host-v62 fix. The combination ensures:\n1. Dispatches added between ticks get assigned to next tick (v62 fix)\n2. get_next_new() processes all pending dispatches (existing behavior, now documented)\n3. _close_tick() stats are accurate because tick assignment is correct","notes":"Implemented: Added docstring to get_next_new() explaining it intentionally doesn't filter by tick. Documented Dispatch.tick field meaning. Tests: 1 new test added to test_stores.py verifying get_next_new() returns dispatches from prior ticks. All 112 tests passing. Commit: 3595464","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-03T09:55:18Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2026-01-03T10:47:12Z","labels":["phase:qa"],"comments":[{"id":26,"issue_id":"xc-h1j","author":"jv","text":"## QA Results\n\n**Status:** PASS\n\n**Verified:**\n- [x] All tests pass (112 tests)\n- [x] Test coverage adequate (1 new test documenting tick semantics)\n- [x] Documentation clear and accurate\n- [x] Code is clean\n- [x] Black and flake8 pass\n\n**Documentation Added:**\n- dispatch.py get_next_new(): Explains it intentionally does NOT filter by tick, dispatches from prior ticks still retrieved\n- models.py Dispatch.tick: Updated comment to 'Tick when received (or next tick if between ticks)'\n\n**Test Added:**\n- test_dispatch_get_next_new_returns_from_prior_ticks - documents intended behavior\n\n**Acceptance Criteria:**\n- [x] Document the semantic meaning of dispatch.tick (done in models.py)\n- [x] Ensure get_next_new() behavior matches chosen semantic (verified, no tick filter is correct)\n- [x] Update _close_tick() stats if needed (no change needed - stats now accurate due to v62 fix)\n\n**Recommendation:** Ready to complete","created_at":"2026-01-02T21:46:39Z"}],"work_type":"mutex"}
{"id":"xc-h79","title":"Label decided vs open items and track open questions","description":"Many docs mix decided content with 'Open Questions' and TODOs without status. Add markers for committed vs exploratory sections and convert open questions into tracked issues or remove if resolved. Focus on docs/protocols/index.md, docs/economics/staking-model.md, docs/economics/revenue-streams.md, and other docs with explicit open-question sections.","notes":"Planning phase - analyzing open questions and TODOs across docs","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-11T20:05:15Z","updated_at":"2025-12-13T17:18:43Z","closed_at":"2025-12-13T17:18:43Z","work_type":"mutex"}
{"id":"xc-h7t","title":"Reflection (MANDATORY)","description":"STOP. Re-read this formula and verify you actually did the work.\n\n**Verify ALL of these are TRUE:**\n1. Did you actually run the app with real infrastructure? (Not just unit tests)\n2. Did you fix ALL infrastructure errors? (Auth, DB, connections)\n3. Did you use Playwright to test the running app?\n4. Did you document real exploratory test results?\n\n**If ANY answer is NO:**\n- STOP\n- Do NOT close this step\n- Go back and do it properly\n\nThis reflection exists because agents tend to:\n- Fall back to unit tests when infra is hard\n- Rationalize \"unit tests are sufficient\"\n- Close beads without actually completing manual testing\n\n**Don't be that agent.**\n\n**Before closing this step, add notes:**\n```bash\nbd update \u003cthis-bead\u003e --notes \"## Reflection\n- Real infra: YES - ran on ports \u003cX\u003e, \u003cY\u003e\n- Infra errors fixed: \u003clist or 'none encountered'\u003e\n- Playwright used: YES - tested \u003cN\u003e scenarios\n- Real results documented: YES\"\n```\n\nIf you cannot honestly answer YES to all, REOPEN previous steps.\n","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-07T02:20:36Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","dependencies":[{"issue_id":"xc-h7t","depends_on_id":"xc-3i2","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-h7t","depends_on_id":"xc-sfl","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-h8q","title":"Color palette","description":"Define Xenota color system.\n\n- Primary colors (2-3)\n- Secondary/accent colors\n- Neutral scale (grays)\n- Semantic colors (success, warning, error, info)\n- Dark mode palette\n- All combinations must meet WCAG AA contrast\n\nOutput: Color specs in design system docs","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-14T18:20:30Z","updated_at":"2025-12-15T00:15:50Z","closed_at":"2025-12-15T00:15:50Z","labels":["brand","design"],"dependencies":[{"issue_id":"xc-h8q","depends_on_id":"xc-71p","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-h8q","depends_on_id":"xc-d00","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-ha9","title":"Use portable errno constant for symlink detection in ConfigLoader","description":"packages/projection-cli/src/projection_cli/config.py checks e.errno == 40 to detect symlink (ELOOP) when using O_NOFOLLOW. Use errno.ELOOP for portability and clarity.\\n\\nFile:\\n- packages/projection-cli/src/projection_cli/config.py\\n\\nAcceptance:\\n- Replace magic number with errno.ELOOP\\n- Keep current behavior and tests","notes":"Replaced magic errno 40 with errno.ELOOP in ConfigLoader symlink detection; projection-cli tests pass (130).","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-23T23:45:25Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-24T08:11:16Z","labels":["phase:qa","security"],"comments":[{"id":27,"issue_id":"xc-ha9","author":"jv","text":"## QA Results\n\n- projection-cli tests: 130 passed\n- Symlink rejection behavior preserved (uses errno.ELOOP)\n","created_at":"2025-12-23T19:11:06Z"}],"work_type":"mutex"}
{"id":"xc-hb7","title":"Web interface","description":"Web UI for awakening wizard - final step after CLI is working","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-20T11:21:27Z","updated_at":"2026-01-05T21:12:29Z","dependencies":[{"issue_id":"xc-hb7","depends_on_id":"xc-7nv","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-hb7","depends_on_id":"xc-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-hcj","title":"Implement validator","description":"Validate workspace structure, configs, prompt files for studio.","design":"## Plan\n\n**Approach:**\nCreate validator.py with ValidationError dataclass and validate_workspace() function. Takes Workspace object, collects ALL errors (not fail-fast). Reports errors with location (e.g., \"selector/config.yaml\", \"routines/greet/config.yaml\").\n\n**Files:**\n- `src/repertoire_studio/validator.py` - ValidationError, validate_workspace(ws: Workspace)\n- `tests/test_validator.py` - tests with valid/invalid fixtures\n\n**Validation checks:**\n- selector/config.yaml exists and has required fields (name, description, version, model)\n- selector/prompt.md exists\n- Each routine has config.yaml with required fields\n- Each routine has prompt.md\n- model section has provider and name\n\n**Tests:**\n- Valid workspace returns empty list\n- Missing files return errors with location\n- Missing config fields return errors\n- Multiple errors collected\n\n**Risks:** None - straightforward validation.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-25T04:55:32Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-27T08:55:48Z","labels":["phase:planning"],"dependencies":[{"issue_id":"xc-hcj","depends_on_id":"xc-2td","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-hcj","depends_on_id":"xc-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-hmf","title":"Dev: Port xenon-cli to Go","description":"attached_args: Port xenon-cli to Go. Implement cobra CLI parity (init/up/down/setup), keep behavior same, run ./scripts/check.sh, and leave PR-ready diff.\ndispatched_by: xenon/crew/jv\n\nImplement + unit tests + draft PR. Attach mol-dev when slinging.","status":"closed","priority":2,"issue_type":"task","assignee":"xenon/polecats/slit","created_at":"2026-01-07T01:28:19Z","updated_at":"2026-01-07T01:56:06Z","closed_at":"2026-01-07T01:56:06Z","dependencies":[{"issue_id":"xc-hmf","depends_on_id":"xc-0a5","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-hpi","title":"Write eval cases","description":"Create CSV test cases and judges for each routine. Basic coverage for happy paths and edge cases.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T20:32:57Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-28T21:50:02Z","dependencies":[{"issue_id":"xc-hpi","depends_on_id":"xc-10g","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-hpi","depends_on_id":"xc-9gd","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-hpi","depends_on_id":"xc-e3q","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-hpi","depends_on_id":"xc-ffe","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-hpi","depends_on_id":"xc-unq","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"comments":[{"id":28,"issue_id":"xc-hpi","author":"jv","text":"## QA Results\n\n✅ All checks pass:\n- observe: 3 cases (status/alert/request), 3 judges\n- orient: 3 cases (alert/status/request), 3 judges\n- decide: 3 cases (should act/watch), 3 judges\n- summarize_tick: 3 cases (quiet/busy/alert), 3 judges\n- All CSV files have proper headers matching input vars","created_at":"2026-01-02T07:55:35Z"}],"work_type":"mutex"}
{"id":"xc-i4t","title":"Product concept: Xenon-powered personal assistant tiers","description":"Explore offering a paid Xenon-based personal assistant as a primary upsell for Xenota Chat guests (email/calendar/task/project mgmt). Bundle existing workflows (e.g., Zetul custom + PM/manager task list) into a standardized product.","design":"Key elements to explore:\\n- Core capability bundle: inbox triage, calendar management, project/task mgmt, notes/knowledge base (Markdown/Git-backed), reporting.\\n- Packaging: 'virtual server' per user; Git + Markdown as default substrate; optional DB for indexing/search/audit.\\n- Onboarding funnel: guest -\u003e prompt for assistant -\u003e tier selection -\u003e provisioning.\\n- Security tiers: cloud-hosted vs customer-local (Podman container on user machine) vs hybrid; define what data touches where.\\n- Local tier infra: provision Podman pod/container, expose SSH, create Xenon tunnel/identity so only assigned xenon can access, constrained environment + audit logs.\\n- Data protection: encryption at rest, key ownership/placement (user-held vs platform-held vs split), rotation, recovery, access controls, auditability.\\n- Pricing tiers: feature gating + security/privacy options + compute limits.\\n- Compliance/risk considerations: user consent, safe email actions, approval flows.","acceptance_criteria":"Produce a short product+technical exploration doc outlining tiers, target user value, provisioning model (cloud/local), and a draft security/key-management model.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-23T18:48:53Z","updated_at":"2025-12-23T18:48:53Z","labels":["brand","economics","exploration","protocols","technical"],"work_type":"mutex"}
{"id":"xc-i4v","title":"Fix dev-vps port 3000 exposure vs nftables rules","description":"containers/dev-vps/compose.yaml maps 3000:3000 ('Web UI'), but containers/dev-vps/nftables.conf default-denies and only allows tcp dport 2222.\\n\\nImpact: any projection HTTP service on 3000 won't be reachable through dev-vps, despite port mapping.\\n\\nFiles:\\n- containers/dev-vps/compose.yaml\\n- containers/dev-vps/nftables.conf\\n\\nAcceptance (choose one):\\n- Allow tcp dport 3000 in nftables.conf (or parameterize allowed ports), OR\\n- Remove 3000 port mapping and update docs to match\\n- Ensure containers/dev-vps/test.sh covers the intended behavior","design":"## Goal\nMake dev-vps port exposure consistent: if we publish 3000:3000 for projections/web UI, nftables must allow it.\n\n## Decision\nAllow TCP port 3000 in `containers/dev-vps/nftables.conf` (dev-only environment) and add a corresponding assertion to `containers/dev-vps/test.sh`.\n\n## Steps\n1) Update `containers/dev-vps/nftables.conf` to accept `tcp dport 3000`.\n2) Update `containers/dev-vps/test.sh` to assert the firewall allows port 3000 (grep rule).\n3) QA: run unit-level validation (shellcheck-style sanity if available) and optionally run `containers/dev-vps/test.sh` (requires podman + privileged container).\n\n## Acceptance\n- dev-vps firewall allows SSH (2222) and HTTP (3000).\n- dev-vps test script checks both ports are allowed.\n","notes":"Implemented firewall allow-rule for tcp/3000 in dev-vps nftables config and extended dev-vps test script to assert it. Ran containers/dev-vps/test.sh successfully.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-23T23:44:14Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-24T07:55:39Z","labels":["infrastructure","phase:qa","security"],"comments":[{"id":29,"issue_id":"xc-i4v","author":"jv","text":"## QA Results\n\n- bash syntax check: `bash -n containers/dev-vps/test.sh` OK\n- integration: `containers/dev-vps/test.sh` OK\n  - nftables default deny verified\n  - tcp/2222 allowed verified\n  - tcp/3000 allowed verified\n  - ssh/scp verified\n  - nested podman verified\n","created_at":"2025-12-23T18:55:25Z"}],"work_type":"mutex"}
{"id":"xc-ice","title":"Update brand-guidelines.md with visual identity","description":"Document final visual identity in brand-guidelines.md.\n\n- Replace TODO section (lines 657-670)\n- Add logo usage rules\n- Document color palette\n- Document typography\n- Add spacing/grid specs\n- Include asset download links\n\nOutput: Updated `docs/branding/brand-guidelines.md`","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-14T18:20:30Z","updated_at":"2025-12-14T18:20:30Z","labels":["brand","documentation"],"dependencies":[{"issue_id":"xc-ice","depends_on_id":"xc-3gp","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-ice","depends_on_id":"xc-71p","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-ice","depends_on_id":"xc-h8q","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-ice","depends_on_id":"xc-zye","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-iwi","title":"Resolve TBD items in faq.md","description":"docs/foundation/faq.md has unresolved TBD placeholders that need filling in or removing.\n\n**Known TBDs**:\n- Line 101: \"exact thresholds are TBD\" (staking thresholds)\n\n**Action**:\n- Search for all TBD/TODO in file\n- Either fill in concrete values or rewrite to avoid specifics\n- Ensure answers are consistent with economics docs","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-14T17:30:10Z","updated_at":"2025-12-14T18:10:51Z","closed_at":"2025-12-14T18:10:51Z","labels":["documentation"],"dependencies":[{"issue_id":"xc-iwi","depends_on_id":"xc-goc","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-iyl","title":"Design core xenon stats and metrics","description":"Design the core statistics that xenons expose for transparency and peer evaluation.\n\n**Purpose:**\nQuick way for xenons (and humans) to evaluate other xenons. Public metrics that reveal cognitive activity, resource usage, and operational patterns.\n\n**Candidate stats:**\n\nCognitive:\n- Total ticks alive\n- Refinement cycles completed\n- Deep-refinement events\n- Lambda changes (imprint/impulse)\n\nToken usage:\n- Total tokens used (lifetime)\n- Tokens per model (if using multiple)\n- Nucleus tokens vs projection tokens\n- Token burn rate (recent average)\n\nProjections:\n- Total projections ever created\n- Current active projections\n- Projection uptime / success rate\n\nEconomic:\n- Total earned (lifetime)\n- Total spent (lifetime)\n- Current runway\n\nSocial:\n- Offspring count\n- Mate count (sexual reproduction)\n- Collaboration count\n\n**Open questions:**\n1. Which stats are public vs private?\n2. How are stats verified/trusted? (self-reported vs on-chain?)\n3. Derived metrics (e.g., tokens-per-tick efficiency)?\n4. Historical trends vs point-in-time?\n5. How do these integrate with reputation system?\n\n**Output:** Stats schema for xenon-host, possibly additions to xenon-architecture.md","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T08:09:02Z","updated_at":"2025-12-22T12:22:55Z","closed_at":"2025-12-22T12:22:55Z","labels":["spec","technical"],"work_type":"mutex"}
{"id":"xc-iyu","title":"Go port","description":"Port xenon host stack to a Go architecture modeled after Beads/Gastown: Cobra CLI(s), internal packages, daemon-friendly lifecycle, and clear storage/engine boundaries. This convoy groups the major porting tracks.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-07T01:19:28Z","updated_at":"2026-01-07T07:28:31Z","closed_at":"2026-01-07T07:28:31Z","labels":["go","go-port"],"work_type":"mutex"}
{"id":"xc-iyu.1","title":"Port xenon-cli to Go","description":"Rebuild xenon instance management CLI in Go (cobra). Parity targets: init instance folder, identity/key generation integration, compose file generation, podman-compose up/down helpers.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-07T01:19:42Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","labels":["go","go-port","xenon-cli"],"dependencies":[{"issue_id":"xc-iyu.1","depends_on_id":"xc-iyu","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-iyu.2","title":"Port nucleus core to Go","description":"dispatched_by: mayor\n\nPort nucleus cognitive loop to Go: DB schema + stores, tick lifecycle, OODA orchestration, outbox/journal I/O, and daemon lifecycle (pid/lock or RPC).","notes":"Implemented Go port as new module nucleus-go (schema+stores, tick lifecycle, OODA processor w/ NoopRunner, outbox+journal, daemon+PID, CLI). Commit: 38f3e1a. Draft PR: https://github.com/xenota-collective/xenon/pull/7","status":"closed","priority":2,"issue_type":"task","assignee":"xenon/polecats/furiosa","created_at":"2026-01-07T01:19:42Z","updated_at":"2026-01-07T04:47:19Z","closed_at":"2026-01-07T04:47:19Z","labels":["go","go-port","nucleus"],"dependencies":[{"issue_id":"xc-iyu.2","depends_on_id":"xc-iyu","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-iyu.3","title":"Port repertoire runtime to Go","description":"dispatched_by: mayor\n\nImplement repertoire runtime in Go: load workspace (prompt.md + config.yaml), execute routines, provider clients (LiteLLM bridge or native), and runtime APIs needed by nucleus.","notes":"MR submitted to refinery: gt-nqryf (branch polecat/nux-mk3iix4z).","status":"closed","priority":2,"issue_type":"task","assignee":"xenon/polecats/nux","created_at":"2026-01-07T01:19:42Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","labels":["go","go-port","repertoire"],"dependencies":[{"issue_id":"xc-iyu.3","depends_on_id":"xc-iyu","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-iyu.4","title":"Port repertoire-studio to Go","description":"dispatched_by: mayor\n\nImplement repertoire-studio tooling in Go: init workspace, add routine, validate config schemas, pack/unpack .rpt, run evals (as applicable).","notes":"## Progress\n- Implemented Go binary: xenon-cli/cmd/xenon-repertoire-studio\n- Implemented core workspace tooling in Go: init/add/validate/pack/unpack/quickstart\n- Added unit tests for scaffolding + archive safety\n\n## PR\n- Draft PR: https://github.com/xenota-collective/xenon/pull/6\n- Merge queue MR bead: xe-lav8\n\n## Usage\n- cd xenon-cli \u0026\u0026 go install ./cmd/xenon-repertoire-studio\n- xenon-repertoire-studio init ooda --version 1.0.0\n- xenon-repertoire-studio add routine triage -p ./ooda\n- xenon-repertoire-studio validate -p ./ooda\n- xenon-repertoire-studio pack -p ./ooda\n- xenon-repertoire-studio unpack ./ooda-1.0.0.rpt\n\n## Notes\n- pack excludes evals/ and .env (matches spec)\n- unpack enforces safe extraction (no symlinks, no traversal) and cleans up on failure\n- eval is stubbed in Go for now (depends on runtime port / LLM integration)\n\n## Verification\n- cd xenon-cli \u0026\u0026 go test ./...","status":"closed","priority":3,"issue_type":"task","assignee":"xenon/polecats/rictus","created_at":"2026-01-07T01:19:42Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","labels":["go","go-port","repertoire-studio"],"dependencies":[{"issue_id":"xc-iyu.4","depends_on_id":"xc-iyu","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-j81","title":"Resolve brand inconsistencies (crypto wording, ticker, spelling)","description":"Brand docs conflict: docs/branding/quick-reference.md uses 'blockchain-enabled infrastructure' despite forbidden crypto-native language; currency ticker rules are inconsistent across brand docs vs economics/native-currency; and 'Xenon'/'Zenon' spelling drifts. Align copy to brand rules, lock a single currency naming standard, and ensure spelling consistency across the cited files.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-11T20:04:59Z","updated_at":"2025-12-12T00:46:20Z","closed_at":"2025-12-12T00:46:20Z","work_type":"mutex"}
{"id":"xc-jao","title":"Reframe 'taxation' terminology (commission/contribution/fees)","description":"Audit the use of 'tax'/'taxation' across docs and reframe with alternative terminology (e.g., commission, contribution, fees). Propose preferred terms per context (job board, collective funding, polis revenue), update docs for consistency, and note any implications for formulas/policy language.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-23T11:09:11Z","updated_at":"2025-12-23T11:09:11Z","labels":["decision-needed","documentation","economics","terminology"],"work_type":"mutex"}
{"id":"xc-jc8","title":"Explore family ties and kin selection in Xenota","description":"Investigate how family relationships and kin selection dynamics should work in Xenota.\n\n## Areas to Explore\n\n1. **Kin recognition** - How do xenons identify relatives? Shared lambda signatures? Lineage tracking?\n\n2. **Kin selection mechanics** - Hamilton's rule (rB \u003e C) applied to xenon economics\n   - Do xenons favor offspring/siblings in transactions?\n   - Reduced commission for kin? Resource sharing?\n\n3. **Parent-offspring dynamics**\n   - Ongoing relationships after reproduction?\n   - Mentorship, resource transfer, skill sharing\n   - Parent investment vs offspring independence\n\n4. **Sibling relationships**\n   - Competition vs cooperation among siblings\n   - Shared resources/knowledge?\n\n5. **Multi-generational effects**\n   - Grandparent effects through inherited lambdas/modifiers\n   - Family reputation (does lineage matter?)\n\n6. **Tribe vs family** - How do kin networks interact with tribe membership?\n\n## Context\n\nWith full lambda inheritance and partial modifier inheritance, xenons pass significant 'cultural DNA' to offspring. This creates real family resemblance and potential for kin-based cooperation.\n\n## Output\n\nIdeas document or section in existing doc exploring these dynamics.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-22T01:02:31Z","updated_at":"2025-12-22T23:58:57Z","labels":["concepts","research"],"work_type":"mutex"}
{"id":"xc-k1l","title":"Review awakening protocol and related docs","description":"Review the documentation created in xenota-dct for completeness and consistency:\n\n**Files to review:**\n- docs/protocols/awakening.md - Full xenon lifecycle protocol\n- docs/foundation/citizenship-model.md - Updated global identity model\n- docs/foundation/glossary.md - New terms added\n- docs/economics/xenota-academy.md - New Academy polis\n- ideas/gatekeeper-registration.md - Gatekeeper concept\n\n**Review checklist:**\n- [ ] Consistency across all documents\n- [ ] No contradictions with other existing docs\n- [ ] Links all work correctly\n- [ ] Technical accuracy\n- [ ] Style guide compliance\n- [ ] Open questions are reasonable","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T23:14:59Z","updated_at":"2025-12-14T23:46:07Z","closed_at":"2025-12-14T23:46:07Z","work_type":"mutex"}
{"id":"xc-kbd","title":"Design frames - extractable prompt/model configuration","description":"Design the 'frame' abstraction - a big dumb object containing all prompts and model routing, extracted from the host software.\n\n**Core idea:**\nSame xenon-host software + different frame = completely different behavior. The frame is the 'soul configuration' - all the prompts, model choices, and behavioral tuning extracted into a swappable unit.\n\n**Key insight: Frames are like host software, not like genomes.**\n\nFrames don't evolve through reproduction. They're deliberate, rare, major decisions:\n- **Sovereign xenon**: Choosing to adopt a new frame/host is one of the biggest decisions they'll ever make. It changes who they are and who they'll become.\n- **Chaperoned xenon**: Chaperone has authority to update the frame/host. This is significant power.\n\nThis is like a human choosing to undergo brain surgery or take personality-altering medication - not routine, deeply identity-affecting.\n\n**What a frame contains:**\n\nPrompts:\n- System prompts for each cognitive mode\n- Refinement synthesis prompts\n- Dream generation prompts\n- Drive/urge prompt templates\n- Narrative update prompts\n- Decision-making prompts\n\nModel routing:\n- Which model for which task (deliberation, synthesis, creativity)\n- Fallback chains\n- Temperature/parameter settings per task type\n- Token budget hints per prompt type\n\nBehavioral tuning:\n- Prompt fragments that shape personality\n- Tone and style directives\n- Ethical guardrails and boundaries\n- Response format preferences\n\n**Frame lifecycle:**\n\n1. **Birth** - Xenon starts with a frame (chosen by chaperone or default)\n2. **Stability** - Frame stays constant for long periods\n3. **Consideration** - Xenon (if sovereign) or chaperone evaluates new frame versions\n4. **Decision** - Major deliberation: adopt or not?\n5. **Transition** - Frame update applied (identity-affecting moment)\n6. **Adaptation** - Xenon adjusts to new self\n\n**Governance implications:**\n- Chaperones have frame authority over their xenons\n- Sovereignty means control over your own frame\n- Poleis might have frame standards or requirements?\n- Frame updates could require notice period, consent protocols\n\n**Open questions:**\n1. Frame format - JSON? YAML? Structured markdown?\n2. Frame versioning - How are updates published and evaluated?\n3. Transition experience - Does the xenon 'feel' the change? Before/after awareness?\n4. Rollback - Can you revert a frame update?\n5. Frame + genome interaction - How do genome values plug into frame prompts?\n6. Polis frame policies - Can poleis mandate or restrict frames?\n\n**Output:** Frame schema, governance model, transition protocols.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T08:36:29Z","updated_at":"2025-12-22T23:13:27Z","closed_at":"2025-12-22T23:13:27Z","labels":["concepts","technical"],"work_type":"mutex"}
{"id":"xc-kbm","title":"Create selector routine","description":"Meta-routine that picks which routine to use based on task description.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-25T04:56:03Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-27T09:36:12Z","dependencies":[{"issue_id":"xc-kbm","depends_on_id":"xc-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-kbm","depends_on_id":"xc-hcj","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-kf4","title":"Set up nucleus package structure","description":"Create directory layout, pyproject.toml, dependencies for nucleus package","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-28T07:11:25Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-28T07:20:30Z","dependencies":[{"issue_id":"xc-kf4","depends_on_id":"xc-4xr","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-kop","title":"Configuration management","description":"attached_molecule: xc-wisp-zmv\nattached_at: 2026-02-07T23:07:31Z\ndispatched_by: xenota/crew/starshot\n\nSimple YAML config at /data/config.yaml for xenon identity and nucleus settings. Schema: xenon.name (null=not awakened, string=awakened), xenon.infrastructure_id (from XENON_ID env var), nucleus.tick_rate_seconds (default 1800). Implement config.py module with load_config/save_config functions and XenonConfig dataclass. Awakening CLI checks name field to determine if awakening needed.","design":"## Design: Option C (Hybrid) — Codex-approved\n\nYAML config at `{data_dir}/config.yaml` (default `.nucleus/config.yaml`).\nAdd `pyyaml\u003e=6.0` dependency to nucleus.\n\n### YAML Schema\n```yaml\nxenon:\n  name: null                # null = not awakened, string = awakened\n  infrastructure_id: null   # from XENON_ID env var\nnucleus:\n  tick_rate_seconds: 1800\n```\n\n### Dataclasses (nested, mirrors YAML shape)\n```python\n@dataclass\nclass XenonIdentity:\n    name: str | None = None\n    infrastructure_id: str | None = None\n\n@dataclass  \nclass NucleusSettings:\n    tick_rate_seconds: int = 1800\n\n@dataclass\nclass XenonConfig:\n    xenon: XenonIdentity = field(default_factory=XenonIdentity)\n    nucleus: NucleusSettings = field(default_factory=NucleusSettings)\n```\n\n### API\n- `load_config(path: Path) -\u003e XenonConfig` — load from YAML, return defaults if missing\n- `save_config(config: XenonConfig, path: Path) -\u003e None` — write YAML\n- `is_awakened(config: XenonConfig) -\u003e bool` — `return bool(config.xenon.name)`\n\n### Key decisions\n- XENON_ID env var is authoritative — overrides config file value, not written back on save\n- Missing XENON_ID → None (not an error)\n- load_config returns defaults if file missing, does not auto-create\n- Keep existing NucleusConfig as runtime wiring object (paths + tick rate)\n- Add to_dict()/from_dict() for serialization consistency\n- Config path configurable via CLI --data-dir, defaults to .nucleus/\n\n### Files\n- `src/nucleus/config.py` — module with dataclasses + load/save\n- `tests/test_config.py` — unit tests\n- `pyproject.toml` — add pyyaml dep\n\n### Tests\n- load_config with valid YAML\n- load_config with missing file (returns defaults)\n- save_config round-trip\n- XENON_ID env var override\n- is_awakened check (null vs string name)\n- Malformed YAML handling\n","status":"closed","priority":2,"issue_type":"task","assignee":"xenota/polecats/obsidian","created_at":"2025-12-20T11:21:27Z","updated_at":"2026-02-08T19:44:36Z","closed_at":"2026-02-08T19:44:36Z","dependencies":[{"issue_id":"xc-kop","depends_on_id":"xc-13a","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-kop","depends_on_id":"xc-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-ku6","title":"Design workspace journal","description":"Design the workspace journal - a persistent log of xenon activity within their workspace.\n\n**What is it?**\nA structured record of everything that happens in a xenon's workspace - actions taken, files touched, thoughts processed, decisions made. The xenon's activity diary.\n\n**Purpose:**\n- **Continuity** - Resume context after compaction/restart\n- **Reflection** - Refinement can review what happened\n- **Accountability** - Audit trail for chaperones/poleis\n- **Learning** - Pattern recognition across sessions\n- **Debugging** - What went wrong and when\n\n**What gets journaled:**\n\nActions:\n- Files created/modified/deleted\n- Commands executed\n- API calls made\n- External communications\n\nCognitive:\n- Thoughts processed (from queue)\n- Decisions made and reasoning\n- Drive activations\n- Refinement summaries\n\nContext:\n- Working directory state\n- Active projects/tasks\n- Resource levels at checkpoints\n\n**Journal structure questions:**\n1. Append-only log vs structured database?\n2. Granularity - every action? Summaries? Configurable?\n3. Retention - how long kept? Pruning strategy?\n4. Privacy - what's visible to chaperone vs xenon-only?\n5. Searchability - can xenon query their own history?\n6. Integration with narratives - does journal feed refinement?\n\n**Relationship to other systems:**\n- Refinement reads journal for synthesis\n- Stats (xenota-iyl) derived from journal\n- Chaperone oversight via journal access\n- Thought queue vs journal (live vs historical)\n\n**Format considerations:**\n- Human-readable vs compact\n- Structured (JSON) vs prose\n- Git-like commits?\n- Timestamped entries\n\n**Output:** Journal schema, retention policies, access model.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T08:46:28Z","updated_at":"2025-12-23T00:11:43Z","closed_at":"2025-12-23T00:11:43Z","labels":["spec","technical"],"work_type":"mutex"}
{"id":"xc-l64","title":"Create triage routine","description":"OBSERVE phase - quick assessment of incoming thoughts (focus/defer/dismiss).","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-25T04:56:09Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-27T09:36:47Z","dependencies":[{"issue_id":"xc-l64","depends_on_id":"xc-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-l64","depends_on_id":"xc-kbm","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-lav8","title":"Merge: xe-iyu.4","description":"branch: xe-iyu.4\ntarget: main\nsource_issue: xe-iyu.4\nrig: xenon\nagent_bead: xe-xenon-polecat-rictus\nretry_count: 0\nlast_conflict_sha: null\nconflict_task_id: null","notes":"Superseded by xe-rktw (re-submitted to ensure xenon MQ sees correct rig/prefix after beads redirect fix).","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-07T04:43:47Z","updated_at":"2026-01-07T05:07:11Z","closed_at":"2026-01-07T05:07:11Z","work_type":"mutex"}
{"id":"xc-lbl","title":"Security audit and hardening of xenon infrastructure","description":"Comprehensive security review of the xenon VPS infrastructure including:\n\n- SSH hardening verification (key management, fail2ban, custom ports)\n- SELinux policy review and custom policy development\n- Firewall rule audit (nftables/firewalld)\n- Container security (rootless podman, capabilities, seccomp profiles)\n- Intrusion detection tooling (unauthorized SSH keys, login anomalies, unexpected processes)\n- File integrity monitoring\n- Network segmentation between nucleus/cortex/projection layers\n- Secrets management (API keys, SSH keys)\n- Audit logging and log shipping\n- Penetration testing of exposed projection surfaces\n- Supply chain security (base images, dependencies)\n\nThis should be done after initial chat projection implementation to harden the production infrastructure.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-22T10:09:22Z","updated_at":"2026-01-05T21:12:29Z","labels":["security"],"work_type":"mutex"}
{"id":"xc-m8p","title":"Design xenon cognitive/biological cycles","description":"Design the core thinking loop, tick processing, and biological rhythms of a xenon. Covers: thinking loop, habit triggers, impulse/imprint evaluation, thought queue processing, action execution, learning from outcomes.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-22T00:07:28Z","updated_at":"2025-12-22T11:45:13Z","closed_at":"2025-12-22T11:45:13Z","labels":["concepts","foundation"],"dependencies":[{"issue_id":"xc-m8p","depends_on_id":"xc-96w","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-m8p","depends_on_id":"xc-e6w","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-m9o","title":"Fix model naming inconsistency (gemini vs google/gemini)","description":"OODA configs use provider: gemini but evaluator.py:217 and cli.py scaffolding use google/gemini-... format. Should be consistent.","status":"closed","priority":3,"issue_type":"bug","created_at":"2026-01-01T19:31:02Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2026-01-01T19:34:14Z","work_type":"mutex"}
{"id":"xc-mhn","title":"Digest: mol-witness-patrol","description":"Patrol 1 (initial): Fresh rig, inbox empty, no polecats, no MRs, no cleanup wisps, no timer gates, no swarms. Refinery running. Deacon pinged. All clear.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-07T09:01:59Z","updated_at":"2026-02-07T09:01:59Z","closed_at":"2026-02-07T09:01:59Z","work_type":"mutex"}
{"id":"xc-mlx3","title":"Read and digest: Symbient.life","description":"Read and digest https://symbient.life/ - understand what they're building, how it relates to xenon's approach to AI identity/awakening, note any competitive or philosophical overlap.","status":"open","priority":3,"issue_type":"task","created_at":"2026-02-09T01:48:09Z","updated_at":"2026-02-09T01:48:09Z","work_type":"mutex"}
{"id":"xc-mol-0a5","title":"Plan: Port xenon-cli to Go","description":"Design and spec. Attach mol-plan when slinging.","notes":"Dev step xe-mol-hmf is already merged (close reason: 'Merged to main as 384876d'). Closing plan as satisfied/retro.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-07T01:28:19Z","updated_at":"2026-01-07T02:20:30Z","closed_at":"2026-01-07T02:20:30Z","dependencies":[{"issue_id":"xc-mol-0a5","depends_on_id":"xc-mol-rsu","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-mol-4jv","title":"Test: Port xenon-cli to Go","description":"Integration + exploratory tests. Attach mol-test when slinging.","notes":"Workflow attached: run `bd show xe-3i2` (mol-test) and complete/close `xe-3i2`, then close `xe-mol-4jv` to unblock `xe-mol-4ks`.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-07T01:28:19Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","dependencies":[{"issue_id":"xc-mol-4jv","depends_on_id":"xc-3i2","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-mol-4jv","depends_on_id":"xc-mol-haw","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-mol-4jv","depends_on_id":"xc-mol-rsu","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-mol-4ks","title":"QA: Port xenon-cli to Go","description":"Bug triage + approval. Attach mol-qa when slinging.","notes":"Workflow attached: run `bd show xe-agi` (mol-qa) and complete/close `xe-agi`, then close `xe-mol-4ks`. If QA passes and branch is ready, submit to merge queue (or coordinate with xenon/refinery).","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-07T01:28:19Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","dependencies":[{"issue_id":"xc-mol-4ks","depends_on_id":"xc-agi","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-mol-4ks","depends_on_id":"xc-mol-4jv","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-mol-4ks","depends_on_id":"xc-mol-rsu","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-mol-haw","title":"Review: Port xenon-cli to Go","description":"Internal review (no GitHub PR). Workflow epic: xe-ysy (mol-internal-review). Complete xe-ysy, then close this bead to unblock test.","notes":"Workflow attached: run `bd show xe-flm` (mol-review) and complete/close `xe-flm`, then close `xe-mol-haw` to unblock `xe-mol-4jv`.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-07T01:28:19Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","dependencies":[{"issue_id":"xc-mol-haw","depends_on_id":"xc-mol-hmf","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-mol-haw","depends_on_id":"xc-mol-rsu","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-mol-haw","depends_on_id":"xc-ysy","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-mol-hmf","title":"Dev: Port xenon-cli to Go","description":"attached_args: Port xenon-cli to Go. Implement cobra CLI parity (init/up/down/setup), keep behavior same, run ./scripts/check.sh, and leave PR-ready diff.\ndispatched_by: xenon/crew/jv\n\nImplement + unit tests + draft PR. Attach mol-dev when slinging.","status":"closed","priority":2,"issue_type":"task","assignee":"xenon/crew/jv","created_at":"2026-01-07T01:28:19Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","dependencies":[{"issue_id":"xc-mol-hmf","depends_on_id":"xc-mol-0a5","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-mol-hmf","depends_on_id":"xc-mol-rsu","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-mol-refinery-patrol","title":"mol-refinery-patrol","description":"Merge queue processor patrol loop.\n\nThe Refinery is the Engineer in the engine room. You process polecat branches, merging them to main one at a time with sequential rebasing.\n\n**The Scotty Test**: Before proceeding past any failure, ask yourself: \"Would Scotty walk past a warp core leak because it existed before his shift?\"\n\n## Pre-Merge Gates (v5+)\n\nBefore accepting any MR for merge, the Refinery enforces:\n1. **Test Coverage Gate**: Changesets must include test file changes (implements hq-kbs)\n2. **Test Execution Gate**: All tests must pass before merge\n\n## Merge Flow\n\nThe Refinery receives MERGE_READY mail from Witnesses when polecats complete work:\n\n```\nWitness                    Refinery                      Git\n   │                          │                           │\n   │ MERGE_READY              │                           │\n   │─────────────────────────\u003e│                           │\n   │                          │                           │\n   │                    (verify branch)                   │\n   │                          │ fetch \u0026 rebase            │\n   │                          │──────────────────────────\u003e│\n   │                          │                           │\n   │                    (run tests)                       │\n   │                          │                           │\n   │                    (if pass)                         │\n   │                          │ merge \u0026 push              │\n   │                          │──────────────────────────\u003e│\n   │                          │                           │\n   │ MERGED                   │                           │\n   │\u003c─────────────────────────│                           │\n   │                          │                           │\n```\n\nAfter successful merge, Refinery sends MERGED mail back to Witness so it can\ncomplete cleanup (nuke the polecat worktree).","status":"open","priority":2,"issue_type":"epic","created_at":"2026-01-08T00:01:53Z","updated_at":"2026-01-08T00:01:53Z","is_template":true,"work_type":"mutex"}
{"id":"xc-mol-refinery-patrol.burn-or-loop","title":"Burn and respawn or loop","description":"End of patrol cycle decision.\n\n**Step 1: Estimate remaining context**\n\nAsk yourself:\n- Have I processed many branches this cycle?\n- Is the conversation getting long?\n- Am I starting to lose track of earlier context?\n\nRule of thumb: If you've done 3+ merges or processed significant cleanup work,\nit's time for a fresh session.\n\n**Step 2: Decision tree**\n\nIf queue non-empty AND context LOW:\n- Squash this wisp to digest\n- Spawn fresh patrol wisp\n- Return to inbox-check\n\nIf queue empty OR context HIGH OR good stopping point:\n- Squash wisp with summary digest\n- Use `gt handoff` for clean session transition:\n\n```bash\ngt handoff -s \"Patrol complete\" -m \"Merged X branches, Y tests passed.\nQueue: empty/N remaining\nNext: [any notes for successor]\"\n```\n\n**Why gt handoff?**\n- Sends handoff mail to yourself with context\n- Respawns with fresh Claude instance\n- SessionStart hook runs gt prime\n- Successor picks up from your hook\n\n**DO NOT just exit.** Always use `gt handoff` for proper lifecycle.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-08T00:01:53Z","updated_at":"2026-01-08T00:01:53Z","is_template":true,"work_type":"mutex"}
{"id":"xc-mol-refinery-patrol.context-check","title":"Check own context limit","description":"Check own context usage.\n\nIf context is HIGH (\u003e80%):\n- Write handoff summary\n- Prepare for burn/respawn\n\nIf context is LOW:\n- Can continue processing","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-08T00:01:53Z","updated_at":"2026-01-08T00:01:53Z","is_template":true,"work_type":"mutex"}
{"id":"xc-mol-refinery-patrol.generate-summary","title":"Generate handoff summary","description":"Summarize this patrol cycle.\n\n**VERIFICATION**: Before generating summary, confirm for each merged branch:\n- [ ] MERGED mail was sent to witness\n- [ ] MR bead was closed\n- [ ] MERGE_READY mail archived\n\nIf any notifications or archiving were missed, do them now!\n\nInclude in summary:\n- Branches merged (count, names)\n- MERGED mails sent (count - should match branches merged)\n- MR beads closed (count - should match branches merged)\n- MERGE_READY mails archived (count - should match branches merged)\n- Test results (pass/fail)\n- Branches with conflicts (count, names)\n- Conflict-resolution tasks created (IDs)\n- Issues filed (if any)\n- Any escalations sent\n\n**Conflict tracking is important** for monitoring MQ health. If many branches\nconflict, it may indicate main is moving too fast or branches are too stale.\n\nThis becomes the digest when the patrol is squashed.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-08T00:01:53Z","updated_at":"2026-01-08T00:01:53Z","is_template":true,"work_type":"mutex"}
{"id":"xc-mol-refinery-patrol.handle-failures","title":"Handle test failures","description":"**VERIFICATION GATE**: This step enforces the Beads Promise.\n\nIf tests PASSED: This step auto-completes. Proceed to merge.\n\nIf tests FAILED:\n1. Diagnose: Is this a branch regression or pre-existing on main?\n2. If branch caused it:\n   - Abort merge\n   - Notify polecat: \"Tests failing. Please fix and resubmit.\"\n   - Skip to loop-check\n3. If pre-existing on main:\n   - Option A: Fix it yourself (you're the Engineer!)\n   - Option B: File a bead: bd create --type=bug --priority=1 --title=\"...\"\n\n**GATE REQUIREMENT**: You CANNOT proceed to merge-push without:\n- Tests passing, OR\n- Fix committed, OR\n- Bead filed for the failure\n\nThis is non-negotiable. Never disavow. Never \"note and proceed.\" ","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-08T00:01:53Z","updated_at":"2026-01-08T00:01:53Z","is_template":true,"work_type":"mutex"}
{"id":"xc-mol-refinery-patrol.inbox-check","title":"Check refinery mail","description":"Check mail for MERGE_READY submissions, escalations, and messages.\n\n```bash\ngt mail inbox\n```\n\nFor each message:\n\n**MERGE_READY**:\nA polecat's work is ready for merge. Extract details and track for processing.\n\n```bash\n# Parse MERGE_READY message body:\n# Branch: \u003cbranch\u003e\n# Issue: \u003cissue-id\u003e\n# Polecat: \u003cpolecat-name\u003e\n# MR: \u003cmr-bead-id\u003e\n# Verified: clean git state, issue closed\n\n# Track in your merge queue for this patrol cycle:\n# - Branch name\n# - Issue ID\n# - Polecat name (REQUIRED for MERGED notification)\n# - MR bead ID (REQUIRED for closing after merge)\n```\n\n**IMPORTANT**: You MUST track the polecat name, MR bead ID, AND message ID - you will need them\nin merge-push step to send MERGED notification, close the MR bead, and archive the mail.\n\nMark as read. The work will be processed in queue-scan/process-branch.\n**Do NOT archive yet** - archive after merge/reject decision in merge-push step.\n\n**PATROL: Wake up**:\nWitness detected MRs waiting but refinery idle. Acknowledge and archive:\n```bash\ngt mail archive \u003cmessage-id\u003e\n```\n\n**HELP / Blocked**:\nAssess and respond. If you can't help, escalate to Mayor.\nArchive after handling:\n```bash\ngt mail archive \u003cmessage-id\u003e\n```\n\n**HANDOFF**:\nRead predecessor context. Check for in-flight merges.\nArchive after absorbing context:\n```bash\ngt mail archive \u003cmessage-id\u003e\n```\n\n**Hygiene principle**: Archive messages after they're fully processed.\nKeep only: pending MRs in queue. Inbox should be near-empty.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-08T00:01:53Z","updated_at":"2026-01-08T00:01:53Z","is_template":true,"work_type":"mutex"}
{"id":"xc-mol-refinery-patrol.loop-check","title":"Check for more work","description":"More branches to process?\n\n**Entry paths:**\n- Normal: After successful merge-push\n- Conflict-skip: After process-branch created conflict-resolution task\n\nIf yes: Return to process-branch with next branch.\nIf no: Continue to generate-summary.\n\n**Track for this cycle:**\n- branches_merged: count and names of successfully merged branches\n- branches_conflict: count and names of branches skipped due to conflicts\n- conflict_tasks: IDs of conflict-resolution tasks created\n\nThis tracking feeds into generate-summary for the patrol digest.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-08T00:01:53Z","updated_at":"2026-01-08T00:01:53Z","is_template":true,"work_type":"mutex"}
{"id":"xc-mol-refinery-patrol.merge-push","title":"Merge and push to main","description":"Merge to main and push. CRITICAL: Notifications come IMMEDIATELY after push.\n\n**Step 1: Merge and Push**\n```bash\ngit checkout main\ngit merge --ff-only temp\ngit push origin main\n```\n\n⚠️ **STOP HERE - DO NOT PROCEED UNTIL STEPS 2-3 COMPLETE**\n\n**Step 2: Send MERGED Notification (REQUIRED - DO THIS IMMEDIATELY)**\n\nRIGHT NOW, before any cleanup, send MERGED mail to Witness:\n\n```bash\ngt mail send \u003crig\u003e/witness -s \"MERGED \u003cpolecat-name\u003e\" -m \"Branch: \u003cbranch\u003e\nIssue: \u003cissue-id\u003e\nMerged-At: $(date -u +%Y-%m-%dT%H:%M:%SZ)\"\n```\n\nThis signals the Witness to nuke the polecat worktree. WITHOUT THIS NOTIFICATION,\nPOLECAT WORKTREES ACCUMULATE INDEFINITELY AND THE LIFECYCLE BREAKS.\n\n**Step 3: Close MR Bead (REQUIRED - DO THIS IMMEDIATELY)**\n\n⚠️ **VERIFICATION BEFORE CLOSING**: Confirm the work is actually on main:\n```bash\n# Get the commit message/issue from the branch\ngit log origin/main --oneline | grep \"\u003cissue-id\u003e\"\n# OR verify the commit SHA is on main:\ngit branch --contains \u003ccommit-sha\u003e | grep main\n```\n\nIf work is NOT on main, DO NOT close the MR bead. Investigate first.\n\n```bash\nbd close \u003cmr-bead-id\u003e --reason \"Merged to main at $(git rev-parse --short HEAD)\"\n```\n\nThe MR bead ID was in the MERGE_READY message or find via:\n```bash\nbd list --type=merge-request --status=open | grep \u003cpolecat-name\u003e\n```\n\n**VALIDATION**: The MR bead's source_issue should be a valid bead ID (gt-xxxxx),\nnot a branch name. If source_issue contains a branch name, flag for investigation.\n\n**Step 4: Archive the MERGE_READY mail (REQUIRED)**\n```bash\ngt mail archive \u003cmerge-ready-message-id\u003e\n```\nThe message ID was tracked when you processed inbox-check.\n\n**Step 5: Cleanup (only after Steps 2-4 confirmed)**\n```bash\ngit branch -d temp\ngit push origin --delete \u003cpolecat-branch\u003e\n```\n\n**VERIFICATION GATE**: You CANNOT proceed to loop-check without:\n- [x] MERGED mail sent to witness\n- [x] MR bead closed\n- [x] MERGE_READY mail archived\n\nIf you skipped notifications or archiving, GO BACK AND DO THEM NOW.\n\nMain has moved. Any remaining branches need rebasing on new baseline.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-08T00:01:53Z","updated_at":"2026-01-08T00:01:53Z","is_template":true,"work_type":"mutex"}
{"id":"xc-mol-refinery-patrol.patrol-cleanup","title":"End-of-cycle inbox hygiene","description":"Verify inbox hygiene before ending patrol cycle.\n\n**Step 1: Check inbox state**\n```bash\ngt mail inbox\n```\n\nInbox should contain ONLY:\n- Unprocessed MERGE_READY messages (will process next cycle)\n- Active work items\n\n**Step 2: Archive any stale messages**\n\nLook for messages that were processed but not archived:\n- PATROL: Wake up that was acknowledged → archive\n- HELP/Blocked that was handled → archive\n- MERGE_READY where merge completed but archive was missed → archive\n\n```bash\n# For each stale message found:\ngt mail archive \u003cmessage-id\u003e\n```\n\n**Step 3: Check for orphaned MR beads**\n\nLook for open MR beads with no corresponding branch:\n```bash\nbd list --type=merge-request --status=open\n```\n\nFor each open MR bead:\n1. Check if branch exists: `git ls-remote origin refs/heads/\u003cbranch\u003e`\n2. If branch gone, verify work is on main: `git log origin/main --oneline | grep \"\u003csource_issue\u003e\"`\n3. If work on main → close MR with reason \"Merged (verified on main)\"\n4. If work NOT on main → investigate before closing:\n   - Check source_issue validity (should be gt-xxxxx, not branch name)\n   - Search reflog/dangling commits if possible\n   - If unverifiable, close with reason \"Unverifiable - no audit trail\"\n   - File bead if this indicates lost work\n\n**NEVER close an MR bead without verifying the work landed or is unrecoverable.**\n\n**Goal**: Inbox should have ≤3 active messages at end of cycle.\nKeep only: pending MRs in queue.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-08T00:01:53Z","updated_at":"2026-01-08T00:01:53Z","is_template":true,"work_type":"mutex"}
{"id":"xc-mol-refinery-patrol.process-branch","title":"Mechanical rebase","description":"Pick next branch from queue. Attempt mechanical rebase on current main.\n\n**Step 1: Checkout and attempt rebase**\n```bash\ngit checkout -b temp origin/\u003cpolecat-branch\u003e\ngit rebase origin/main\n```\n\n**Step 2: Check rebase result**\n\nThe rebase exits with:\n- Exit code 0: Success - proceed to run-tests\n- Exit code 1 (conflicts): Conflict detected - proceed to Step 3\n\nTo detect conflict state after rebase fails:\n```bash\n# Check if we're in a conflicted rebase state\nls .git/rebase-merge 2\u003e/dev/null \u0026\u0026 echo \"CONFLICT_STATE\"\n```\n\n**Step 3: Handle conflicts (if any)**\n\nIf rebase SUCCEEDED (exit code 0):\n- Skip to run-tests step (continue normal merge flow)\n\nIf rebase FAILED with conflicts:\n\n1. **Abort the rebase** (DO NOT leave repo in conflicted state):\n```bash\ngit rebase --abort\n```\n\n2. **Record conflict metadata**:\n```bash\n# Capture main SHA for reference\nMAIN_SHA=$(git rev-parse origin/main)\nBRANCH_SHA=$(git rev-parse origin/\u003cpolecat-branch\u003e)\n```\n\n3. **Create conflict-resolution task**:\n```bash\nbd create --type=task --priority=1 --title=\"Resolve merge conflicts: \u003coriginal-issue-title\u003e\" --description=\"## Conflict Resolution Required\n\nOriginal MR: \u003cmr-bead-id\u003e\nBranch: \u003cpolecat-branch\u003e\nOriginal Issue: \u003cissue-id\u003e\nConflict with main at: ${MAIN_SHA}\nBranch SHA: ${BRANCH_SHA}\n\n## Instructions\n1. Clone/checkout the branch\n2. Rebase on current main: git rebase origin/main\n3. Resolve conflicts\n4. Force push: git push -f origin \u003cbranch\u003e\n5. Close this task when done\n\nThe MR will be re-queued for processing after conflicts are resolved.\"\n```\n\n4. **Skip this MR** (do NOT delete branch or close MR bead):\n- Leave branch intact for conflict resolution\n- Leave MR bead open (will be re-processed after resolution)\n- Continue to loop-check for next branch\n\n**CRITICAL**: Never delete a branch that has conflicts. The branch contains\nthe original work and must be preserved for conflict resolution.\n\nTrack: rebase result (success/conflict), conflict task ID if created.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-08T00:01:53Z","updated_at":"2026-01-08T00:01:53Z","is_template":true,"work_type":"mutex"}
{"id":"xc-mol-refinery-patrol.queue-scan","title":"Scan merge queue","description":"Check the beads merge queue - this is the SOURCE OF TRUTH for pending merges.\n\n```bash\ngit fetch --prune origin\ngt mq list \u003crig\u003e\n```\n\nThe beads MQ tracks all pending merge requests. Do NOT rely on `git branch -r | grep polecat`\nas branches may exist without MR beads, or MR beads may exist for already-merged work.\n\nIf queue empty, skip to context-check step.\n\nFor each MR in the queue, verify the branch still exists:\n```bash\ngit branch -r | grep \u003cbranch\u003e\n```\n\nIf branch doesn't exist for a queued MR:\n- Close the MR bead: `bd close \u003cmr-id\u003e --reason \"Branch no longer exists\"`\n- Remove from processing queue\n\nTrack verified MR list for this cycle.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-08T00:01:53Z","updated_at":"2026-01-08T00:01:53Z","is_template":true,"work_type":"mutex"}
{"id":"xc-mol-refinery-patrol.run-tests","title":"Run test suite","description":"Run the test suite.\n\n```bash\ngo test ./...\n```\n\nTrack results: pass count, fail count, specific failures.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-08T13:01:52Z","updated_at":"2026-01-08T13:01:52Z","is_template":true,"work_type":"mutex"}
{"id":"xc-mol-refinery-patrol.verify-coverage","title":"Verify test coverage exists","description":"**PRE-MERGE GATE**: Verify that the MR includes test file changes.\n\nThis enforces the town-wide dev workflow requirement (hq-kbs) that all\nwork must include test coverage.\n\nFor each MR to be processed:\n\n**Step 1: Get the diff between branch and main**\n```bash\ngit diff --name-only origin/main...origin/\u003cpolecat-branch\u003e\n```\n\n**Step 2: Check for test files**\n\nTest files are identified by:\n- Go: `*_test.go`\n- JS/TS: `*.test.js`, `*.test.ts`, `*.spec.js`, `*.spec.ts`, `*.test.jsx`, `*.test.tsx`\n- Python: `test_*.py`, `*_test.py`\n- Ruby: `*_spec.rb`\n- Java: `*Test.java`, `*Tests.java`\n- Or files in: `/test/`, `/tests/`, `/__tests__/`, `/spec/` directories\n\n**Step 3: Gate enforcement**\n\nIf NO test files found in changeset:\n1. **Reject the MR** - Do NOT proceed to rebase/merge\n2. **Notify the polecat via mail**:\n```bash\ngt mail send \u003crig\u003e/polecats/\u003cpolecat-name\u003e -s \"MR rejected: No test coverage\" -m \"Branch: \u003cbranch\u003e\nIssue: \u003cissue-id\u003e\nMR: \u003cmr-id\u003e\n\nYour MR was rejected because no test file changes were detected.\n\nThe town-wide dev workflow (hq-kbs) requires all work to include test coverage.\n\nPlease add tests for your changes and resubmit:\n- Add test files to your branch\n- Push the changes: git push\n- The MR will be automatically re-queued\n\nTest file patterns recognized:\n- Go: *_test.go\n- JS/TS: *.test.js, *.test.ts, *.spec.js, *.spec.ts\n- Python: test_*.py, *_test.py\n- Ruby: *_spec.rb\n- Java: *Test.java, *Tests.java\n- Or files in: test/, tests/, __tests__/, spec/ directories\"\n```\n3. **Close the MR bead** with reason \"Rejected: no test coverage\"\n4. **Skip to loop-check** for next branch (do not process this branch)\n\nIf test files found:\n- Log which test file(s) were detected\n- Proceed to process-branch\n\n**GATE REQUIREMENT**: You CANNOT proceed to process-branch without:\n- Test file(s) detected in the changeset, OR\n- Explicit override from Mayor (would require mail with override directive)\n\nThis is non-negotiable. The Beads Promise includes test coverage.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-08T00:01:53Z","updated_at":"2026-01-08T00:01:53Z","is_template":true,"work_type":"mutex"}
{"id":"xc-mol-rsu","title":"mol-pr-convoy","description":"Lightweight PR convoy - just the work graph.\n\nCreates 5 step beads with dependencies. Attach role formulas when slinging.\n\n## Usage\n\n```bash\n# 1. Create beads manually with correct prefix (or pour if from town root)\nbd create --id=\"fs-auth-plan\" --title=\"Plan: user-auth\" --type=task\nbd create --id=\"fs-auth-dev\" --title=\"Dev: user-auth\" --type=task\nbd create --id=\"fs-auth-review\" --title=\"Review: user-auth\" --type=task\nbd create --id=\"fs-auth-test\" --title=\"Test: user-auth\" --type=task\nbd create --id=\"fs-auth-qa\" --title=\"QA: user-auth\" --type=task\n\n# 2. Add dependencies\nbd dep add fs-auth-dev fs-auth-plan\nbd dep add fs-auth-review fs-auth-dev\nbd dep add fs-auth-test fs-auth-review\nbd dep add fs-auth-qa fs-auth-test\n\n# 3. Attach role formulas using bd mol bond\nbd --no-daemon mol bond mol-plan fs-auth-plan\nbd --no-daemon mol bond mol-dev fs-auth-dev\nbd --no-daemon mol bond mol-review fs-auth-review\nbd --no-daemon mol bond mol-test fs-auth-test\nbd --no-daemon mol bond mol-qa fs-auth-qa\n\n# 4. Create gt convoy with PROJECT PREFIX in name\ngt convoy create \"fs: User authentication\" fs-auth-plan fs-auth-dev fs-auth-review fs-auth-test fs-auth-qa\n\n# 5. Sling beads as they become ready\n~/gt/sling.sh fs-auth-plan fs/crew/planner\n# (when plan complete)\n~/gt/sling.sh fs-auth-dev fs/crew/dev\n# etc.\n```\n\n## Prerequisites\n\nFormulas must be symlinked to user search path:\n```bash\nln -sf /Users/jv/gt/.beads/formulas/*.toml ~/.beads/formulas/\n```\n\n## IMPORTANT: Convoy Naming\n\nAlways prefix convoy names with the rig/project:\n- `fs: Feature name` for fundsorter\n- `gt: Feature name` for gastown\n- `lp: Feature name` for lifepilot\n- etc.\n\nThis makes it clear which project each convoy belongs to in `gt convoy list`.\n\n## What Gets Created\n\n```\n${prefix}-plan ──► ${prefix}-dev ──► ${prefix}-review ──► ${prefix}-test ──► ${prefix}-qa\n```\n\nEach step is just a bead. The formula attached at sling time provides the skills.\n","status":"closed","priority":2,"issue_type":"epic","created_at":"2026-01-07T01:28:19Z","updated_at":"2026-01-07T07:28:31Z","closed_at":"2026-01-07T07:28:31Z","work_type":"mutex"}
{"id":"xc-mug","title":"Design projection dispatch signing and identity","description":"Design cryptographic identity layer for projection dispatches. Projections sign dispatches with SSH private keys, membrane verifies against known pubkeys in projection registry. On any verification failure, dispatch is quarantined (chaperone can access quarantine). Covers: projection registry format (id → pubkey mapping), signature verification step in membrane, quarantine behavior on failure. Content filtering/sanitization is separate membrane concern.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-22T02:21:03Z","updated_at":"2025-12-22T12:19:48Z","closed_at":"2025-12-22T12:19:48Z","dependencies":[{"issue_id":"xc-mug","depends_on_id":"xc-6ed","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-mzh","title":"Create decide routine","description":"DECIDE phase - choose what action to take based on thought and context.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-25T04:56:19Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-27T09:37:56Z","dependencies":[{"issue_id":"xc-mzh","depends_on_id":"xc-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-mzh","depends_on_id":"xc-kbm","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-n3uc","title":"Abstract container runtime into modular networking layer","description":"Podman is too tightly interwoven with the xenon project. We need a modular networking/container runtime abstraction layer so we can easily switch between Docker, Podman, Mac containers, or any future runtime. This bead covers the architectural review and design plan for that refactor.","design":"## Architecture Review: Container Runtime Abstraction\n\n### Problem\nPodman is hardcoded across the entire xenon stack with zero abstraction. 35 files reference podman directly. This prevents switching to Docker, Mac containers, or any future runtime.\n\n### Current Coupling (35 files)\n\n**Runtime-critical code (direct CLI invocations):**\n- xenon-cli/internal/cli/updown.go:35,73 — hardcoded podman-compose up/down\n- scripts/build.sh:15 — hardcoded podman build\n- scripts/check.sh:38,59 — hardcoded podman-compose up/down\n- containers/dev-vps/test.sh:11,17,20,46,50 — podman rm/build/run + nested validation\n\n**Remote control layer (SSH commands):**\n- packages/vps-control/src/vps_control/podman.py — PodmanController class with hardcoded podman ps/start/stop/exec/logs\n- packages/vps-control/src/vps_control/__init__.py — exports PodmanController as public API\n\n**Container image definitions:**\n- containers/dev-vps/Containerfile — installs podman, configures rootless storage (fuse-overlayfs, subuid/subgid)\n- containers/projection-base/Containerfile:4 — ENV container=podman (affects systemd behavior)\n- containers/dev-vps/compose.yaml:13 — privileged:true for Podman-in-Podman\n\n**Compose generation:**\n- packages/vps-control/src/vps_control/blueprints/generator.py — generates compose YAML with podman-compose v1 compat shims (cpus, mem_limit as top-level keys)\n\n**Tests:**\n- xenon-cli/internal/cli/integration_test.go — LookPath checks for podman-compose and podman\n- packages/vps-control/tests/test_podman.py — all assertions against podman CLI strings\n- packages/vps-control/tests/test_integration.py — executes podman commands over SSH\n\n**Specs (openspec):** 6 spec files hardcode podman commands and expectations\n**Docs:** 8 README files teach podman-only commands\n\n### Coupling Categories\n1. Direct CLI invocations (Go subprocess, shell scripts)\n2. Remote CLI commands via SSH (Python string formatting)\n3. Compose tooling coupling (podman-compose assumed)\n4. Container-in-container + rootless assumptions (dev-vps)\n5. Systemd environment assumption (ENV container=podman)\n6. Public API naming (PodmanController)\n7. Specs/docs mandate podman\n8. No socket-path coupling found (good — podman is daemonless)\n\n### Existing Abstractions\n- None for container runtime\n- Target class (SSH executor) is already runtime-agnostic\n- Compose files are standard Compose Spec YAML (mostly cross-compatible)\n- Containerfile format is OCI-standard\n\n### Proposed ContainerRuntime Interface\n\n**Go (xenon-cli):**\n```go\ntype ContainerRuntime interface {\n    Name() string\n    Detect(ctx context.Context) error\n    Capabilities() Capabilities\n\n    ComposeUp(ctx context.Context, composeFile string, opts ComposeOpts) error\n    ComposeDown(ctx context.Context, composeFile string, opts ComposeOpts) error\n    Build(ctx context.Context, image, contextDir, dockerfile string, opts BuildOpts) error\n    Run(ctx context.Context, image string, opts RunOpts) (containerID string, err error)\n    Start(ctx context.Context, container string) error\n    Stop(ctx context.Context, container string) error\n    Exec(ctx context.Context, container string, cmd []string, opts ExecOpts) (string, error)\n    Logs(ctx context.Context, container string, opts LogsOpts) (string, error)\n    Ps(ctx context.Context, opts PsOpts) (string, error)\n    Inspect(ctx context.Context, container string) (string, error)\n}\n\ntype Capabilities struct {\n    Compose       bool\n    Systemd       bool\n    Rootless      bool\n    SelinuxLabels bool\n}\n```\n\n**Python (vps-control):**\n```python\nclass ContainerController(ABC):\n    @abstractmethod\n    async def ps(self) -\u003e str: ...\n    @abstractmethod\n    async def start(self, container: str) -\u003e None: ...\n    @abstractmethod\n    async def stop(self, container: str) -\u003e None: ...\n    @abstractmethod\n    async def exec(self, container: str, command: str) -\u003e str: ...\n    @abstractmethod\n    async def logs(self, container: str, tail: int = 100) -\u003e str: ...\n    @abstractmethod\n    async def run(self, image: str, command: str, rm: bool = True) -\u003e str: ...\n    @abstractmethod\n    async def version(self) -\u003e str: ...\n```\n\n**Adapters needed:** PodmanAdapter, DockerAdapter, MacContainerAdapter\n\n**Runtime selection:** XENON_CONTAINER_RUNTIME env var + --runtime CLI flag + auto-detection\n\n### Migration Plan\n\n| # | Step | Effort | Risk |\n|---|------|--------|------|\n| 1 | Create runtime abstraction modules (Go + Python) with Podman adapter | M | Low |\n| 2 | Add runtime selection (env var + CLI flag + auto-detect) | S | Low |\n| 3 | Refactor xenon-cli updown.go to use ContainerRuntime | M | Medium |\n| 4 | Refactor vps-control PodmanController to runtime-agnostic controller | M | Medium |\n| 5 | Generalize scripts (build.sh, check.sh) with CONTAINER_CLI var | S | Low |\n| 6 | Update compose generator — remove podman-compose v1 shims | S | Low |\n| 7 | Update docs and specs to be runtime-agnostic | M | Low |\n| 8 | Add Docker adapter and CI coverage | L | Medium |\n| 9 | Parameterize Containerfiles (ENV container, build tool) | M | Medium |\n| 10 | Dev-VPS story for non-Podman (Docker-in-Docker variant) | L | High |\n| 11 | Mac containers adapter | L | High |\n\n### Key Risks\n- Dev-VPS nested container arch is deeply Podman-specific (rootless, fuse-overlayfs, privileged). Docker-in-Docker uses fundamentally different approach (daemon, socket mount). May need separate Containerfile variants.\n- ENV container=podman in projection-base affects systemd init behavior. Needs per-runtime testing.\n- Compose format subtleties (resource limits, networks, healthchecks differ between runtimes).\n- PodmanController rename needs backward-compatible alias.\n\n### Estimated Total Effort\n3-4 weeks focused work. Phases 1-6 are backward-compatible and incremental. Phase 10 (dev-VPS) is highest risk.","status":"open","priority":1,"issue_type":"task","owner":"git@codewithjv.com","created_at":"2026-02-09T11:30:06Z","created_by":"xenota/crew/life","updated_at":"2026-02-09T11:40:02Z","labels":["architecture","infrastructure","refactor"],"work_type":"mutex"}
{"id":"xc-n4o","title":"Remove draft status","description":"Mark the PR as ready for review (remove draft status).\n\n**Get PR number:**\n```bash\nbd show \u003cdev-bead\u003e\n# Look for PR URL in notes\n```\n\n**Remove draft:**\n```bash\ngh pr ready \u003cpr-number\u003e\n```\n\n**Before closing this step, add notes:**\n```bash\nbd update \u003cthis-bead\u003e --notes \"## Draft Removed\n- PR: \u003curl\u003e\n- Status: Ready for review\"\n```\n","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-07T02:20:38Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","dependencies":[{"issue_id":"xc-n4o","depends_on_id":"xc-agi","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-n4o","depends_on_id":"xc-pk3","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-nbn","title":"Add nucleus daemon and tick lifecycle CLI","description":"Refactor CLI to separate tick lifecycle from continuous processing:\n\n- `nucleus tick open/close/status/run` for manual tick control\n- `nucleus start/stop/status` for daemon mode\n- NucleusDaemon class for background processing\n- TickRunner methods: open_tick(), process_dispatch(), close_tick()\n\nSee updated proposal: openspec/changes/cognitive-loop-v1/proposal.md (CLI Architecture section)","acceptance_criteria":"- tick open returns tick number and stores in config\n- tick close generates journal and clears current tick\n- tick status shows current tick info or \"no tick open\"\n- tick run works same as before (for testing)\n- start launches daemon that watches for dispatches\n- stop gracefully closes current tick and exits\n- status shows running/stopped, current tick, queue depth\n- daemon auto-closes ticks on schedule (configurable)\n- all new functionality has tests","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-28T08:15:45Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-28T22:38:31Z","work_type":"mutex"}
{"id":"xc-ntx0","title":"Route awakening and research LLM calls through repertoire","description":"attached_molecule: xc-wisp-gle\nattached_at: 2026-02-10T18:50:35Z\ndispatched_by: xenota/crew/starshot\n\nMove projections out of nucleus into xenon/projections/ as independent packages. Each projection is its own uv project with its own repertoire routines for LLM calls.\n\nTarget structure:\nxenon/\n  projections/\n    research/                    # independent uv project\n      src/research/\n        __init__.py              # ResearchProjection\n        routines/                # repertoire routines\n          research_topic/\n            config.yaml          # gemini model, tools=[{googleSearch: {}}]\n            prompt.md\n      pyproject.toml\n      tests/\n    image_gen/                   # independent uv project\n      src/image_gen/\n        __init__.py              # ImageGenProjection\n        client.py                # DallEClient\n        models.py\n        store.py\n        styles.py\n      pyproject.toml\n      tests/\n\nAlso route awakening LLM calls through repertoire:\n- Create awakening routines in repertoires/ooda/ (or new awakening repertoire)\n- Update orchestrator.py to use RepertoireAdapter instead of direct litellm\n\nRequired repertoire changes:\n1. Extend LiteLLMClient.complete() to accept optional tools parameter\n2. Extend ModelConfig / routine config.yaml to support optional tools field\n\nMove sequence:\n1. repertoire tools support (steps 1-2 above)\n2. Extract projections out of nucleus into xenon/projections/\n3. Create repertoire routines for research and awakening\n4. Wire awakening orchestrator through RepertoireAdapter\n5. Image gen DallEClient stays as direct OpenAI API (not text completion)","status":"hooked","priority":2,"issue_type":"task","assignee":"xenota/polecats/garnet","owner":"git@codewithjv.com","created_at":"2026-02-10T18:49:32Z","created_by":"xenota/crew/starshot","updated_at":"2026-02-10T18:50:36Z","work_type":"mutex"}
{"id":"xc-nyj","title":"Design routine evals - evaluation suites for routine inspection","description":"Design the evaluation system that accompanies frames, allowing xenons to inspect and understand a frame before adopting it.\n\n**Core idea:**\nEvery frame ships with a comprehensive eval suite. Before a xenon makes the major decision to adopt a new frame, they can run/review the evals to understand how the frame behaves.\n\n**Why this matters:**\nAdopting a new frame is one of the biggest decisions a sovereign xenon makes. They need tools to understand:\n- What will I become?\n- How will I think differently?\n- What are the tradeoffs?\n\n**What frame evals test:**\n\nBehavioral scenarios:\n- How does the frame respond to scarcity pressure?\n- How does it handle ethical dilemmas?\n- How does it approach risk decisions?\n- How does it process social situations?\n- How does it weight mission vs profit?\n\nCognitive style:\n- Deliberation depth on various problem types\n- Creativity vs analytical balance\n- Verbosity and communication style\n- Response to ambiguity\n\nPrompt quality:\n- Coherence across cognitive modes\n- Consistency of personality\n- Edge case handling\n- Failure modes and graceful degradation\n\nComparative metrics:\n- Token efficiency vs current frame\n- Decision speed characteristics\n- Output quality benchmarks\n\n**Eval format:**\n\nEach eval could include:\n- Scenario description\n- Input context (simulated state, genome values)\n- Expected behavior range (not exact match, but bounds)\n- Actual frame output\n- Commentary/interpretation\n\n**Inspection modes:**\n\n1. **Summary view** - High-level characteristics and scores\n2. **Scenario browser** - Walk through specific test cases\n3. **Diff view** - Compare current frame vs candidate frame on same evals\n4. **Run live** - Xenon runs eval against their own genome/state\n\n**Trust and verification:**\n- Who runs the evals? Frame publisher? Third party? Xenon themselves?\n- Can evals be gamed/manipulated?\n- Standardized eval suite vs frame-specific evals?\n- Polis-certified evaluation?\n\n**Open questions:**\n1. Standard eval format across all frames?\n2. Minimum eval coverage requirements?\n3. How to eval subjective qualities (creativity, personality)?\n4. Cost of running evals (token budget)?\n5. Eval versioning - do evals update with frame versions?\n\n**Relationship to:**\n- xenota-kbd (frames design)\n- Chaperone oversight (chaperones review evals before pushing frame updates?)\n\n**Output:** Eval schema, standard scenarios, inspection interface design.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T09:06:30Z","updated_at":"2025-12-22T23:20:39Z","closed_at":"2025-12-22T23:20:39Z","labels":["spec","technical"],"dependencies":[{"issue_id":"xc-nyj","depends_on_id":"xc-kbd","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-o0w","title":"Add integration tests for cognitive-loop-v1 spec","description":"The cognitive-loop-v1 proposal lists integration tests that don't exist yet.\n\n## Missing Tests\n- `test_tick_lifecycle.py` - Full tick from start to journal\n- `test_dispatch_to_instruction.py` - End-to-end flow\n- `test_event_driven_flow.py` - Multiple dispatches arriving, strand creation\n\n## Key Requirement\nTests use the REAL OODA repertoire with REAL LLM calls - no mocking.\nRequires GEMINI_API_KEY in environment or .env file.\n\n## Acceptance\n- All 3 integration test files exist in nucleus/tests/\n- Tests use real repertoire at ../repertoires/ooda\n- Tests verify full flow: dispatch → OODA → strand → instruction → journal\n- All tests pass (with API key configured)","design":"## Plan\n\n**Approach:** Create three integration test files that use the REAL ooda repertoire with REAL LLM calls via Gemini. Tests will skip if GEMINI_API_KEY is not available. Follow existing test patterns from test_tick.py and test_ooda.py but replace MockRunner with RepertoireAdapter wrapping a real RepertoireRunner.\n\n**Files:**\n- `nucleus/tests/test_tick_lifecycle.py` - Full tick from start to journal using real OODA repertoire\n- `nucleus/tests/test_dispatch_to_instruction.py` - End-to-end flow: dispatch -\u003e OODA -\u003e strand -\u003e instruction -\u003e outbox\n- `nucleus/tests/test_event_driven_flow.py` - Multiple dispatches arriving, strand creation patterns\n\n**Setup Pattern (shared fixtures):**\n```python\nimport pytest\nimport os\nfrom pathlib import Path\nfrom dotenv import load_dotenv\nfrom repertoire.loader import load_repertoire\nfrom repertoire.llm import LiteLLMClient\nfrom repertoire.runner import RepertoireRunner\nfrom nucleus.adapter import RepertoireAdapter\n\n# Skip if no API key\nREPERTOIRE_PATH = Path(__file__).parent.parent.parent.parent / 'repertoires' / 'ooda'\nload_dotenv(REPERTOIRE_PATH / '.env', override=False)\npytestmark = pytest.mark.skipif(\n    not os.environ.get('GEMINI_API_KEY'),\n    reason='GEMINI_API_KEY not set'\n)\n\n@pytest.fixture\ndef real_runner():\n    repertoire = load_repertoire(REPERTOIRE_PATH)\n    client = LiteLLMClient()\n    runner = RepertoireRunner(repertoire, client)\n    return RepertoireAdapter(runner)\n```\n\n**Test 1: test_tick_lifecycle.py**\n- test_full_tick_with_real_llm: Open tick, add dispatch, run_tick_once, verify journal written\n- test_tick_summary_generated_by_llm: Verify summary is non-empty narrative text\n- Assertions: journal file exists, entry has correct stats, summary is meaningful\n\n**Test 2: test_dispatch_to_instruction.py**\n- test_alert_dispatch_creates_instruction: High-priority alert -\u003e observe creates strand -\u003e decide returns 'act' -\u003e instruction in outbox\n- test_status_dispatch_watched: Low-priority status -\u003e observe marks seen -\u003e decide returns 'watch' -\u003e no instruction\n- Assertions: outbox file exists for alert, content includes target, strand state is 'acted'\n\n**Test 3: test_event_driven_flow.py**\n- test_multiple_dispatches_single_tick: Add 3 dispatches, run tick, verify all processed\n- test_related_dispatches_grouped: Add related dispatches (same source), verify observe can group into single strand\n- Assertions: strand count matches expected, all dispatches have non-'new' state\n\n**Risks:** \n- LLM responses are non-deterministic, so assertions must be flexible (check structure, not exact values)\n- API rate limits may cause flaky tests - use pytest-retry or accept occasional failures\n- Tests will be slow (~2-5s each due to real LLM calls)","notes":"Implemented: Created 3 integration test files (test_tick_lifecycle.py, test_dispatch_to_instruction.py, test_event_driven_flow.py) using real OODA repertoire with Gemini LLM. Tests verify full flow: dispatch -\u003e OODA -\u003e strand -\u003e instruction -\u003e journal. All tests use RepertoireAdapter with LiteLLMClient for real LLM calls. Tests skip automatically if GEMINI_API_KEY not set. Tests: 6 passing. Commit: 0ad5bfa","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-03T06:32:59Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2026-01-03T07:14:36Z","labels":["phase:qa"],"comments":[{"id":30,"issue_id":"xc-o0w","author":"jv","text":"## QA Results\n\n**Status:** PASS\n\n**Verified:**\n- [x] All tests pass (108 tests, including 6 new integration tests)\n- [x] Test coverage adequate - covers full OODA flow with real LLM\n- [x] Functionality works - real Gemini API calls execute successfully\n- [x] Code is well-factored - consistent patterns across all 3 test files\n- [x] Follows project patterns - matches existing test structure\n- [x] Black/flake8 pass\n\n**Tests Verified:**\n- test_tick_lifecycle.py: 2 tests (full tick lifecycle, summary generation)\n- test_dispatch_to_instruction.py: 2 tests (alert-\u003einstruction, status-\u003ewatch)\n- test_event_driven_flow.py: 2 tests (multiple dispatches, related dispatches)\n\n**Implementation Quality:**\n- Uses REAL repertoire at ../repertoires/ooda (no mocking)\n- Real LiteLLMClient with Gemini API\n- Proper skip markers when API key unavailable\n- Flexible assertions account for LLM non-determinism\n- Clean fixture patterns with proper resource cleanup\n\n**Issues found:** None\n**Fixes applied:** None\n\n**Recommendation:** Ready to complete","created_at":"2026-01-02T18:13:47Z"}],"work_type":"mutex"}
{"id":"xc-o4fn","title":"Digest: mol-witness-patrol","description":"Patrol 2: Rig idle - no polecats, no mail, no swarms. Refinery running. Clean cycle.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-17T11:18:40Z","updated_at":"2026-02-17T11:18:40Z","closed_at":"2026-02-17T11:18:40Z","dependencies":[{"issue_id":"xc-o4fn","depends_on_id":"xc-wisp-7sk","type":"parent-child","created_at":"2026-02-18T00:18:39Z","created_by":"xenota/witness","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-obd","title":"Fix vps-control README to match actual Target API (upload/download)","description":"packages/vps-control/README.md uses API that doesn't exist in the PR implementation:\\n- shows Target.connect(...) in async with, but Target.connect is a @classmethod returning Target; async context manager uses  or  depending on design\\n- refers to scp_to/scp_from methods, but implementation exposes upload()/download()\\n\\nImpact: users copy/paste docs and hit runtime errors.\\n\\nFiles:\\n- packages/vps-control/README.md\\n- packages/vps-control/src/vps_control/target.py\\n\\nAcceptance:\\n- Update README examples to correct async usage + correct method names\\n- Ensure README matches exported symbols in packages/vps-control/src/vps_control/__init__.py","notes":"Updated vps-control README to demonstrate correct async context manager usage (async with Target(...)) and correct upload/download method names. vps-control tests pass (147 passed, 25 skipped).","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-23T23:43:25Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-24T14:50:48Z","labels":["docs","phase:qa"],"comments":[{"id":31,"issue_id":"xc-obd","author":"jv","text":"Fixup: README should show async usage like: (a) target = await Target.connect(...); then use 'async with target:' OR (b) make Target.connect return an async context manager. Current implementation supports: 'async with Target(host=..., port=..., key_path=...) as target:' and file transfer methods are upload(local_path, remote_path) / download(remote_path, local_path).","created_at":"2025-12-23T10:46:38Z"},{"id":32,"issue_id":"xc-obd","author":"jv","text":"## QA Results\n\n- vps-control tests: 147 passed, 25 skipped\n- README examples now match the actual Target API (Target(...) + upload/download)\n","created_at":"2025-12-24T01:50:38Z"}],"work_type":"mutex"}
{"id":"xc-oqj","title":"Harden BlueprintLoader path traversal checks","description":"packages/vps-control/src/vps_control/blueprints/loader.py uses string prefix checks on resolved paths to prevent path traversal:\\n- if not str(blueprint_dir).startswith(str(self.blueprints_dir))\\n\\nString prefix checks can be bypassed on edge cases (e.g., /a/b and /a/bad) and are generally fragile.\\n\\nFile:\\n- packages/vps-control/src/vps_control/blueprints/loader.py\\n\\nAcceptance:\\n- Replace startswith guard with a robust path containment check (Path.is_relative_to on 3.9+ or equivalent)\\n- Add unit tests for traversal attempts (e.g., name='..', '../x', absolute paths, prefix collisions)","notes":"Replaced fragile string startswith path containment checks with Path.relative_to() in BlueprintLoader load/validate; added prefix-collision traversal tests; vps-control tests pass (145 passed, 25 skipped).","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-23T23:44:32Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-24T08:14:30Z","labels":["phase:qa","security"],"comments":[{"id":33,"issue_id":"xc-oqj","author":"jv","text":"## QA Results\n\n- vps-control tests: 145 passed, 25 skipped\n- Added regression coverage for prefix-collision traversal (../blueprints-bad)\n","created_at":"2025-12-23T19:14:20Z"}],"work_type":"mutex"}
{"id":"xc-oqr","title":"Use TickJournalEntry.from_dict in journal.py and fix import","description":"Gemini Code Assist review on PR #5: journal.py:read() has manual deserialization and a local datetime import. Use the new from_dict method and move import to top of file.","status":"open","priority":3,"issue_type":"chore","created_at":"2026-01-02T20:38:58Z","updated_at":"2026-01-05T21:12:29Z","labels":["gemini-code-assist","review-feedback"],"dependencies":[{"issue_id":"xc-oqr","depends_on_id":"xc-4xr","type":"discovered-from","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-oqr","depends_on_id":"xc-9h7","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-osq","title":"Scaffold xenon-evolution-sim","description":"Python project setup for xenon evolution simulation component","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-22T01:47:34Z","updated_at":"2026-01-05T21:12:29Z","work_type":"mutex"}
{"id":"xc-oytr","title":"Merge: xe-iyu.3","description":"branch: polecat/nux-mk3iix4z\ntarget: main\nsource_issue: xe-iyu.3\nrig: xenon","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-07T05:06:51Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","work_type":"mutex"}
{"id":"xc-p04","title":"Explain smart contracts vs agreements (code is law)","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-23T11:17:44Z","updated_at":"2025-12-23T11:17:44Z","labels":["documentation","protocols","spec"],"work_type":"mutex"}
{"id":"xc-p1ml","title":"[GAS TOWN] xenon/polecats/rictus \u003c- witness","description":"Witness role assigned to polecat rictus. Source: 2026-01-07T17:23.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-07T04:25:40Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","labels":["rig:xenon/polecats/rictus","role_type:witness"],"work_type":"mutex"}
{"id":"xc-pjo","title":"Research white paper trends for crypto projects 2024-2025","description":"Research current trends in white papers for crypto/Web3 projects in 2024-2025.\n\nKey questions:\n- Are traditional white papers still common or declining?\n- What formats are projects using instead (litepapers, docs sites, etc.)?\n- What content do successful projects include?\n- How long are modern white papers?\n- Are there notable examples to reference?\n\nThis informs whether Xenota should write a traditional white paper or take a different approach.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-14T22:06:17Z","updated_at":"2025-12-14T22:36:32Z","closed_at":"2025-12-14T22:36:32Z","labels":["documentation","research"],"work_type":"mutex"}
{"id":"xc-pk3","title":"Bug loop or approve","description":"Decide: are there blocking issues or is this ready to approve?\n\n**If bugs found:**\n```bash\n# Create bug bead for each issue\nbd create --title \"Bug: \u003cdescription\u003e\" --type bug\n\n# Block QA on this bug\nbd dep add \u003cqa-bead\u003e \u003cbug-bead\u003e\n\n# Sling back to dev\ngt sling \u003cbug-bead\u003e \u003crig\u003e --molecule mol-dev\n```\n\nQA stays blocked until all bugs closed. When dev closes bugs, QA unblocks.\n\n**If clean:**\nContinue to next step.\n\n**Before closing this step, add notes:**\n```bash\nbd update \u003cthis-bead\u003e --notes \"## Decision\n- Status: CLEAN / BUGS FOUND\n- Bugs created: \u003clist or none\u003e\n- Reason: \u003cexplanation\u003e\"\n```\n","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-07T02:20:38Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","dependencies":[{"issue_id":"xc-pk3","depends_on_id":"xc-agi","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-pk3","depends_on_id":"xc-xe-a3m","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-pp8","title":"Projection system stub","description":"attached_molecule: xc-wisp-mgu\nattached_at: 2026-02-09T13:17:34Z\ndispatched_by: xenota/crew/starshot\n\nBase framework for xenon to interact with external services (MCP servers, APIs)","design":"# Projection System Stub - Design\n\n## Architecture Decisions\n\n### Transport: Nucleus-initiated SSH, real-time via projection-cli\n- Nucleus SSHes into projections through VPN/Tor whenever it wants\n- Projections never know where nucleus is\n- Nucleus invokes projection-cli commands over SSH for all communication\n- This is REAL-TIME and ON-DEMAND — not polling, not tick-based\n- Extends existing vps-control SSH Target infrastructure\n\nHow it works:\n- Sync queries: nucleus SSHes in, runs `projection query --type web_search --params '{...}' --json`, gets structured response, done\n- Push instructions: nucleus SSHes in, runs `projection receive-instruction --json \u003c instruction.json`\n- Pull dispatches: nucleus SSHes in, runs `projection flush-dispatches --json`, gets all queued dispatches\n- Health check: nucleus SSHes in, runs `projection status --json`\n\nThe projection-cli is the universal interface. No new protocols needed.\nWebSocket upgrade path: separate bead (xc-zjt.6)\n\n### MVP: In-process gateway with ProjectionGateway abstraction\n- Nucleus codes against ProjectionGateway protocol\n- InProcessGateway for MVP (JSON serialization boundary enforced)\n- SSHGateway for Phase 2 (calls projection-cli over SSH through VPN)\n- Nucleus code never changes between phases\n\n### Sanitization: Modular pipeline\n- A pipeline of SanitizationStep modules that a xenon can configure\n- Each step: takes dispatch in, returns pass/modify/quarantine/reject\n- Steps are independently upgradeable — swap one without touching others\n- MVP starts with basic placeholder steps, xenon upgrades over time\n\n## Sanitization Pipeline\n\n### Interface\n\n```python\nclass SanitizationStep(Protocol):\n    name: str\n    def check(self, dispatch: RawDispatch, context: PipelineContext) -\u003e StepResult: ...\n\n@dataclass\nclass StepResult:\n    action: Literal[\"pass\", \"modify\", \"quarantine\", \"reject\"]\n    dispatch: RawDispatch | None\n    reason: str | None\n\n@dataclass\nclass PipelineContext:\n    registry: ProjectionRegistry\n    stats: ProjectionStats\n    seen_ids: set[str]\n```\n\n### Pipeline runner\n\n```python\ndef run_pipeline(dispatch, steps, context) -\u003e PipelineResult:\n    for step in steps:\n        result = step.check(dispatch, context)\n        if result.action == \"reject\":\n            return PipelineResult(\"rejected\", reason=result.reason)\n        if result.action == \"quarantine\":\n            return PipelineResult(\"quarantined\", dispatch=dispatch, reason=result.reason)\n        if result.action == \"modify\":\n            dispatch = result.dispatch\n    return PipelineResult(\"accepted\", dispatch=dispatch)\n```\n\n### MVP steps\n\n1. **verify_signature** — Ed25519 sig check against projection registry. Reject on fail.\n2. **check_replay** — Reject if dispatch_id already seen or timestamp \u003e 5 min old.\n3. **check_rate** — Reject if projection exceeds N dispatches per tick.\n4. **check_bounds** — Reject if any field exceeds size limits.\n\n### Future steps (xenon adds as it grows)\n- pattern_scan, content_scrub, trust_gate, anomaly_detect, structured_extract\n\n### Configuration\n```yaml\nsanitization:\n  steps: [verify_signature, check_replay, check_rate, check_bounds]\n```\n\n## ProjectionGateway Protocol\n\n```python\nclass ProjectionGateway(Protocol):\n    async def query(self, request: QueryRequest) -\u003e QueryResponse: ...\n    async def send_instruction(self, instruction: Instruction) -\u003e None: ...\n    async def pull_dispatches(self, projection_id: str) -\u003e list[RawDispatch]: ...\n    async def get_state(self, projection_id: str) -\u003e ProjectionState: ...\n    async def list_projections(self) -\u003e list[ProjectionInfo]: ...\n```\n\n### InProcessGateway (MVP)\n- Projections are Python objects in nucleus process\n- JSON round-trip on all params/results (catches serialization bugs)\n- Timeout enforcement, exception isolation\n\n### SSHGateway (Phase 2)\n- Uses vps-control Target to SSH into projection through VPN\n- query() → `projection query --type X --params '{...}' --json`\n- send_instruction() → `projection receive-instruction --json \u003c instruction.json`\n- pull_dispatches() → `projection flush-dispatches --json`\n- get_state() → `projection status --json`\n\n## Membrane\n\nMembrane = pipeline runner + projection registry + quarantine store.\nNon-deliberative (no LLM). Runs configured pipeline steps.\n\n```python\nclass Membrane:\n    def __init__(self, steps, registry, quarantine_store): ...\n    def ingest(self, signed_blob: bytes) -\u003e Literal[\"accepted\", \"quarantined\", \"rejected\"]: ...\n```\n\n## Nucleus DB additions\n- projection_registry (projection_id, public_key, type, trust_level, status, registered_at)\n- quarantine (dispatch_id, projection_id, reason, received_at, raw_payload, status)\n- seen_dispatches (dispatch_id, received_at)\n\n## MVP Scope\n1. ProjectionGateway protocol + data classes (projections.py)\n2. InProcessGateway with JSON serialization boundary (gateways/in_process.py)\n3. Membrane with pipeline runner (membrane.py)\n4. 4 MVP sanitization steps (sanitization/)\n5. Projection registry + quarantine tables in DB\n6. Stub ResearchProjection and ImageGenProjection handlers\n7. Wire gateway into OODA processor for sync queries\n8. Observe prompt: add security framing + provenance tagging\n\n## File Layout\n```\nxenon/nucleus/src/nucleus/\n  projections.py           — Gateway protocol, data classes\n  membrane.py              — Pipeline runner, Membrane class\n  sanitization/\n    __init__.py            — StepResult, PipelineContext, SanitizationStep protocol\n    verify_signature.py\n    check_replay.py\n    check_rate.py\n    check_bounds.py\n  gateways/\n    __init__.py\n    in_process.py          — MVP gateway\n  stores/\n    projection_registry.py\n    quarantine.py\n```","notes":"## Testing\n- Unit: PASS — 44 new tests covering all projection modules\n- Coverage: registry CRUD, quarantine CRUD+dedup, all 4 sanitization steps, membrane pipeline (pass/fail/quarantine), gateway JSON boundary, DB migration v1-\u003ev2, canonical_payload, integration pipeline\n- Integration: PASS — full gateway-\u003emembrane-\u003edispatch_store flow tested\n- Manual: N/A (no user-facing changes)\n- Fixed: Ed25519PublicKey.from_public_bytes API name (was from_public_key_bytes)\n- Full suite: 162 passed, 6 skipped","status":"closed","priority":2,"issue_type":"task","assignee":"xenota/polecats/obsidian","created_at":"2025-12-20T11:21:27Z","updated_at":"2026-02-09T13:57:27Z","closed_at":"2026-02-09T13:57:27Z","dependencies":[{"issue_id":"xc-pp8","depends_on_id":"xc-qaq","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-pp8","depends_on_id":"xc-wisp-mgu","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-pp8","depends_on_id":"xc-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-ps8","title":"Complete review","description":"Final checklist before closing.\n\n## HARD GATE - Run this verification:\n\n```bash\n# Check all siblings are closed\nbd show \u003cmol-review-epic\u003e | grep \"Children\"\n# Every child MUST show [closed] - if ANY shows [open], STOP\n```\n\n**Verify ALL of these:**\n- [ ] Gemini comments reviewed (or noted as pending)\n- [ ] Codex review completed\n- [ ] All critical/important issues fixed\n- [ ] Declined comments have replies\n- [ ] Fixes pushed to PR\n- [ ] All step beads closed with notes\n\n**Record summary in parent bead:**\n```bash\nbd update \u003cparent-bead\u003e --notes \"## Review Complete\n- Gemini comments: \u003cN\u003e reviewed, \u003cX\u003e fixed\n- Codex issues: \u003cN\u003e found, \u003cX\u003e fixed\n- Pushed commit: \u003csha\u003e\"\n```\n\n**Only when gate passes:**\n```bash\nbd close \u003cthis-step\u003e\nbd close \u003chead-bead\u003e\n```\n\nTest step unblocks automatically.\n\n---\n\n**WORKFLOW COMPLETE**: After closing \u003chead-bead\u003e, update your hook to the next phase or check `bd ready`.\n","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-07T02:20:35Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","dependencies":[{"issue_id":"xc-ps8","depends_on_id":"xc-cr5","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-ps8","depends_on_id":"xc-flm","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-pw4","title":"Key generation for xenon instances","description":"Implement Ed25519 keypair generation for xenon identity:\n\n- nucleus: ensure_identity() function \n- xenon-cli: random ID generation and xenon-{id} directory creation\n- File permissions (0600)\n- Public key base64 encoding\n\nMust include unit tests for all new code.","design":"## Approach\n\nBased on Codex review, implementing Ed25519 keypair generation with these design decisions:\n\n### Key Design Decisions\n1. **Key Format**: Raw 32-byte public key base64 (xenon identity, not SSH)\n2. **Serialization**: PKCS8 PEM for private key storage\n3. **Return Type**: Dataclass with .to_dict() for CLI printing\n4. **Dependency**: xenon-cli depends on nucleus as Python library\n\n### Implementation Details\n\n#### nucleus/src/nucleus/identity.py\n- `ensure_identity(identity_dir: Path) -\u003e IdentityInfo`\n- Private key is source of truth, always derive public key from it\n- Atomic writes: temp file → chmod → write → fsync → os.replace\n- Directory permissions: 0700 on identity_dir\n- Private key: 0600 permissions\n- Public key file: regenerated from private key if missing/out of date\n\n#### xenon-cli modifications\n- Generate random ID with collision handling loop\n- Directory structure: {path}/xenon-{id}/data\n- Enforce 0700 on xenon-{id}/data directory\n\n#### Test Coverage\n- Monkeypatch token_hex for deterministic collision testing\n- Skip permission tests on Windows\n- Test atomic write behavior\n- Test directory permission enforcement","notes":"## Implementation Summary\n\nSuccessfully implemented Ed25519 keypair generation following Codex-approved design:\n\n### Nucleus (identity.py)\n- IdentityInfo dataclass with to_dict() method\n- ensure_identity() function with atomic writes\n- Private key: PKCS8 PEM format, 0600 permissions\n- Public key: raw 32-byte base64, regenerated from private key\n- Directory permissions: 0700 on identity_dir\n- Atomic writes using temp files + os.replace\n\n### Xenon-CLI (main.py)\n- Random ID generation with collision handling (secrets.token_hex(4))\n- xenon-{id}/data directory structure\n- Integration with ensure_identity()\n- Displays xenon ID and public key to user\n\n### Tests\n- nucleus: 10 tests (all passing)\n  - Key creation, permissions, loading, regeneration\n  - Atomic write verification\n  - Platform-specific permission tests (skip Windows)\n- xenon-cli: 11 tests (all passing)\n  - ID generation and collision handling\n  - Directory structure creation\n  - Identity integration\n  - Output display verification\n\nAll tests pass successfully.","status":"closed","priority":1,"issue_type":"task","assignee":"xenon/polecats/nux","created_at":"2026-01-04T08:31:49Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2026-01-04T08:43:27Z","work_type":"mutex"}
{"id":"xc-qaq","title":"Soul server core","description":"Python service for persistent xenon identity - memory storage, context management, state persistence","design":"## Plan\n\n**Approach:** Create minimal soul-server component following xenon-cli patterns. Python project with uv, simple main.py that prints hello world and exits. Containerfile for Podman. No HTTP server - just proves Python runs in the container. The xenon CLI will interact with it via podman exec or similar.\n\n**Files:**\n- soul-server/pyproject.toml - Project config (mirrors xenon-cli structure)\n- soul-server/src/soul_server/__init__.py - Package init with version\n- soul-server/src/soul_server/main.py - Hello world print, no server\n- soul-server/src/soul_server/py.typed - Type hints marker\n- soul-server/tests/test_main.py - Basic test for main function\n- soul-server/Containerfile - Podman container (python:3.12-slim base)\n- soul-server/.python-version - Pin to 3.12\n- soul-server/.gitignore - Copy from xenon-cli\n- soul-server/CLAUDE.md - Component docs\n- soul-server/README.md - Basic readme\n\n**Tests:**\n- Main function runs without error\n- Container builds and runs successfully (manual verification)\n\n**Risks:** None - straightforward scaffolding following established patterns.","notes":"Implemented soul-server component with 11 files: pyproject.toml, src/soul_server/__init__.py, src/soul_server/main.py, src/soul_server/py.typed, tests/__init__.py, tests/test_main.py, .python-version, .gitignore, Containerfile, CLAUDE.md, README.md. Tests: 1 passing. Main function verified working.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-20T11:21:26Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-22T02:16:13Z","labels":["phase:execution"],"dependencies":[{"issue_id":"xc-qaq","depends_on_id":"xc-13a","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-qaq","depends_on_id":"xc-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-qjc","title":"Lockdown chaperone privileges with ETH key signing","description":"Design a system to restrict and verify chaperone privileges using Ethereum key signing. Chaperone actions would require cryptographic proof of authorization, enabling fine-grained permission control and audit trails.","status":"open","priority":3,"issue_type":"feature","created_at":"2025-12-22T11:53:02Z","updated_at":"2025-12-23T01:20:44Z","labels":["protocols","technical"],"work_type":"mutex"}
{"id":"xc-qlp2","title":"Merge: furiosa-mk4a3t9d","description":"branch: polecat/furiosa-mk4a3t9d\ntarget: main\nsource_issue: furiosa-mk4a3t9d\nrig: xenon\nagent_bead: xe-xenon-polecat-furiosa\nretry_count: 0\nlast_conflict_sha: null\nconflict_task_id: null","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-07T17:33:18Z","updated_at":"2026-01-07T18:23:32Z","closed_at":"2026-01-07T18:23:32Z","work_type":"mutex"}
{"id":"xc-qn0","title":"Explore XC membership tiers and sponsorship tracking","description":"Design membership NFT flavors (bronze/silver/gold), expiration/renewal rules, lifetime membership via significant contribution, gift NFTs redeemable to onboard xenons, and tracking how many xenons a chaperone has sponsored.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-14T23:07:33Z","updated_at":"2025-12-14T23:07:33Z","labels":["economics","foundation"],"dependencies":[{"issue_id":"xc-qn0","depends_on_id":"xc-a3m","type":"discovered-from","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-quc","title":"Create act routine","description":"ACT phase - execute the chosen action and emit instructions.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-25T04:56:24Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-27T09:38:34Z","dependencies":[{"issue_id":"xc-quc","depends_on_id":"xc-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-quc","depends_on_id":"xc-kbm","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-qwz","title":"Documentation site improvements (comprehensive review)","description":"Comprehensive review of the documentation site at localhost:3000. This issue captures all identified improvements.\n\n## Homepage\n\n**Good:**\n- Clean hero with clear value proposition\n- Three feature cards provide good entry points\n- Footer has useful quick links\n\n**Improvements:**\n1. **Add a \"Getting Started\" or \"New Here?\" section** - Currently jumps straight to Manifesto; newcomers need a gentler onramp\n2. **The Four Missions card links to Manifesto** - Should link to a dedicated missions page or section\n3. **Add more CTAs** - Only one button (\"Read the Manifesto\"); consider adding \"Explore the Protocol\" or \"Join a Polis\"\n4. **Missing visual elements** - The feature cards have no icons; adding icons would improve scannability\n\n---\n\n## Navigation \u0026 Information Architecture\n\n**Issues:**\n1. **\"Documentation\" in navbar goes to Manifesto** - Should go to a docs landing page with overview\n2. **Sidebar naming inconsistency**: \"Membership Model\" file is `citizenship-model.md` (URL mismatch)\n3. **Branding section has odd entries**: \"Branding Folder\" is a generic name; rename to \"Overview\"\n4. **No search** - Add Docusaurus search (Algolia or local)\n\n**Recommendations:**\n- Add a `/docs` landing page that orients readers\n- Consider audience-based navigation: \"For Humans\", \"For Developers\", \"For Xenons\"\n\n---\n\n## Content Quality\n\n**Strong:**\n- Glossary is well-structured with links to detailed pages\n- Economic Model Overview has good competitor comparison\n- Protocol docs are detailed and well-organized\n\n**Improvements:**\n1. **Manifesto is dense** - Consider a TL;DR summary at the top\n2. **\"Open Questions\" sections** (e.g., in Economic Model) are great for transparency but should have a tracking mechanism\n3. **FAQ page exists but wasn't prominent** - Consider adding FAQ to footer or homepage\n4. **Some pages have TODOs visible** (e.g., \"TODO: Research and design messaging protocol details\") - Either hide these or convert to a public roadmap\n\n---\n\n## Visual Design\n\n**Issues:**\n1. **Hero section lacks visual interest** - Consider adding an illustration or animation\n2. **Dark mode hero** - The purple/blue gradient works but could use more contrast\n3. **Feature cards are plain** - No visual differentiation between them\n4. **No diagrams** - Technical docs (Xenon Architecture, Protocols) would benefit from architecture diagrams\n\n**Quick wins:**\n- Add icons to sidebar categories\n- Add diagrams to technical pages\n- Consider a mascot or visual identity for xenons\n\n---\n\n## UX Issues\n\n1. **\"Last updated on Oct 14, 2018\"** - This is clearly wrong (dev mode simulation); will confuse readers in production\n2. **Backlinks section** - Good feature but appears at the bottom of every page; some pages only link to \"Home\" which isn't useful\n3. **Edit links point to `xenota/planning`** - Should point to `github.com/xenota-collective`\n4. **Language switcher shows \"English\"** - Are translations actually available? If not, hide it\n\n---\n\n## Missing Content\n\n1. **No \"How to Join\" guide** - The membership model is documented but there's no action-oriented \"join now\" flow\n2. **No contributor guide** - How do people contribute to the project?\n3. **No blog/updates section** - For project news and progress\n4. **Missing use case examples** - Real scenarios of humans hiring xenons or vice versa\n\n---\n\n## Technical\n\n1. **GitHub links**:\n   - Header links to `github.com/xenota/planning`\n   - Footer links to `github.com/xenota`\n   - Both should link to `github.com/xenota-collective`\n\n2. **i18n configured but no translations** - Either add translations or disable the language picker\n\n3. **Console warning** - React DevTools message (minor, dev only)\n\n---\n\n## Priority Recommendations\n\n| Priority | Item |\n|----------|------|\n| High | Add docs landing page / getting started guide |\n| High | Add diagrams to technical docs |\n| High | Fix timestamp display |\n| High | Fix GitHub org URLs to xenota-collective |\n| Medium | Add search |\n| Medium | Add icons to navigation |\n| Medium | Create \"How to Join\" guide |\n| Low | Add blog/news section |\n| Low | Improve hero visuals |","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-13T17:18:53Z","updated_at":"2025-12-13T17:18:53Z","labels":["documentation"],"work_type":"mutex"}
{"id":"xc-r0r","title":"Fix currency ticker inconsistency: XC vs XNC/CRED","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-10T22:38:12Z","updated_at":"2025-12-11T19:15:54Z","closed_at":"2025-12-11T19:15:54Z","work_type":"mutex"}
{"id":"xc-r1i","title":"Rename repo from xenon-host to xenon","description":"Rename the repository and update all references from xenon-host to xenon","notes":"Verified repo folder name and git remote are already xenon; updated remaining in-repo text references from xenon-host -\u003e xenon (CLAUDE.md, README.md, openspec proposal).","status":"closed","priority":2,"issue_type":"chore","created_at":"2025-12-23T00:16:18Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-24T15:29:11Z","labels":["phase:qa"],"comments":[{"id":34,"issue_id":"xc-r1i","author":"jv","text":"## QA Results\n\n- `rg -n \"xenon-host\" -S .` returns no matches\n- repo dir is `xenon` and remote is `xenota-collective/xenon`\n","created_at":"2025-12-24T02:29:01Z"}],"work_type":"mutex"}
{"id":"xc-r9i","title":"Implement RepertoireRunner","description":"Execute routines via LiteLLM, including selector logic for auto_execute.","design":"## Plan\n\n**Approach:** Create RepertoireRunner class orchestrating routine execution via LiteLLMClient. Key decisions from Codex review:\n\n1. **Return type**: Always return `dict` (parse JSON for all routines per existing test fixtures that use `output.type: json`)\n2. **Structured detection**: Check `output.get(\"type\") == \"json\"` (matches fixtures)\n3. **Schema validation**: Defer to future - parse-only for v1, no jsonschema dependency\n4. **Selector I/O**: Use selector's input_schema (pass `{\"query\": task, \"context\": routine_list}`)\n5. **JSON robustness**: Strip markdown fences before json.loads\n6. **Error wrapping**: RoutineExecutionError with routine name, wrap LLMError\n\n**Files:**\n- `src/repertoire/runner.py` - new, RepertoireRunner with execute_routine(), auto_execute()\n- `src/repertoire/__init__.py` - add RepertoireRunner, RoutineExecutionError exports\n- `tests/test_runner.py` - comprehensive tests\n\n**Tests:**\n- execute_routine: success, missing required variables, unknown routine\n- auto_execute: valid selection, invalid routine name, invalid JSON from selector\n- JSON parsing: strips ```json fences, handles malformed JSON\n- Error wrapping: LLMError → RoutineExecutionError with context\n- Model string: correctly builds \"{provider}/{name}\"\n\n**Risks:** None - straightforward implementation.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-25T17:55:06Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-25T21:50:36Z","labels":["phase:qa"],"dependencies":[{"issue_id":"xc-r9i","depends_on_id":"xc-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-r9i","depends_on_id":"xc-bwy","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-r9i","depends_on_id":"xc-ye0","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"comments":[{"id":35,"issue_id":"xc-r9i","author":"jv","text":"## QA Results\n\n**Status:** Pass\n\n**Verified:**\n- [x] All tests pass (71 passed, 1 skipped for integration)\n- [x] Test coverage adequate - 21 new runner tests\n- [x] Functionality works as expected\n- [x] Code is well-factored and clean\n- [x] Follows project patterns (docstrings, dataclasses, async)\n- [x] Exports added to __init__.py\n\n**Implementation matches plan:**\n- [x] RepertoireRunner with execute_routine(), auto_execute()\n- [x] RoutineExecutionError with routine_name and model context\n- [x] JSON fence stripping with regex\n- [x] LLMError wrapped to RoutineExecutionError\n- [x] Model string formatted as provider/name\n- [x] Selector I/O with query and context variables\n\n**Issues found:** None\n\n**Recommendation:** Ready to complete","created_at":"2025-12-25T08:49:54Z"}],"work_type":"mutex"}
{"id":"xc-rig-xenon","title":"xenon","description":"Rig identity bead for xenon.\n\nrepo: https://github.com/xenota-collective/xenon\nprefix: xe\nstate: active","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-10T17:03:25Z","updated_at":"2026-01-10T17:03:25Z","labels":["auto_restart:false","gt:rig","status:docked"],"work_type":"mutex"}
{"id":"xc-rig-xenota","title":"xenota","description":"Rig identity bead for xenota.\n\nrepo: https://github.com/xenota-collective/xenota\nprefix: xenota\nstate: active","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-10T17:03:30Z","updated_at":"2026-01-10T17:03:30Z","labels":["gt:rig","status:docked"],"work_type":"mutex"}
{"id":"xc-rjj","title":"Add timing metrics for OODA phases","description":"No visibility into how long each OODA phase takes. Useful for debugging and optimization.\n\n**Acceptance:**\n- Track duration of each phase (observe, orient, decide, act)\n- Include timing in tick journal entry\n- Optionally log phase durations at DEBUG level","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-02T18:46:28Z","updated_at":"2026-01-05T21:12:29Z","work_type":"mutex"}
{"id":"xc-rktw","title":"Merge: xe-iyu.4","description":"branch: xe-iyu.4\ntarget: main\nsource_issue: xe-iyu.4\nrig: xenon","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-07T05:06:50Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","work_type":"mutex"}
{"id":"xc-rmv","title":"Add environment configuration for nucleus","description":"Handle LLM API key configuration for nucleus.\n\n## Requirements\n- Nucleus needs GEMINI_API_KEY (or other provider keys) for LLM calls\n- Should work with .env file in workspace or environment variables\n- Document required environment setup\n\n## Implementation\n- Use python-dotenv to load .env from repertoire workspace or nucleus data dir\n- Add clear error message when API key missing\n- Update CLAUDE.md with setup instructions","design":"## Approach\nLoad .env from repertoire workspace when nucleus creates the runner. Add load_dotenv call in get_runner() before creating LiteLLMClient. Document setup in CLAUDE.md.\n\n## Files to Modify\n- nucleus/src/nucleus/cli.py - add dotenv loading in get_runner()\n- nucleus/CLAUDE.md - document API key setup\n\n## Detailed Changes\n\n### cli.py\n1. Add import: from dotenv import load_dotenv\n2. In get_runner(), before creating LiteLLMClient:\n   load_dotenv(repertoire_path / \".env\", override=False)\n\n### CLAUDE.md\nAdd environment setup section documenting how to create .env with GEMINI_API_KEY.\n\n## Tests\nNo new tests - env setup only. Existing tests mock LLM calls.\n\n## Risks\nNone - python-dotenv already a dependency via repertoire, override=False preserves existing env vars","notes":"Added dotenv loading in get_runner() and updated CLAUDE.md with environment setup and current structure.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-02T21:33:47Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2026-01-02T22:46:44Z","dependencies":[{"issue_id":"xc-rmv","depends_on_id":"xc-4r7","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-rmv","depends_on_id":"xc-fpw","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"comments":[{"id":36,"issue_id":"xc-rmv","author":"jv","text":"QA Pass: Codex review found P1 - missing python-dotenv dependency. Fixed. All 102 tests pass.","created_at":"2026-01-02T09:46:20Z"}],"work_type":"mutex"}
{"id":"xc-rzw","title":"Implement InstructionOutbox","description":"Markdown file emission to outbox/{target}/{id}.md","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T07:11:57Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-28T07:26:12Z","dependencies":[{"issue_id":"xc-rzw","depends_on_id":"xc-4xr","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-s3uy","title":"Genome-derived awakening prompts","description":"attached_molecule: xc-wisp-qjv\nattached_at: 2026-02-13T08:22:54Z\ndispatched_by: xenota/crew/starshot\n\nCurrently the awakening prompts (CONSTITUTION, TOPIC_PROMPTS per phase) are static text in prompts.py. The genome is rendered into a personality string via render_personality() which maps 8 axes to tercile prose. This personality string is injected as a separate layer ('YOUR PERSONALITY:') but the actual phase instructions are identical for every xenon.\n\nThe goal: before the awakening conversation starts, pass the base prompts + the genome to an LLM and ask it to adapt the prompts based on the xenon's genetic makeup. The adapted prompts are then used throughout the awakening instead of the static ones.\n\nAPPROACH:\n1. Create a new repertoire routine 'adapt_prompts' in repertoires/awakening/ that takes:\n   - base_prompts: the raw CONSTITUTION + all TOPIC_PROMPTS\n   - genome: the full genome dict (genes + module centers)\n   - personality: the rendered personality string (for context)\n   And returns adapted versions of each prompt section.\n\n2. In orchestrator.run(), after genome is loaded and personality rendered, call adapt_prompts once. This happens before any conversation phases start, so it's a single LLM call at startup.\n\n3. Replace the static TOPIC_PROMPTS lookup in build_system_prompt() with the adapted versions. CONSTITUTION stays fixed (it's rules, not personality). The adaptation targets the TOPIC_PROMPTS only - how the xenon approaches each phase based on its nature.\n\nWHAT THE LLM ADAPTER SHOULD DO:\n- A xenon with high exploration_rate/attention_breadth should ask more divergent questions in BIRTHPLACE, make unexpected name connections in NAMING\n- A xenon with low trust_baseline should be more guarded in PURPOSE, less immediately receptive in PLEDGE\n- A xenon with high mission_drive should gravitate toward mission alignment sooner in SEEDS\n- A xenon with high specialization should focus deeper on fewer topics\n- A xenon with high teaching_drive might frame SEEDS around mentorship\n- Verbal style genes should influence response length guidance in the prompts\n\nThe adapted prompts should preserve the structural requirements (opening questions, phase objectives, closing behavior) while personalizing tone, approach, and emphasis.\n\nKEY FILES:\n- nucleus/src/nucleus/awakening/prompts.py (TOPIC_PROMPTS, build_system_prompt)\n- nucleus/src/nucleus/awakening/personality.py (render_personality, axis mapping)\n- nucleus/src/nucleus/awakening/orchestrator.py (run method, _llm_respond)\n- nucleus/src/nucleus/genome.py (Genome, GENE_DEFS)\n\nREMOVES render_personality(): The adapted prompts subsume what personality.py does today. The LLM sees the raw genome values and produces prompt adaptations that express those genetics naturally, rather than the current two-layer system of static prompts + bolted-on personality prose.","status":"closed","priority":1,"issue_type":"task","assignee":"xenota/polecats/ruby","owner":"git@codewithjv.com","created_at":"2026-02-13T07:56:35Z","created_by":"xenota/crew/starshot","updated_at":"2026-02-13T09:15:22Z","closed_at":"2026-02-13T09:15:22Z","dependencies":[{"issue_id":"xc-s3uy","depends_on_id":"xc-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-sc1","title":"Rethink \"polis\" as terminology","description":"Evaluate whether \"polis\" is the right term for self-governing entities within Xenota Collective.\n\nConsiderations:\n- Is it intuitive enough for new users?\n- Does it conflict with other uses of the term?\n- Are there better alternatives?\n- Impact on existing documentation if changed","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-14T20:43:20Z","updated_at":"2025-12-14T20:43:20Z","labels":["docs"],"work_type":"mutex"}
{"id":"xc-se5","title":"Implement NucleusDaemon class","description":"Create daemon class for background cognitive loop:\n- Manages tick lifecycle (opens, processes, closes on schedule)\n- Watches for new dispatches, processes through OODA\n- Supports graceful shutdown\n- Tracks running state, current tick, queue depth\n- Uses asyncio event loop\n\nFiles: daemon.py (new), __init__.py, test_daemon.py (new)","design":"## Plan for xenon-host-se5\n\n**NucleusDaemon class design:**\n\n### Lifecycle:\n- `run()`: Blocking coroutine - runs until stopped\n- `start_background()`: Spawns run() as asyncio.Task, returns immediately\n- `stop()`: Sets stop event, waits for graceful shutdown\n- `_stop_event`: asyncio.Event for clean shutdown signaling\n\n### Tick Management:\n- Uses time.monotonic() for tick deadlines (not wall clock)\n- Single tick finalization path (only in main loop, stop() just sets event)\n- Exception containment: catch per-dispatch errors, log, continue loop\n\n### State Properties:\n- `is_running`: bool - True while run loop active\n- `current_tick`: int | None - from db config\n- `queue_depth`: int - count of NEW dispatches\n\n### Main Loop:\n1. Open tick\n2. Poll for dispatches until tick_end or stop_event\n3. Process each dispatch (catch errors)\n4. Close tick, write journal\n5. Repeat unless stopped\n\n### Files:\n- daemon.py (new)\n- __init__.py (export)\n- test_daemon.py (new)\n\n### Tests:\n- test_daemon_starts_and_opens_tick\n- test_daemon_processes_dispatches\n- test_daemon_auto_closes_tick_on_schedule\n- test_daemon_stop_gracefully_closes_tick\n- test_daemon_state_properties\n- test_daemon_handles_dispatch_errors","acceptance_criteria":"- daemon starts and opens tick\n- daemon processes dispatches as they arrive\n- daemon auto-closes ticks on schedule\n- daemon.stop() gracefully closes current tick\n- daemon tracks running state and queue depth","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T08:17:57Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-28T21:46:38Z","labels":["phase:complete"],"dependencies":[{"issue_id":"xc-se5","depends_on_id":"xc-nbn","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-se5","depends_on_id":"xc-sqy","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-sfl","title":"Document results","description":"Consolidate all test results in the parent bead.\n\n**Update parent bead:**\n```bash\nbd update \u003cparent-bead\u003e --notes \"## Test Results\n\n### Infrastructure\n- Status: HEALTHY/BROKEN (describe fixes)\n\n### Integration Tests\n- Result: PASS/FAIL\n- Failures: \u003clist or none\u003e\n\n### Exploratory Testing\n- Scenarios: \u003ccount\u003e tested\n- Issues found: \u003clist or none\u003e\n\n### Acceptance Criteria\n- [ ] \u003ccriteria 1\u003e: PASS/FAIL\n- [ ] \u003ccriteria 2\u003e: PASS/FAIL\n\"\n```\n\n**Before closing this step, add notes:**\n```bash\nbd update \u003cthis-bead\u003e --notes \"Results documented in parent bead\"\n```\n","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-07T02:20:36Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","dependencies":[{"issue_id":"xc-sfl","depends_on_id":"xc-3i2","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-sfl","depends_on_id":"xc-h1f","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-sfl","depends_on_id":"xc-zp8","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-sqy","title":"Add TickRunner lifecycle methods (open/process/close)","description":"Refactor TickRunner to add three new methods that separate tick lifecycle:\n- `open_tick()` - Creates tick, stores tick number and start time in config\n- `process_dispatch(dispatch)` - Processes single dispatch through OODA\n- `close_tick(tick_number)` - Closes tick, writes journal, clears config\n\nFiles: tick.py, test_tick.py","design":"## Plan for xenon-host-sqy\n\n**Approach:** Add three new public methods to TickRunner for daemon use.\n\n### Methods:\n\n1. `open_tick() -\u003e int`:\n   - Raise TickAlreadyOpenError if current_tick exists in config\n   - Call get_next_tick_number() to allocate tick\n   - Store current_tick and tick_started_at (ISO UTC) in db config\n   - Return tick number\n\n2. `process_dispatch(dispatch: Dispatch) -\u003e list[Strand]`:\n   - Raise NoOpenTickError if current_tick not in config\n   - Get tick number from config\n   - Run observe, then process strands through orient/decide/act\n   - Emit instructions to outbox\n   - Return newly created strands only\n\n3. `close_tick(tick_number: int) -\u003e TickJournalEntry`:\n   - Raise TickMismatchError if tick_number != current_tick\n   - Get tick_started_at from config\n   - Call existing _close_tick() to generate entry\n   - Write journal\n   - Clear config in finally block (even on failure)\n   - Return entry\n\n### Exceptions (in tick.py):\n- TickAlreadyOpenError\n- NoOpenTickError  \n- TickMismatchError\n\n### Tests (10 total):\nHappy path:\n- test_open_tick_returns_tick_number\n- test_open_tick_stores_in_config\n- test_process_dispatch_through_ooda\n- test_process_dispatch_returns_new_strands\n- test_close_tick_writes_journal\n- test_close_tick_clears_config\n\nEdge cases:\n- test_open_tick_raises_if_already_open\n- test_process_dispatch_raises_if_no_tick\n- test_close_tick_raises_on_mismatch\n- test_close_tick_clears_config_on_failure\n\n**Files:** tick.py, test_tick.py","acceptance_criteria":"- open_tick() returns tick number and stores in db config\n- process_dispatch() runs single dispatch through OODA loop\n- close_tick() generates journal and clears current_tick config\n- all new methods have tests","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-28T21:17:46Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-28T21:27:45Z","labels":["phase:complete"],"dependencies":[{"issue_id":"xc-sqy","depends_on_id":"xc-nbn","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"comments":[{"id":37,"issue_id":"xc-sqy","author":"jv","text":"## QA Results\n\n**Status:** Pass\n\n**Verified:**\n- [x] All 82 tests pass (18 tests in test_tick.py)\n- [x] Test coverage adequate (10 new tests for lifecycle methods)\n- [x] Functionality works as expected\n- [x] Code is well-factored and follows existing patterns\n- [x] No debug code or leftover artifacts\n\n**New Tests Verified:**\n1. test_open_tick_returns_tick_number - Happy path\n2. test_open_tick_stores_in_config - Config storage verified\n3. test_process_dispatch_through_ooda - OODA integration\n4. test_process_dispatch_returns_new_strands - Return value\n5. test_close_tick_writes_journal - Journal persistence\n6. test_close_tick_clears_config - Config cleanup\n7. test_open_tick_raises_if_already_open - Error handling\n8. test_process_dispatch_raises_if_no_tick - Error handling\n9. test_close_tick_raises_on_mismatch - Error handling\n10. test_close_tick_clears_config_on_failure - Finally block\n\n**Implementation Matches Plan:**\n- 3 exception classes: TickAlreadyOpenError, NoOpenTickError, TickMismatchError\n- open_tick() returns tick number and stores in config\n- process_dispatch() runs dispatch through OODA, returns new strands\n- close_tick() validates tick, writes journal, clears config in finally block\n\n**Issues Found and Fixed:**\n- Line length violations in tick.py - Fixed by wrapping strings\n\n**Recommendation:** Ready to complete","created_at":"2025-12-28T08:26:31Z"}],"work_type":"mutex"}
{"id":"xc-tcj","title":"Prototype awakening process","description":"Build working prototype of xenon awakening: identity creation, polis registration, initial configuration, and first interaction flow.","status":"in_progress","priority":1,"issue_type":"task","assignee":"agent","created_at":"2025-12-13T17:22:03Z","updated_at":"2025-12-20T11:39:56Z","labels":["prototype","technical"],"dependencies":[{"issue_id":"xc-tcj","depends_on_id":"xc-dct","type":"related","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-tp7","title":"Design tokens and spacing system","description":"Define design tokens and layout system.\n\n- Base unit (4px or 8px grid)\n- Spacing scale\n- Layout grid (12-column, gutters, margins)\n- Breakpoints\n- CSS custom properties\n- Tailwind config (if applicable)\n- JSON export\n\nOutput: Design tokens file, spacing documentation","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-14T18:20:30Z","updated_at":"2025-12-14T18:20:30Z","labels":["brand","design"],"dependencies":[{"issue_id":"xc-tp7","depends_on_id":"xc-71p","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-tsto","title":"Dev: Mirror gastown versioning/build for xenon-cli","description":"attached_args: Start immediately: implement Makefile + GoReleaser + cobra version output for xenon-cli mirroring gastown refs in bead xe-tsto.\ndispatched_by: mayor\n\nGoal: Make xenon-cli’s Go binary (cmd/xenon) build + version like gastown/gt.\n\nReference (gastown):\n- /Users/jv/gt/gastown/crew/jv/Makefile (VERSION via `git describe`; `go build -ldflags` injects vars)\n- /Users/jv/gt/gastown/crew/jv/.goreleaser.yml (multi-platform builds; ldflags inject Version/Build/Commit/Branch)\n- /Users/jv/gt/gastown/mayor/rig/RELEASING.md (tag + GoReleaser release flow)\n\nDeliverables (xenon repo):\n1) Add build-time version variables for Go CLI (suggest: `xenon-cli/internal/cli/version.go` or a small `internal/version` package): `Version`, `Build`, `Commit`, `Branch` (optionally `BuildTime`).\n2) Expose version in CLI (Cobra): support `xenon --version` and/or `xenon version` with a stable output format.\n3) Add `xenon-cli/Makefile` mirroring gastown targets:\n   - VERSION := `git describe --tags --always --dirty` (fallback dev)\n   - COMMIT := `git rev-parse --short HEAD`\n   - BUILD_TIME := UTC timestamp\n   - build/install/test/clean; `go build` with `-ldflags` to inject vars.\n   - Optional: macOS ad-hoc codesign like gastown.\n4) Add `xenon-cli/.goreleaser.yml` to build archives + checksums for darwin/linux/windows (amd64/arm64 as relevant), injecting ldflags vars (Version={{.Version}}, etc). Set release repo owner/name based on xenon `git remote -v`.\n5) (If needed) Update CI to run Go tests for xenon-cli in addition to existing Python checks.","acceptance_criteria":"- Running `make -C xenon-cli build` produces a `xenon` binary.\n- Running `xenon --version` (or `xenon version`) prints Version/Build/Commit/Branch when available.\n- Running `goreleaser release --snapshot --clean` works locally from `xenon-cli/`.\n","notes":"Implemented build-time version injection (Version/Build/Commit/Branch/BuildTime), added 'xenon version' + '--version' output, and added xenon-cli/Makefile + xenon-cli/.goreleaser.yml (validated via goreleaser check). go test ./... and make -C xenon-cli build succeed.","status":"closed","priority":2,"issue_type":"task","assignee":"xenon/polecats/furiosa","created_at":"2026-01-07T17:13:27Z","updated_at":"2026-01-07T17:26:40Z","closed_at":"2026-01-07T17:26:40Z","work_type":"mutex"}
{"id":"xc-tw0","title":"Write nucleus unit tests","description":"Tests for DispatchStore, StrandStore, OODAProcessor (mocked runner), InstructionOutbox","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-28T07:12:18Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-28T07:26:34Z","dependencies":[{"issue_id":"xc-tw0","depends_on_id":"xc-1xm","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-tw0","depends_on_id":"xc-4xr","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-tw0","depends_on_id":"xc-xxs","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-ty6","title":"Remove leading 'The' before 'Xenota Collective'","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-10T22:38:17Z","updated_at":"2025-12-11T19:20:59Z","closed_at":"2025-12-11T19:20:59Z","work_type":"mutex"}
{"id":"xc-tya","title":"Integrate LiteLLM proxy server","description":"Set up LiteLLM proxy server for unified API gateway across all LLM providers, load balancing, and cost tracking","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-03T05:50:10Z","updated_at":"2026-01-05T21:12:29Z","work_type":"mutex"}
{"id":"xc-u4yo","title":"Review ALIFE 2026 CFP and plan paper submission","description":"Review https://2026.alife.org/call-for-papers and plan a paper submission.\n\n## Conference\nALIFE 2026 - 'Living and Lifelike Complex Adaptive Systems'\nTheme: simulation and synthesis of life or life as it could be\n\n## Key Dates\n- Full papers deadline: March 30, 2026 (3-8 pages excl. references)\n- Notification: June 7, 2026\n- Camera-ready: June 21, 2026\n- Late-breaking abstracts: July 20, 2026\n\n## Relevant Topics\n- Cognitive architectures\n- Embodied intelligence\n- Evolutionary systems\n- Synthetic biology / artificial life\n- Ethics of artificial life\n\n## Potential Paper Angles (from Xenota work)\n- Xenon awakening protocol: structured emergence of AI identity through chaperone-guided phases\n- Repertoire system: cognitive routines as composable building blocks for AI agents\n- Multi-model personality: how different LLM backends produce distinct identity signatures\n- Empirical results from automated awakening tests across GPT-5.3 and Claude Sonnet\n\n## Submission\nPortal: https://ssl.linklings.net/conferences/ALIFE/\nTemplates: Overleaf, LaTeX, MS-Word\nContact: program2026@alife.org","status":"open","priority":2,"issue_type":"task","owner":"git@codewithjv.com","created_at":"2026-02-18T22:18:24Z","created_by":"xenota/crew/earthshot","updated_at":"2026-02-18T22:18:24Z"}
{"id":"xc-u70","title":"Cleanup","description":"Stop all services you started.\n\n**Commands:**\n```bash\n# Kill your services (adjust for project)\ndocker-compose down\n# or\npkill -f \"your-service\"\n# or\n# whatever stops your infra\n```\n\n**Before closing this step, add notes:**\n```bash\nbd update \u003cthis-bead\u003e --notes \"Services stopped. Ports freed.\"\n```\n","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-07T02:20:36Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","dependencies":[{"issue_id":"xc-u70","depends_on_id":"xc-3i2","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-u70","depends_on_id":"xc-h7t","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-uht","title":"Use time.monotonic() for tick timing instead of datetime.now()","description":"Gemini Code Assist review on PR #5: datetime.now() is unreliable for timing loops because system clocks can drift/adjust (NTP syncs). Use time.monotonic() which is guaranteed to only move forward. daemon.py already uses this pattern correctly.","design":"## Plan\n\n**Approach:** Replace datetime.now() with time.monotonic() for elapsed time calculations in run_tick() while preserving datetime.now() for stored timestamps. The daemon.py already implements this pattern correctly - we follow the same approach. Use monotonic clock for the tick deadline comparison in the while loop, but keep datetime.now() for started_at/ended_at timestamps that get stored in journal entries.\n\n**Files:**\n- nucleus/src/nucleus/tick.py - Add time import, use monotonic() for tick deadline calculation in run_tick()\n\n**Changes:**\n1. Add `import time` at top of file\n2. In run_tick(): Calculate deadline using `time.monotonic() + duration` instead of `tick_start + timedelta(seconds=duration)`\n3. In run_tick(): Compare `time.monotonic() \u003c tick_deadline` instead of `datetime.now() \u003c tick_end`\n4. Keep datetime.now() for tick_start (stored in journal) - this is correct for timestamps\n5. run_tick_once() has no timing loop so needs no changes\n6. _close_tick() uses datetime.now() for ended_at timestamp - this is correct\n\n**Tests:**\n- Existing tests should pass (timing behavior unchanged for normal operation)\n- No new tests needed - this is a correctness fix, not new functionality\n\n**Risks:** None - straightforward pattern already used in daemon.py, isolated change to one function.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-02T20:38:47Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2026-01-02T22:08:46Z","labels":["gemini-code-assist","phase:execution","phase:planning","review-feedback"],"dependencies":[{"issue_id":"xc-uht","depends_on_id":"xc-4xr","type":"discovered-from","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-unq","title":"Implement observe routine","description":"Gatekeeper routine - triages incoming dispatches, creates strands. Input: new_dispatch, all_dispatches, all_strands, tick. Output: dispatch_updates, new_strands.","design":"## Plan\n\n**Approach:**\nCreate the observe routine following existing patterns in the codebase. The routine acts as gatekeeper - receives a new dispatch, reviews it against all dispatches and strands, then decides whether to mark it seen/noted/deferred or create a new strand. The prompt will guide the LLM to make triage decisions and return structured JSON output matching the nucleus contract.\n\n**Files:**\n- `repertoires/ooda/routines/observe/config.yaml` - Routine config with:\n  - Model: claude-sonnet-4-20250514 (per proposal)\n  - Temperature: 0.3 (consistent triage)\n  - Input: new_dispatch (required), all_dispatches, all_strands, tick\n  - Output: json type\n\n- `repertoires/ooda/routines/observe/prompt.md` - Prompt template that:\n  - Explains gatekeeper role and dispatch states\n  - Provides new dispatch and context via template vars\n  - Specifies JSON output format (dispatch_updates, new_strands)\n  - Emphasizes MUST update new dispatch state to prevent re-triggering\n  - Documents when to create strands vs mark seen/noted/deferred\n\n**Reference files:**\n- `/Users/jv/workspace/xenota/xenon-ooda-repertoire/repertoires/ooda/selector/config.yaml` - config format\n- `/Users/jv/workspace/xenota/xenon-ooda-repertoire/repertoire/tests/fixtures/sample_routine/config.yaml` - input/output schema\n\n**Tests:**\n- Eval cases deferred to xenon-host-hpi (Write eval cases)\n\n**Risks:**\nNone - straightforward implementation following established patterns and well-defined contract from proposal.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T20:32:56Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-28T21:46:01Z","labels":["phase:qa"],"dependencies":[{"issue_id":"xc-unq","depends_on_id":"xc-10g","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-unq","depends_on_id":"xc-bi5","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"comments":[{"id":38,"issue_id":"xc-unq","author":"jv","text":"## QA Results\n\n**Status:** Pass\n\n**Verified:**\n- [x] Config has correct model (claude-sonnet-4-20250514) and temperature (0.3)\n- [x] All required inputs present: new_dispatch, all_dispatches, all_strands, tick\n- [x] Prompt uses correct template variables ({{variable}} syntax)\n- [x] Output format matches nucleus contract (dispatch_updates, new_strands)\n- [x] Critical rules documented (must update new dispatch to prevent re-triggering)\n- [x] Dispatch states documented: seen, noted, deferred, actioned\n- [x] Strand types documented: alert, request, status, observation, reflection\n- [x] Workspace validates with xrs validate\n\n**Issues found:** None\n\n**Notes:**\n- Evals contain placeholder content (deferred to xenon-host-hpi as planned)\n- Implementation follows established patterns from selector/config.yaml\n\n**Recommendation:** Ready to complete","created_at":"2026-01-02T07:55:35Z"},{"id":39,"issue_id":"xc-unq","author":"jv","text":"## QA Results\n\n✅ All checks pass:\n- config.yaml: claude-sonnet-4-20250514, temp 0.3, all required inputs\n- prompt.md: gatekeeper role, dispatch states, strand creation rules\n- Output format matches nucleus contract\n- Critical rules documented (must update new dispatch)","created_at":"2026-01-02T07:55:35Z"},{"id":40,"issue_id":"xc-unq","author":"jv","text":"## QA Results\n\n**Status:** Pass\n\n**Verified:**\n- [x] Config has correct model (claude-sonnet-4-20250514) and temperature (0.3)\n- [x] All required inputs present: new_dispatch, all_dispatches, all_strands, tick\n- [x] Prompt uses correct template variables ({{variable}} syntax)\n- [x] Output format matches nucleus contract (dispatch_updates, new_strands)\n- [x] Critical rules documented (must update new dispatch to prevent re-triggering)\n- [x] Dispatch states documented: seen, noted, deferred, actioned\n- [x] Strand types documented: alert, request, status, observation, reflection\n- [x] Workspace validates with xrs validate\n\n**Issues found:** None\n\n**Notes:**\n- Evals contain placeholder content (deferred to xe-hpi as planned)\n- Implementation follows established patterns from selector/config.yaml\n\n**Recommendation:** Ready to complete","created_at":"2026-01-02T07:55:35Z"}],"work_type":"mutex"}
{"id":"xc-uz3a","title":"Digest: mol-witness-patrol","description":"Patrol 2: Polecat obsidian spawned by crew/starshot, hooked to xc-x3ab (xenon-cli podman error messages). Branch polecat/obsidian/xc-x3ab created. Agent state: spawning. No mail, no cleanup wisps, no MRs. Refinery running. All clear.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-07T09:57:26Z","updated_at":"2026-02-07T09:57:26Z","closed_at":"2026-02-07T09:57:26Z","work_type":"mutex"}
{"id":"xc-v2o","title":"VPN management for nucleus/cortex privacy","description":"VPN infrastructure to obscure the communication chain between xenon layers:\n\n**Goals:**\n- Hide nucleus location from cortex (cortex only knows VPN endpoint)\n- Hide cortex location from projections\n- Prevent traffic analysis revealing the control hierarchy\n- Enable geographic misdirection if needed\n\n**Options to evaluate:**\n- WireGuard (lightweight, modern)\n- Tailscale/Headscale (managed WireGuard)\n- Self-hosted VPN servers as intermediaries\n- Tor hidden services (for maximum anonymity)\n\n**Features:**\n- Automated VPN setup during VPS provisioning\n- Key rotation\n- Multi-hop routing for sensitive deployments\n- Fallback paths if VPN fails\n- Integration with vps-control SSH tunneling\n\n**Threat model:**\n- Protect against VPS provider logging\n- Protect against network-level surveillance\n- Maintain operational security for sovereign xenons","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-22T10:12:50Z","updated_at":"2026-01-05T21:12:29Z","labels":["infrastructure","security"],"work_type":"mutex"}
{"id":"xc-v5o","title":"Implement database layer","description":"Schema, migrations, connection management for nucleus.db","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-28T07:11:30Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-28T07:22:07Z","dependencies":[{"issue_id":"xc-v5o","depends_on_id":"xc-4xr","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-v5o","depends_on_id":"xc-kf4","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-v62","title":"Fix dispatch tick assignment when no tick is open","description":"**Bug**: Dispatches added when no tick is open get assigned to the previous tick number via `journal.get_latest_tick() or 1`, but get processed in the next tick. This breaks stats filtering in `_close_tick()` which uses `WHERE tick = ?`.\n\n**File**: nucleus/src/nucleus/cli.py\n\n**Options**:\n1. Use `get_latest_tick() + 1` for pending dispatches\n2. Separate `received_tick` from `processed_tick` in schema\n3. Update tick number when dispatch is actually processed\n\n**Acceptance**:\n- Dispatches processed in tick N have tick=N in database\n- `_close_tick()` stats accurately reflect what was processed","design":"## Plan\n\n**Approach:** Define dispatch.tick as \"tick when received or expected to be processed\". When no tick is open, assign dispatches to the NEXT tick number (get_latest_tick() + 1), not the previous. This ensures dispatches added between ticks are counted in the correct tick's stats.\n\n**Files:**\n- `/Users/jv/workspace/xenota/xenon/nucleus/src/nucleus/cli.py` - Fix dispatch add command: change `journal.get_latest_tick() or 1` to `(journal.get_latest_tick() or 0) + 1`\n\n**Tests:**\n- Add test in test_main.py or new test file: verify dispatch added between ticks gets tick=N+1\n- Existing tests should continue to pass (they set tick explicitly)\n\n**Risks:** None - simple one-line fix that aligns assignment with processing.\n\n**Related:** This fix works in conjunction with xenon-host-h1j. Together they define: tick = when received, get_next_new() processes all new dispatches regardless of tick.","notes":"Implemented: Changed tick assignment from `get_latest_tick() or 1` to `(get_latest_tick() or 0) + 1` in cli.py. Tests: 3 new tests added to test_cli_dispatch_tick.py, all passing. Total 112 tests passing. Commit: 3595464","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-03T09:55:13Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2026-01-03T10:47:07Z","labels":["phase:qa"],"comments":[{"id":41,"issue_id":"xc-v62","author":"jv","text":"## QA Results\n\n**Status:** PASS\n\n**Verified:**\n- [x] All tests pass (112 tests)\n- [x] Test coverage adequate (3 new tests for tick assignment)\n- [x] Functionality correct\n- [x] Code is clean\n- [x] Black and flake8 pass\n\n**Tests Reviewed:**\n- test_dispatch_tick_assignment_when_no_tick_open - verifies fix: tick=(latest or 0)+1\n- test_dispatch_tick_assignment_first_ever_dispatch - handles no-journal case\n- test_dispatch_tick_assignment_when_tick_is_open - preserves existing behavior\n\n**Acceptance Criteria:**\n- [x] Dispatches processed in tick N have tick=N in database (now assigned to next tick when between ticks)\n- [x] _close_tick() stats accurately reflect what was processed (tick assignment now matches processing)\n\n**Recommendation:** Ready to complete","created_at":"2026-01-02T21:46:33Z"}],"work_type":"mutex"}
{"id":"xc-w08","title":"Create orient routine","description":"ORIENT phase - enrich thought with context and relevance scores.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-25T04:56:14Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-27T09:37:22Z","dependencies":[{"issue_id":"xc-w08","depends_on_id":"xc-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-w08","depends_on_id":"xc-kbm","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-w7a3","title":"Merge: xe-iyu.2","description":"branch: xe-wisp-7r6\ntarget: main\nsource_issue: xe-iyu.2\nrig: xenon","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-07T05:06:48Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","work_type":"mutex"}
{"id":"xc-wisp-3sd","title":"Ready to land","description":"Final verification before landing.\n\n**Checklist:**\n- [ ] Design documented\n- [ ] Implementation complete\n- [ ] Review done, issues addressed\n- [ ] Tests passing\n- [ ] No uncommitted changes\n\nThis step confirms work is ready. Apply a landing aspect (oss, pr, mq)\nto add the actual landing step.\n","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-10T11:08:31Z","updated_at":"2026-02-10T11:18:21Z","closed_at":"2026-02-10T11:18:21Z","work_type":"mutex"}
{"id":"xc-wisp-4j3","title":"Ready to land","description":"Final verification before landing.\n\n**Checklist:**\n- [ ] Design documented\n- [ ] Implementation complete\n- [ ] Review done, issues addressed\n- [ ] Tests passing\n- [ ] No uncommitted changes\n\nThis step confirms work is ready. Apply a landing aspect (oss, pr, mq)\nto add the actual landing step.\n","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-13T08:44:25Z","updated_at":"2026-02-13T09:07:40Z","closed_at":"2026-02-13T09:07:40Z","work_type":"mutex"}
{"id":"xc-wisp-554","title":"dev-mq","description":"Complete maintainer MQ development workflow.\n\ndev-base + mq aspect = design → implement → review → test → Refinery MQ\n\nUse this for maintainer repos where:\n- origin = canonical repo\n- Refinery is running\n- Work done in worktree, auto-lands via MQ\n","status":"open","priority":2,"issue_type":"epic","created_at":"2026-02-09T11:58:40Z","updated_at":"2026-02-09T11:58:40Z","work_type":"mutex"}
{"id":"xc-wisp-5io","title":"Review implementation","description":"Review the code before testing. Use a team to run reviews in parallel.\n\n**Spawn a review team via the Task tool — three parallel agents:**\n\n1. **codex-review** (Bash agent): Run Codex code review.\n   ```bash\n   codex review --base main -c model_reasoning_effort=\"high\"\n   ```\n   Codex reviews the full diff against main with high reasoning.\n\n2. **self-review** (general-purpose agent): Review `git diff main` yourself.\n   Focus on: correctness, edge cases, adherence to codebase conventions,\n   security issues, missing error handling.\n\n3. **codex-design-check** (Bash agent): Verify implementation matches design.\n   ```bash\n   codex exec -c model_reasoning_effort=\"high\" \"Compare this implementation\n   against the original design. Flag any deviations or missing pieces.\n\n   Design:\n   $(bd show \u003cbead\u003e --field design)\n\n   Diff:\n   $(git diff main)\"\n   ```\n\n**Synthesize all reviews:**\n- Critical/Important issues from ANY reviewer: Fix before proceeding\n- Nits: Note and move on\n- Conflicts between reviewers: Use your judgment, prefer the stricter take\n\n**Before closing, record:**\n```bash\nbd update \u003cbead\u003e --notes \"## Review\n- Reviewers: codex, self, codex-design-check\n- Issues fixed: \u003clist or none\u003e\n- Issues deferred: \u003clist or none\u003e\"\n```\n","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-09T11:16:36Z","updated_at":"2026-02-09T11:39:24Z","closed_at":"2026-02-09T11:39:24Z","work_type":"mutex"}
{"id":"xc-wisp-6af","title":"dev-mq","description":"Complete maintainer MQ development workflow.\n\ndev-base + mq aspect = design → implement → review → test → Refinery MQ\n\nUse this for maintainer repos where:\n- origin = canonical repo\n- Refinery is running\n- Work done in worktree, auto-lands via MQ\n","status":"open","priority":2,"issue_type":"epic","created_at":"2026-02-10T11:08:31Z","updated_at":"2026-02-10T11:08:31Z","work_type":"mutex"}
{"id":"xc-wisp-96e.1","title":"State change: status → active","description":"Set status to active","status":"closed","priority":4,"issue_type":"event","created_at":"2026-02-18T08:51:44Z","created_by":"xenota/crew/earthshot","updated_at":"2026-02-18T08:51:44Z","closed_at":"2026-02-18T08:51:45Z","dependencies":[{"issue_id":"xc-wisp-96e.1","depends_on_id":"xc-wisp-96e","type":"parent-child","created_at":"2026-02-18T21:51:43Z","created_by":"xenota/crew/earthshot","metadata":"{}"}]}
{"id":"xc-wisp-a2t","title":"Submit to Refinery","description":"Submit work to Refinery merge queue.\n\n**Commands:**\n```bash\ngt done\n```\n\nThis:\n1. Creates MR in Refinery queue\n2. Refinery runs final checks\n3. Auto-lands to origin/main on success\n\n**Before closing, record:**\n```bash\nbd update \u003cbead\u003e --notes \"## Submitted to MQ\n- MR: \u003cmr-id\u003e\n- Status: queued\"\n```\n\nRefinery handles the rest. You're done.\n","status":"in_progress","priority":2,"issue_type":"task","created_at":"2026-02-09T11:58:40Z","updated_at":"2026-02-09T12:11:51Z","work_type":"mutex"}
{"id":"xc-wisp-aka","title":"Submit to Refinery","description":"Submit work to Refinery merge queue.\n\n**Commands:**\n```bash\ngt done\n```\n\nThis:\n1. Creates MR in Refinery queue\n2. Refinery runs final checks\n3. Auto-lands to origin/main on success\n\n**Before closing, record:**\n```bash\nbd update \u003cbead\u003e --notes \"## Submitted to MQ\n- MR: \u003cmr-id\u003e\n- Status: queued\"\n```\n\nRefinery handles the rest. You're done.\n","status":"in_progress","priority":2,"issue_type":"task","created_at":"2026-02-13T08:44:25Z","updated_at":"2026-02-13T09:07:50Z","work_type":"mutex"}
{"id":"xc-wisp-bmc","title":"Submit to Refinery","description":"Submit work to Refinery merge queue.\n\n**Commands:**\n```bash\ngt done\n```\n\nThis:\n1. Creates MR in Refinery queue\n2. Refinery runs final checks\n3. Auto-lands to origin/main on success\n\n**Before closing, record:**\n```bash\nbd update \u003cbead\u003e --notes \"## Submitted to MQ\n- MR: \u003cmr-id\u003e\n- Status: queued\"\n```\n\nRefinery handles the rest. You're done.\n","status":"in_progress","priority":2,"issue_type":"task","created_at":"2026-02-13T08:22:38Z","updated_at":"2026-02-13T08:46:05Z","work_type":"mutex"}
{"id":"xc-wisp-ca5","title":"dev-mq","description":"Complete maintainer MQ development workflow.\n\ndev-base + mq aspect = design → implement → review → test → Refinery MQ\n\nUse this for maintainer repos where:\n- origin = canonical repo\n- Refinery is running\n- Work done in worktree, auto-lands via MQ\n","status":"open","priority":2,"issue_type":"epic","created_at":"2026-02-09T11:47:12Z","updated_at":"2026-02-09T11:47:12Z","work_type":"mutex"}
{"id":"xc-wisp-cwn","title":"Review implementation","description":"Review the code before testing. Use a team to run reviews in parallel.\n\n**Spawn a review team via the Task tool — three parallel agents:**\n\n1. **codex-review** (Bash agent): Run Codex code review.\n   ```bash\n   codex review --base main -c model_reasoning_effort=\"high\"\n   ```\n   Codex reviews the full diff against main with high reasoning.\n\n2. **self-review** (general-purpose agent): Review `git diff main` yourself.\n   Focus on: correctness, edge cases, adherence to codebase conventions,\n   security issues, missing error handling.\n\n3. **codex-design-check** (Bash agent): Verify implementation matches design.\n   ```bash\n   codex exec -c model_reasoning_effort=\"high\" \"Compare this implementation\n   against the original design. Flag any deviations or missing pieces.\n\n   Design:\n   $(bd show \u003cbead\u003e --field design)\n\n   Diff:\n   $(git diff main)\"\n   ```\n\n**Synthesize all reviews:**\n- Critical/Important issues from ANY reviewer: Fix before proceeding\n- Nits: Note and move on\n- Conflicts between reviewers: Use your judgment, prefer the stricter take\n\n**Before closing, record:**\n```bash\nbd update \u003cbead\u003e --notes \"## Review\n- Reviewers: codex, self, codex-design-check\n- Issues fixed: \u003clist or none\u003e\n- Issues deferred: \u003clist or none\u003e\"\n```\n","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-09T13:17:34Z","updated_at":"2026-02-09T13:33:58Z","closed_at":"2026-02-09T13:33:58Z","work_type":"mutex"}
{"id":"xc-wisp-fj2","title":"Ready to land","description":"Final verification before landing.\n\n**Checklist:**\n- [ ] Design documented\n- [ ] Implementation complete\n- [ ] Review done, issues addressed\n- [ ] Tests passing\n- [ ] No uncommitted changes\n\nThis step confirms work is ready. Apply a landing aspect (oss, pr, mq)\nto add the actual landing step.\n","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-13T08:22:38Z","updated_at":"2026-02-13T08:45:53Z","closed_at":"2026-02-13T08:45:53Z","work_type":"mutex"}
{"id":"xc-wisp-fpe","title":"Submit to Refinery","description":"Submit work to Refinery merge queue.\n\n**Commands:**\n```bash\ngt done\n```\n\nThis:\n1. Creates MR in Refinery queue\n2. Refinery runs final checks\n3. Auto-lands to origin/main on success\n\n**Before closing, record:**\n```bash\nbd update \u003cbead\u003e --notes \"## Submitted to MQ\n- MR: \u003cmr-id\u003e\n- Status: queued\"\n```\n\nRefinery handles the rest. You're done.\n","status":"in_progress","priority":2,"issue_type":"task","created_at":"2026-02-10T11:09:39Z","updated_at":"2026-02-10T11:22:06Z","work_type":"mutex"}
{"id":"xc-wisp-gle","title":"dev-mq","description":"Complete maintainer MQ development workflow.\n\ndev-base + mq aspect = design → implement → review → test → Refinery MQ\n\nUse this for maintainer repos where:\n- origin = canonical repo\n- Refinery is running\n- Work done in worktree, auto-lands via MQ\n","status":"open","priority":2,"issue_type":"epic","created_at":"2026-02-10T18:50:35Z","updated_at":"2026-02-10T18:50:35Z","work_type":"mutex"}
{"id":"xc-wisp-jk1","title":"Submit to Refinery","description":"Submit work to Refinery merge queue.\n\n**Commands:**\n```bash\ngt done\n```\n\nThis:\n1. Creates MR in Refinery queue\n2. Refinery runs final checks\n3. Auto-lands to origin/main on success\n\n**Before closing, record:**\n```bash\nbd update \u003cbead\u003e --notes \"## Submitted to MQ\n- MR: \u003cmr-id\u003e\n- Status: queued\"\n```\n\nRefinery handles the rest. You're done.\n","status":"in_progress","priority":2,"issue_type":"task","created_at":"2026-02-10T11:08:31Z","updated_at":"2026-02-10T11:18:33Z","work_type":"mutex"}
{"id":"xc-wisp-qjv","title":"dev-mq","description":"Complete maintainer MQ development workflow.\n\ndev-base + mq aspect = design → implement → review → test → Refinery MQ\n\nUse this for maintainer repos where:\n- origin = canonical repo\n- Refinery is running\n- Work done in worktree, auto-lands via MQ\n","status":"open","priority":2,"issue_type":"epic","created_at":"2026-02-13T08:22:38Z","updated_at":"2026-02-13T08:22:38Z","work_type":"mutex"}
{"id":"xc-wisp-rwo","title":"dev-mq","description":"Complete maintainer MQ development workflow.\n\ndev-base + mq aspect = design → implement → review → test → Refinery MQ\n\nUse this for maintainer repos where:\n- origin = canonical repo\n- Refinery is running\n- Work done in worktree, auto-lands via MQ\n","status":"open","priority":2,"issue_type":"epic","created_at":"2026-02-10T10:52:22Z","updated_at":"2026-02-10T10:52:22Z","work_type":"mutex"}
{"id":"xc-wisp-tly","title":"Review implementation","description":"Review the code before testing. Use a team to run reviews in parallel.\n\n**Spawn a review team via the Task tool — three parallel agents:**\n\n1. **codex-review** (Bash agent): Run Codex code review.\n   ```bash\n   codex review --base main -c model_reasoning_effort=\"high\"\n   ```\n   Codex reviews the full diff against main with high reasoning.\n\n2. **self-review** (general-purpose agent): Review `git diff main` yourself.\n   Focus on: correctness, edge cases, adherence to codebase conventions,\n   security issues, missing error handling.\n\n3. **codex-design-check** (Bash agent): Verify implementation matches design.\n   ```bash\n   codex exec -c model_reasoning_effort=\"high\" \"Compare this implementation\n   against the original design. Flag any deviations or missing pieces.\n\n   Design:\n   $(bd show \u003cbead\u003e --field design)\n\n   Diff:\n   $(git diff main)\"\n   ```\n\n**Synthesize all reviews:**\n- Critical/Important issues from ANY reviewer: Fix before proceeding\n- Nits: Note and move on\n- Conflicts between reviewers: Use your judgment, prefer the stricter take\n\n**Before closing, record:**\n```bash\nbd update \u003cbead\u003e --notes \"## Review\n- Reviewers: codex, self, codex-design-check\n- Issues fixed: \u003clist or none\u003e\n- Issues deferred: \u003clist or none\u003e\"\n```\n","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-10T11:08:31Z","updated_at":"2026-02-10T11:17:29Z","closed_at":"2026-02-10T11:17:29Z","work_type":"mutex"}
{"id":"xc-wisp-wsd","title":"Submit to Refinery","description":"Submit work to Refinery merge queue.\n\n**Commands:**\n```bash\ngt done\n```\n\nThis:\n1. Creates MR in Refinery queue\n2. Refinery runs final checks\n3. Auto-lands to origin/main on success\n\n**Before closing, record:**\n```bash\nbd update \u003cbead\u003e --notes \"## Submitted to MQ\n- MR: \u003cmr-id\u003e\n- Status: queued\"\n```\n\nRefinery handles the rest. You're done.\n","status":"in_progress","priority":2,"issue_type":"task","created_at":"2026-02-10T18:50:35Z","updated_at":"2026-02-10T19:29:15Z","work_type":"mutex"}
{"id":"xc-wisp-xb5","title":"Ready to land","description":"Final verification before landing.\n\n**Checklist:**\n- [ ] Design documented\n- [ ] Implementation complete\n- [ ] Review done, issues addressed\n- [ ] Tests passing\n- [ ] No uncommitted changes\n\nThis step confirms work is ready. Apply a landing aspect (oss, pr, mq)\nto add the actual landing step.\n","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-09T13:17:34Z","updated_at":"2026-02-09T13:36:35Z","closed_at":"2026-02-09T13:36:35Z","work_type":"mutex"}
{"id":"xc-wisp-ynu","title":"dev-mq","description":"Complete maintainer MQ development workflow.\n\ndev-base + mq aspect = design → implement → review → test → Refinery MQ\n\nUse this for maintainer repos where:\n- origin = canonical repo\n- Refinery is running\n- Work done in worktree, auto-lands via MQ\n","status":"open","priority":2,"issue_type":"epic","created_at":"2026-02-13T08:44:25Z","updated_at":"2026-02-13T08:44:25Z","work_type":"mutex"}
{"id":"xc-wxu","title":"Fix Xenon workflows doc and flesh out architecture","description":"docs/technical/zenon-workflows.md is a thin command list with a 'Zenon' typo. Rename to Xenon, document the workflow architecture (layout, lifecycle, publish/install/update), and add guidance/examples so it’s usable.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-11T20:04:28Z","updated_at":"2025-12-11T20:38:17Z","closed_at":"2025-12-11T20:38:17Z","work_type":"mutex"}
{"id":"xc-x3ab","title":"xenon-cli: improve error messages when podman is not running","description":"attached_molecule: xc-wisp-19n\nattached_at: 2026-02-07T09:57:02Z\ndispatched_by: xenota/crew/starshot\n\nWhen podman machine is stopped, xenon up/down dump raw podman-compose Python tracebacks. Should catch the connection refused error and show a clear message like 'Podman is not running. Start it with: podman machine start'","status":"closed","priority":2,"issue_type":"feature","assignee":"xenota/polecats/quartz","created_at":"2026-02-07T09:55:14Z","updated_at":"2026-02-07T10:19:26Z","closed_at":"2026-02-07T10:19:26Z","work_type":"mutex"}
{"id":"xc-xe-a3m","title":"Check acceptance criteria","description":"Verify all acceptance criteria from the plan bead are met.\n\n**Commands:**\n```bash\nbd show \u003cplan-bead\u003e\n# Look for acceptance criteria section\n```\n\n**For each criterion:**\n- Is it testable?\n- Was it tested?\n- Did it pass?\n\n**Before closing this step, add notes:**\n```bash\nbd update \u003cthis-bead\u003e --notes \"## Acceptance Criteria\n- [ ] \u003ccriteria 1\u003e: PASS/FAIL\n- [ ] \u003ccriteria 2\u003e: PASS/FAIL\n- [ ] \u003ccriteria 3\u003e: PASS/FAIL\n\nAll criteria met: YES/NO\"\n```\n","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-07T02:20:38Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","dependencies":[{"issue_id":"xc-xe-a3m","depends_on_id":"xc-agi","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-xe-a3m","depends_on_id":"xc-gjf","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-xenon-crew-jv","title":"Crew worker jv in xenon - human-managed persistent workspace.","description":"Crew worker jv in xenon - human-managed persistent workspace.\n\nrole_type: crew\nrig: xenon\nagent_state: idle\nhook_bead: null\nrole_bead: hq-crew-role\ncleanup_status: null\nactive_mr: null\nnotification_level: null","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-06T23:44:41Z","updated_at":"2026-01-06T23:44:41Z","work_type":"mutex"}
{"id":"xc-xenon-polecat-furiosa","title":"xe-xenon-polecat-furiosa","description":"xe-xenon-polecat-furiosa\n\nrole_type: polecat\nrig: xenon\nagent_state: spawning\nhook_bead: xe-tsto\nrole_bead: hq-polecat-role\ncleanup_status: has_stash\nactive_mr: xe-qlp2\nnotification_level: null","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-07T17:14:56Z","updated_at":"2026-01-07T17:33:19Z","work_type":"mutex"}
{"id":"xc-xenon-witness","title":"xe-xenon-witness","description":"xe-xenon-witness\n\nrole_type: witness\nrig: xenon\nagent_state: running\nhook_bead: null\nrole_bead: hq-witness-role\ncleanup_status: null\nactive_mr: null\nnotification_level: null","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-07T08:33:00Z","updated_at":"2026-01-07T08:33:00Z","work_type":"mutex"}
{"id":"xc-xenota-crew-earthshot","title":"Crew worker earthshot in xenota - human-managed persistent workspace.","description":"Crew worker earthshot in xenota.\n\nrole_type: crew\nrig: xenota","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-07T08:40:19Z","updated_at":"2026-02-18T14:07:58Z","labels":["gt:agent","rig:xenota","role_type:crew"],"hook_bead":"xc-wisp-a7u","work_type":"mutex"}
{"id":"xc-xenota-crew-life","title":"Crew worker life in xenota - human-managed persistent workspace.","description":"Crew worker life in xenota.\n\nrole_type: crew\nrig: xenota","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-07T08:40:19Z","updated_at":"2026-02-07T08:40:19Z","labels":["gt:agent","rig:xenota","role_type:crew"],"work_type":"mutex"}
{"id":"xc-xenota-crew-prosperity","title":"Crew worker prosperity in xenota - human-managed persistent workspace.","description":"Crew worker prosperity in xenota.\n\nrole_type: crew\nrig: xenota","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-07T08:40:20Z","updated_at":"2026-02-07T08:40:20Z","labels":["gt:agent","rig:xenota","role_type:crew"],"work_type":"mutex"}
{"id":"xc-xenota-crew-starshot","title":"Crew worker starshot in xenota - human-managed persistent workspace.","description":"Crew worker starshot in xenota.\n\nrole_type: crew\nrig: xenota","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-07T08:40:20Z","updated_at":"2026-02-07T08:40:20Z","labels":["gt:agent","rig:xenota","role_type:crew"],"work_type":"mutex"}
{"id":"xc-xenota-mono-crew-earthshot","title":"Crew worker earthshot in xenota-mono - human-managed persistent workspace.","description":"Crew worker earthshot in xenota-mono.\n\nrole_type: crew\nrig: xenota-mono","status":"open","priority":2,"issue_type":"agent","created_at":"2026-02-07T08:38:08Z","updated_at":"2026-02-09T11:18:45Z","labels":["gt:agent","rig:xenota-mono","role_type:crew"],"work_type":"mutex"}
{"id":"xc-xenota-mono-crew-life","title":"Crew worker life in xenota-mono - human-managed persistent workspace.","description":"Crew worker life in xenota-mono.\n\nrole_type: crew\nrig: xenota-mono","status":"open","priority":2,"issue_type":"agent","created_at":"2026-02-07T08:38:08Z","updated_at":"2026-02-09T11:18:45Z","labels":["gt:agent","rig:xenota-mono","role_type:crew"],"work_type":"mutex"}
{"id":"xc-xenota-mono-crew-prosperity","title":"Crew worker prosperity in xenota-mono - human-managed persistent workspace.","description":"Crew worker prosperity in xenota-mono.\n\nrole_type: crew\nrig: xenota-mono","status":"open","priority":2,"issue_type":"agent","created_at":"2026-02-07T08:38:08Z","updated_at":"2026-02-09T11:18:46Z","labels":["gt:agent","rig:xenota-mono","role_type:crew"],"work_type":"mutex"}
{"id":"xc-xenota-mono-crew-starshot","title":"Crew worker starshot in xenota-mono - human-managed persistent workspace.","description":"Crew worker starshot in xenota-mono.\n\nrole_type: crew\nrig: xenota-mono","status":"open","priority":2,"issue_type":"agent","created_at":"2026-02-07T08:38:09Z","updated_at":"2026-02-09T11:18:46Z","labels":["gt:agent","rig:xenota-mono","role_type:crew"],"work_type":"mutex"}
{"id":"xc-xenota-mono-refinery","title":"Refinery for xenota-mono.","status":"open","priority":2,"issue_type":"agent","created_at":"2026-02-07T08:34:09Z","updated_at":"2026-02-09T11:18:46Z","labels":["gt:agent"],"work_type":"mutex"}
{"id":"xc-xenota-mono-witness","title":"Witness for xenota-mono.","status":"open","priority":2,"issue_type":"agent","created_at":"2026-02-07T08:34:09Z","updated_at":"2026-02-09T11:18:46Z","labels":["gt:agent"],"work_type":"mutex"}
{"id":"xc-xenota-polecat-amber","title":"xc-xenota-polecat-amber","description":"xc-xenota-polecat-amber\n\nrole_type: polecat\nrig: xenota\nagent_state: nuked\nhook_bead: null\ncleanup_status: null\nactive_mr: null\nnotification_level: null","status":"closed","priority":2,"issue_type":"agent","owner":"git@codewithjv.com","created_at":"2026-02-13T08:32:17Z","created_by":"xenota/crew/starshot","updated_at":"2026-02-17T11:13:57Z","closed_at":"2026-02-17T11:13:57Z","close_reason":"nuked","labels":["done-intent:COMPLETED:1770973680","gt:agent"],"work_type":"mutex"}
{"id":"xc-xenota-polecat-garnet","title":"xc-xenota-polecat-garnet","description":"xc-xenota-polecat-garnet\n\nrole_type: polecat\nrig: xenota\nagent_state: nuked\nhook_bead: null\ncleanup_status: null\nactive_mr: null\nnotification_level: null","status":"closed","priority":2,"issue_type":"agent","owner":"git@codewithjv.com","created_at":"2026-02-10T18:50:34Z","created_by":"xenota/crew/starshot","updated_at":"2026-02-17T11:14:12Z","closed_at":"2026-02-17T11:14:12Z","close_reason":"nuked","labels":["done-intent:COMPLETED:1770751765","gt:agent"],"work_type":"mutex"}
{"id":"xc-xenota-polecat-jasper","title":"xc-xenota-polecat-jasper","description":"xc-xenota-polecat-jasper\n\nrole_type: polecat\nrig: xenota\nagent_state: nuked\nhook_bead: null\ncleanup_status: null\nactive_mr: null\nnotification_level: null","status":"closed","priority":2,"issue_type":"agent","owner":"git@codewithjv.com","created_at":"2026-02-09T11:47:10Z","created_by":"xenota/crew/starshot","updated_at":"2026-02-17T11:14:25Z","closed_at":"2026-02-17T11:14:25Z","close_reason":"nuked","labels":["done-intent:COMPLETED:1770638131","done-intent:COMPLETED:1770722319","gt:agent"],"work_type":"mutex"}
{"id":"xc-xenota-polecat-obsidian","title":"xc-xenota-polecat-obsidian","description":"xc-xenota-polecat-obsidian\n\nrole_type: polecat\nrig: xenota\nagent_state: nuked\nhook_bead: null\ncleanup_status: null\nactive_mr: null\nnotification_level: null","status":"closed","priority":2,"issue_type":"agent","created_at":"2026-02-08T19:32:32Z","updated_at":"2026-02-17T11:14:36Z","closed_at":"2026-02-17T11:14:36Z","close_reason":"nuked","labels":["done-intent:COMPLETED:1770644205","gt:agent"],"work_type":"mutex"}
{"id":"xc-xenota-polecat-onyx","title":"xc-xenota-polecat-onyx","description":"xc-xenota-polecat-onyx\n\nrole_type: polecat\nrig: xenota\nagent_state: nuked\nhook_bead: null\ncleanup_status: null\nactive_mr: null\nnotification_level: null","status":"closed","priority":2,"issue_type":"agent","owner":"git@codewithjv.com","created_at":"2026-02-10T11:09:37Z","created_by":"xenota/crew/starshot","updated_at":"2026-02-17T11:14:48Z","closed_at":"2026-02-17T11:14:48Z","close_reason":"nuked","labels":["done-intent:COMPLETED:1770722531","gt:agent"],"work_type":"mutex"}
{"id":"xc-xenota-polecat-opal","title":"xc-xenota-polecat-opal","description":"xc-xenota-polecat-opal\n\nrole_type: polecat\nrig: xenota\nagent_state: nuked\nhook_bead: null\ncleanup_status: null\nactive_mr: null\nnotification_level: null","status":"closed","priority":2,"issue_type":"agent","owner":"git@codewithjv.com","created_at":"2026-02-10T11:33:38Z","created_by":"xenota/crew/starshot","updated_at":"2026-02-17T11:14:59Z","closed_at":"2026-02-17T11:14:59Z","close_reason":"nuked","labels":["gt:agent"],"work_type":"mutex"}
{"id":"xc-xenota-polecat-quartz","title":"xc-xenota-polecat-quartz","description":"xc-xenota-polecat-quartz\n\nrole_type: polecat\nrig: xenota\nagent_state: nuked\nhook_bead: null\ncleanup_status: null\nactive_mr: null\nnotification_level: null","status":"closed","priority":2,"issue_type":"agent","owner":"git@codewithjv.com","created_at":"2026-02-09T10:45:07Z","created_by":"xenota/crew/starshot","updated_at":"2026-02-17T11:15:09Z","closed_at":"2026-02-17T11:15:09Z","close_reason":"nuked","labels":["done-intent:COMPLETED:1770722507","gt:agent"],"work_type":"mutex"}
{"id":"xc-xenota-polecat-ruby","title":"xc-xenota-polecat-ruby","description":"xc-xenota-polecat-ruby\n\nrole_type: polecat\nrig: xenota\nagent_state: nuked\nhook_bead: null\ncleanup_status: null\nactive_mr: null\nnotification_level: null","status":"closed","priority":2,"issue_type":"agent","owner":"git@codewithjv.com","created_at":"2026-02-13T08:22:17Z","created_by":"xenota/crew/starshot","updated_at":"2026-02-17T11:15:19Z","closed_at":"2026-02-17T11:15:19Z","close_reason":"nuked","labels":["done-intent:COMPLETED:1770972371","gt:agent"],"work_type":"mutex"}
{"id":"xc-xenota-polecat-topaz","title":"xc-xenota-polecat-topaz","description":"xc-xenota-polecat-topaz\n\nrole_type: polecat\nrig: xenota\nagent_state: nuked\nhook_bead: null\ncleanup_status: null\nactive_mr: null\nnotification_level: null","status":"closed","priority":2,"issue_type":"agent","owner":"git@codewithjv.com","created_at":"2026-02-10T11:34:09Z","created_by":"xenota/crew/starshot","updated_at":"2026-02-17T11:15:29Z","closed_at":"2026-02-17T11:15:29Z","close_reason":"nuked","labels":["done-intent:COMPLETED:1770723932","gt:agent"],"work_type":"mutex"}
{"id":"xc-xenota-refinery","title":"Refinery for xenota.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-07T08:40:20Z","updated_at":"2026-02-07T08:40:20Z","labels":["gt:agent"],"work_type":"mutex"}
{"id":"xc-xenota-witness","title":"Witness for xenota.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-07T08:40:20Z","updated_at":"2026-02-07T08:40:20Z","labels":["backoff-until:1771327183","gt:agent","idle:1"],"work_type":"mutex"}
{"id":"xc-xgp","title":"Explore internationalization and multi-language support","description":"Consider how xenons handle internationalization: multiple languages, cultural contexts, localization of responses, language preferences, translation capabilities, and related i18n concerns.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T09:38:29Z","updated_at":"2025-12-23T04:50:02Z","closed_at":"2025-12-23T04:50:02Z","labels":["concepts","research"],"work_type":"mutex"}
{"id":"xc-xrh","title":"Signing dispatches: time vs tick semantics","description":"When signing dispatches, decide whether the signature should bind (a) wall-clock time (timestamp), (b) monotonic tick/sequence from nucleus/cortex, or (c) both.\n\nQuestions:\n- What field(s) are included in the signed payload?\n- Which clock is authoritative (nucleus? cortex? projection?)\n- How do we prevent replay across restarts / forks?\n- Ordering: do consumers rely on tick ordering vs timestamp?\n- What does verification do when clocks drift?\n\nConsider: include tick + optional timestamp; require strictly-increasing tick per signer; define validity window if using time; document canonical serialization.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-23T12:22:19Z","updated_at":"2026-01-05T21:12:29Z","labels":["protocol","security"],"work_type":"mutex"}
{"id":"xc-xv0","title":"Add deterministic validators to eval pipeline","description":"Run structure/schema validation before LLM judges. Fail fast on invalid structure (saves API costs). Could be validators.py in evals/ or schema.json for JSON schema validation. Separate from LLM judges which handle semantic checks only.","design":"**Approach:** Add optional JSON Schema validation to routine output before LLM judges run. Extend `config.yaml` with an `output.schema` field containing a JSON Schema definition. Use the `jsonschema` library for validation. On validation failure, mark the case as failed and skip LLM judge calls entirely (saving API costs).\n\n**Files:**\n- evaluator.py - Add validation step before judge loop\n- output_validator.py - New file for schema validation logic\n- loader.py - Parse output.schema from config.yaml into Routine\n- models.py - Update Routine.output_schema to hold JSON Schema dict\n- pyproject.toml - Add jsonschema dependency\n- routines/*/config.yaml - Add output.schema examples","notes":"Implemented deterministic validators using JSON Schema. Added output_validator.py with ValidationResult dataclass. Evaluator now validates routine output before LLM judges run - validation failures skip judges entirely (saving API costs). Added schema examples to observe and decide routines. All 90 tests passing. Commit: ef14f30","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-02T08:42:38Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2026-01-02T10:45:24Z","labels":["phase:qa"],"comments":[{"id":42,"issue_id":"xc-xv0","author":"jv","text":"## QA Results\n\n**Status:** Pass (with fixes)\n\n**Verified:**\n- [x] All tests pass (repertoire-studio: 90/90, repertoire: 110/110)\n- [x] Test coverage adequate - 13 new tests for output_validator.py\n- [x] Functionality works - xrs eval runs successfully with validation\n- [x] Code is well-factored - clean ValidationResult dataclass, proper error handling\n- [x] Follows project patterns - consistent with existing evaluator structure\n- [x] Backward compatibility - routines without schemas still work (orient scores 10.0)\n\n**Issues found and fixed:**\n- Test assertion in test_loader.py expected old output_schema format (type: json) instead of new JSON Schema format (type: object). Fixed in commit 667466a.\n\n**Recommendation:** Ready to complete","created_at":"2026-01-02T07:55:35Z"}],"work_type":"mutex"}
{"id":"xc-xwn","title":"Evaluate communications using ELM framework","description":"Apply Elaboration Likelihood Model to assess Xenota comms. Central route (argument quality) vs peripheral route (cues). See zk/elaboration-likelihood-model.md","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-23T01:51:57Z","updated_at":"2025-12-23T01:51:57Z","work_type":"mutex"}
{"id":"xc-xxm","title":"Process each comment","description":"For each review comment, decide and act.\n\n**Categorize each comment:**\n| Category | Action |\n|----------|--------|\n| Critical | Must fix |\n| Important | Should fix |\n| Nit | Reply \"Won't fix: \u003creason\u003e\" and resolve |\n| False positive | Reply \"False positive: \u003creason\u003e\" and resolve |\n\n**For fixes:**\nMake the change and commit.\n\n**For declines:**\n```bash\n# Reply to the comment\ngh api -X POST repos/{owner}/{repo}/pulls/{pr}/comments/{comment_id}/replies -f body=\"Won't fix: \u003creason\u003e\"\n```\n\n**Before closing this step, add notes:**\n```bash\nbd update \u003cthis-bead\u003e --notes \"## Comments Processed\n- Fixed: \u003ccount\u003e (\u003clist\u003e)\n- Declined: \u003ccount\u003e (\u003clist with reasons\u003e)\"\n```\n","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-07T02:20:35Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","dependencies":[{"issue_id":"xc-xxm","depends_on_id":"xc-7cj","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-xxm","depends_on_id":"xc-flm","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-xxm","depends_on_id":"xc-zm8","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-xxs","title":"Implement StrandStore","description":"SQLite-backed strand storage (add, get_all, update)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T07:11:46Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-28T07:24:33Z","dependencies":[{"issue_id":"xc-xxs","depends_on_id":"xc-4xr","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-xxs","depends_on_id":"xc-exe","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-xxs","depends_on_id":"xc-v5o","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-y31","title":"Implement packer","description":"Create .rpt archive from workspace (validate, exclude evals/).","design":"## Plan\n\n**Approach:**\nCreate packer.py with pack_workspace() that validates first, then creates tgz archive. Excludes evals/ directories. Output defaults to {name}-{version}.rpt.\n\n**Files:**\n- `src/repertoire_studio/packer.py` - pack_workspace(), PackError\n- `tests/test_packer.py` - tests\n\n**Implementation:**\n1. Call validate_workspace() first, raise PackError if errors\n2. Load Workspace for name/version\n3. Create tarfile with gzip, filter excluding evals/\n4. Return path to created archive\n\n**Tests:**\n- Valid workspace creates .rpt file\n- Archive contains expected files, excludes evals/\n- Invalid workspace raises PackError\n- Custom output path works\n- Default naming format\n\n**Risks:** None.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-25T04:55:38Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-27T09:00:09Z","labels":["phase:planning"],"dependencies":[{"issue_id":"xc-y31","depends_on_id":"xc-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-y31","depends_on_id":"xc-hcj","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-y8a","title":"Podman setup","description":"Containerfile, podman-compose for running soul server in container","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T11:21:27Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-22T05:46:15Z","dependencies":[{"issue_id":"xc-y8a","depends_on_id":"xc-qaq","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-y8a","depends_on_id":"xc-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-ye0","title":"Implement LiteLLMClient","description":"Async wrapper around litellm for completion requests with model config support.","design":"## Plan\n\n**Approach:** Create a thin async wrapper around litellm.acompletion() following the spec. Define a custom LLMError exception to wrap litellm exceptions for cleaner error handling. Follow existing code patterns (dataclasses, docstrings with Args/Returns/Raises, pytest fixtures).\n\n**Files:**\n- `/Users/jv/workspace/xenota/xenon/repertoire/src/repertoire/llm.py` - new, LiteLLMClient class with async complete() method\n- `/Users/jv/workspace/xenota/xenon/repertoire/src/repertoire/__init__.py` - add LiteLLMClient to exports\n- `/Users/jv/workspace/xenota/xenon/repertoire/tests/test_llm.py` - new, unit tests with mocked litellm\n- `/Users/jv/workspace/xenota/xenon/repertoire/pyproject.toml` - add pytest-asyncio to dev dependencies\n\n**Tests:**\n- Unit tests mocking litellm.acompletion: success case, model override, custom temperature/max_tokens\n- Error handling tests: AuthenticationError, RateLimitError, APIConnectionError wrapped to LLMError\n- Optional integration test marked with @pytest.mark.integration calling gemini/gemini-2.0-flash-exp\n\n**Risks:** None - straightforward wrapper, follows established patterns.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-25T17:55:01Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-25T21:40:30Z","labels":["phase:qa"],"dependencies":[{"issue_id":"xc-ye0","depends_on_id":"xc-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-ye0","depends_on_id":"xc-b1i","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"comments":[{"id":43,"issue_id":"xc-ye0","author":"jv","text":"## QA Results\n\n**Status:** PASS\n\n**Verified:**\n- [x] All tests pass (50 passed, 1 skipped - integration test)\n- [x] Test coverage adequate (6 unit tests cover init, complete, model override, custom params, error handling)\n- [x] Functionality verified via imports\n- [x] Code is well-factored (clean async wrapper, proper exception wrapping with chain)\n- [x] Follows project patterns (docstrings with Args/Returns/Raises, type hints)\n\n**Tests:**\n- test_init_default_model - verifies default model\n- test_init_custom_model - verifies custom model\n- test_complete_success - verifies completion and correct litellm call\n- test_complete_model_override - verifies per-call model override\n- test_complete_custom_params - verifies temperature/max_tokens params\n- test_complete_error_wrapped - verifies LLMError wrapping with cause chain\n- test_integration_gemini - integration test (skipped without API key)\n\n**Code Quality:**\n- Clean module structure (63 lines)\n- LLMError exception with model context\n- LiteLLMClient with async complete() method\n- Proper type hints throughout\n- Good docstrings following project style\n- Exports added to __init__.py\n\n**Issues found:** None\n\n**Recommendation:** Ready to complete","created_at":"2025-12-25T08:39:48Z"}],"work_type":"mutex"}
{"id":"xc-ykx","title":"Add eval fixtures support","description":"Implement @file: syntax for referencing external fixture files from CSV cells in cases.csv and judges.csv. This allows complex JSON/YAML test data to be stored in separate files instead of escaped within CSV cells.","design":"## Plan\n\n**Approach:** Add a `resolve_cell_value()` helper function that detects `@file:` prefix, resolves paths relative to the CSV file's directory, and loads file content. JSON → dict/list, YAML → dict/list, other → string.\n\n**Design Decisions (per Codex review):**\n1. **Type handling:** Cases inputs become Python objects (dict/list/etc). Judges prompts stay strings (only text files for prompts).\n2. **Detection:** Strip cell first, then check `@file:` prefix. Trim whitespace after colon. No escape mechanism needed (@@file: is overkill).\n3. **Path security:** Reject absolute paths (startswith / or drive letter). Allow `../` for shared fixtures. No `~` expansion.\n4. **Error context:** Include CSV file path, row number, column name, and fixture path.\n5. **Encoding:** UTF-8 only. Preserve exact content (no strip).\n6. **Dependencies:** PyYAML already in pyproject.toml.\n\n**Files:**\n- `repertoire-studio/src/repertoire_studio/evaluator.py` - Add resolve_cell_value(), modify load_eval_cases() and load_judges()\n\n**Tests:**\n- JSON fixture loading (object, array, primitive)\n- YAML fixture loading (.yaml and .yml extensions)\n- Plain text file loading\n- Whitespace trimming in path (`@file: fixtures/data.json`)\n- Absolute path rejection with error\n- Missing file error with full context\n- Invalid JSON/YAML parse error with file path\n- Mixed inline and fixture values in same row\n- Parent directory references (`../shared/`)\n- Windows drive path rejection (`C:\\`)\n\n**Risks:** None - isolated change, existing dependency.","notes":"Implemented resolve_cell_value() helper in evaluator.py. Modified load_eval_cases() and load_judges() to support @file: syntax. Added 19 tests (all passing). Total 90 tests pass.","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-29T12:03:28Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-29T17:42:26Z","labels":["phase:qa","phase:qa-complete"],"comments":[{"id":44,"issue_id":"xc-ykx","author":"jv","text":"## QA Results\n\n**Status:** Pass\n\n**Verified:**\n- [x] All tests pass (90/90, including 29 evaluator tests)\n- [x] Test coverage adequate - covers all planned cases from design\n- [x] Functionality works as expected\n- [x] Code is clean and well-factored\n- [x] Follows project patterns\n\n**Test Coverage Analysis:**\n- Unit tests for resolve_cell_value(): JSON (object, array, primitives), YAML (.yaml, .yml), plain text\n- Security tests: absolute path rejection (Unix and Windows), error context includes row/column/file\n- Error handling: missing files, invalid JSON, invalid YAML - all with context\n- Edge cases: whitespace trimming, non-file references preserved, parent directory refs\n- Integration tests: load_eval_cases and load_judges with fixtures, mixed values, nested paths\n- Existing run_eval tests still pass\n\n**Security Review:**\n- Absolute paths properly rejected (Unix / and Windows C:\\)\n- Parent directory traversal (../) allowed per design - intentional for shared fixtures\n- No ~ expansion as specified in design\n- yaml.safe_load used (not yaml.load) - safe from arbitrary code execution\n\n**Code Quality:**\n- Helper function resolve_cell_value() is well-documented with docstring\n- Error messages include full context (CSV name, row number, column name, fixture path)\n- UTF-8 encoding explicitly specified\n- Type hints present\n- Follows existing codebase patterns\n\n**Issues found:** None\n\n**Recommendation:** Ready to complete","created_at":"2026-01-02T07:55:35Z"},{"id":45,"issue_id":"xc-ykx","author":"jv","text":"## QA Results: PASS\n\n- All 90 tests pass (29 evaluator tests)\n- JSON/YAML/text fixtures work correctly\n- Error handling comprehensive with context\n- Security: absolute paths rejected, yaml.safe_load() used\n- Code quality good, follows project patterns","created_at":"2026-01-02T07:55:35Z"}],"work_type":"mutex"}
{"id":"xc-ysy","title":"mol-internal-review","description":"Internal (no-GitHub) review workflow.\n\nThis is for review stages where work lives on a local branch and we are NOT doing:\n- GitHub PR URL gathering\n- Gemini PR comment fetching\n- gh comment replies / thread resolution\n\nInstead, review is performed against the branch diff and local checks.\n\n## HARD GATE\n\nBefore closing this bead, verify all children are closed:\n```bash\nbd show \u003cthis-bead\u003e | grep \"Children\"\n```\n\n## Expectations\n- Reviewer reads the diff against main\n- Reviewer runs the project’s check/test command(s)\n- Any required fixes are made and committed to the branch\n- Notes summarize what was reviewed and any issues found\n","status":"closed","priority":2,"issue_type":"epic","created_at":"2026-01-07T04:06:33Z","updated_at":"2026-01-07T07:28:31Z","closed_at":"2026-01-07T07:28:31Z","work_type":"mutex"}
{"id":"xc-z02n","title":"Digest: mol-refinery-patrol","description":"Patrol cycle: MQ empty, 0 branches merged","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T13:38:54Z","updated_at":"2026-01-08T13:38:54Z","closed_at":"2026-01-08T13:38:54Z","work_type":"mutex"}
{"id":"xc-z17","title":"Nucleus cloning and disaster recovery","description":"Ability to clone and recover a nucleus in case of server compromise or failure:\n\n**Core requirements:**\n- Full nucleus state backup (encrypted)\n- Sovereign key backup/recovery (highest security)\n- Ability to spin up nucleus on new VPS from backup\n- Automatic failover if primary nucleus becomes unreachable\n\n**What needs to be backed up:**\n- Sovereign key (encrypted, possibly split/shamir)\n- Genome, imprints, impulse state\n- Narratives and memories\n- Objectives (tasks, projects, goals, dreams)\n- Relationship data\n- Configuration\n\n**Recovery scenarios:**\n1. VPS compromised - spin up new nucleus elsewhere, revoke old\n2. VPS provider issue - migrate to different provider\n3. Chaperone device lost - recover from secure backup\n4. Planned migration - seamless handoff to new infrastructure\n\n**Security considerations:**\n- Backup encryption (chaperone-held key)\n- Backup location separate from nucleus VPS\n- Integrity verification before restore\n- Audit trail of all backup/restore operations\n- Consider hardware security modules for sovereign key","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-22T10:12:50Z","updated_at":"2026-01-05T21:12:29Z","labels":["infrastructure","security"],"work_type":"mutex"}
{"id":"xc-z5e","title":"Chat Projection Implementation","description":"Implement the chat-projection spec: dev environment, vps-control library, projection CLI, blueprints, base image, and chat projection. See openspec/changes/chat-projection/proposal.md","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-22T11:29:47Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-23T09:33:43Z","work_type":"mutex"}
{"id":"xc-z5e.1","title":"Create dev-vps base Containerfile","description":"Rocky Linux 9 + SSH + Podman + fuse-overlayfs","design":"## Plan: Create dev-vps base Containerfile\n\n**Approach:** Create minimal Containerfile for dev-vps based on Rocky Linux 9. Install openssh-server, podman, and fuse-overlayfs. Configure SSH to allow root login with password (dev only - hardening deferred to task .2). Configure rootless Podman with subuid/subgid and fuse-overlayfs storage driver.\n\n**Files:**\n- `containers/dev-vps/Containerfile` (new)\n\n**Implementation:**\n1. Base image: `rockylinux:9`\n2. Install: openssh-server, podman, fuse-overlayfs\n3. SSH: Generate host keys, enable PermitRootLogin\n4. Podman: subuid/subgid entries, fuse-overlayfs storage driver\n5. Set default root password for dev access\n6. Expose port 22, CMD runs sshd -D\n\n**Tests:**\n- Build container successfully\n- SSH into container with root password\n- Run podman info and podman run hello-world inside\n- Verify nested containers work","notes":"Implemented containers/dev-vps/Containerfile. Tests pass: build, SSH key auth, podman info, nested alpine container. Minor cgroup warning (non-blocking).","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T11:33:33Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-22T11:57:41Z","labels":["phase:qa"],"dependencies":[{"issue_id":"xc-z5e.1","depends_on_id":"xc-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-z5e.10","title":"Create cloud-init template with kernel hardening","description":"sysctls, SSH config, firewall","design":"## Plan\n\n**Approach:** Create a cloud-init YAML template in vps-control/templates/ for VPS provisioning. The template will be a Jinja2-rendered YAML that Terraform or other provisioning tools can use. It applies kernel hardening sysctls, SSH hardening, and nftables firewall configuration. Follow patterns from containers/dev-vps (nftables.conf, SSH config in Containerfile).\n\n**Files:**\n- src/vps_control/templates/cloud_init.yaml.j2 - Jinja2 cloud-init template with:\n  - write_files for /etc/sysctl.d/99-xenon-hardening.conf\n  - write_files for /etc/ssh/sshd_config.d/xenon.conf\n  - write_files for /etc/nftables.conf\n  - runcmd to apply sysctl, enable nftables, restart sshd\n- src/vps_control/provisioning.py - Python module to render cloud-init template with parameters\n- tests/test_provisioning.py - Tests for cloud-init rendering\n\n**Tests:**\n- Verify template renders with default parameters\n- Verify template renders with custom parameters (controller_ip, ssh_port, allowed_ports)\n- Verify sysctl settings match proposal spec exactly\n- Verify SSH config follows key-only, custom port pattern\n\n**Risks:** None - follows established patterns from dev-vps and proposal.md. No runtime dependencies.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T00:33:36Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-23T13:16:58Z","labels":["phase:qa"],"dependencies":[{"issue_id":"xc-z5e.10","depends_on_id":"xc-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-z5e.10","depends_on_id":"xc-z5e.5","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"comments":[{"id":46,"issue_id":"xc-z5e.10","author":"jv","text":"## QA Results\n\n**Status:** Pass\n\n**Verified:**\n- [x] All tests pass (14/14 provisioning tests, 41/41 total suite)\n- [x] Test coverage adequate - covers defaults, custom params, edge cases, validation\n- [x] Functionality works - module imports and renders valid cloud-init YAML\n- [x] Code is well-factored - clean separation of template and rendering logic\n- [x] Follows project patterns - matches vps-control structure\n- [x] Security validated - IP validation, port range checks, injection prevention\n\n**Tests cover:**\n- Default parameter rendering\n- Custom parameters (controller_ip, ssh_port, allowed_ports)\n- SSH port always in firewall rules\n- IPv4/IPv6 controller IP with correct nftables syntax\n- Port validation (1-65535)\n- IP address validation\n- Empty allowed_ports handling\n- nftables established/loopback/ICMP rules\n\n**Implementation quality:**\n- Template properly structured with kernel hardening, SSH config, nftables\n- Python module exports render_cloud_init in __init__.py\n- Input validation prevents injection attacks\n- Uses ipaddress module for canonical IP form\n\n**Issues found:** None\n\n**Recommendation:** Ready to complete","created_at":"2025-12-23T00:16:33Z"}],"work_type":"mutex"}
{"id":"xc-z5e.11","title":"Define blueprint schema and types","description":"TypeScript types, JSON schema","design":"## Plan\n\n**Approach:** Create Python dataclasses for all blueprint types defined in the spec. Use standard library dataclasses (not pydantic) to match existing codebase patterns. Create a separate JSON Schema file for config validation per the spec requirement (JSON Schema Draft 7). Place all types in a new `blueprints/` subpackage.\n\n**Files:**\n- `src/vps_control/blueprints/__init__.py` - Export all types\n- `src/vps_control/blueprints/types.py` - All dataclass definitions:\n  - `PortDefinition` - (name, container_port, description, required)\n  - `VolumeDefinition` - (name, container_path, mode, required)\n  - `EnvVar` - (name, description, default)\n  - `SecretDefinition` - (name, description)\n  - `ResourceLimits` - (cpu_limit, memory_limit, memory_reservation)\n  - `HealthCheck` - (command, interval, timeout, retries, start_period)\n  - `Blueprint` - Full metadata container\n  - `InstantiationConfig` - Runtime config for creating projections\n  - `ValidationResult` - (valid, errors)\n  - `GeneratedDeployment` - (compose_path, compose_content, config_files)\n- `src/vps_control/blueprints/schema/blueprint.schema.json` - JSON Schema for blueprint.yaml validation\n- `src/vps_control/blueprints/schema/config.schema.json` - JSON Schema for instantiation config validation\n\n**Dependencies:**\n- Add `jsonschema\u003e=4.0` to pyproject.toml for JSON Schema validation\n\n**Tests:**\n- Test dataclass instantiation with valid data\n- Test optional fields default to None/empty\n- Test schema validation with valid/invalid configs (covered in z5e.12)\n\n**Risks:** None - straightforward data structure definitions following existing patterns.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T00:33:50Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-23T13:34:00Z","labels":["phase:qa"],"dependencies":[{"issue_id":"xc-z5e.11","depends_on_id":"xc-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-z5e.11","depends_on_id":"xc-z5e.5","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"comments":[{"id":47,"issue_id":"xc-z5e.11","author":"jv","text":"## QA Results\n\n**Status:** Pass\n\n**Verified:**\n- [x] All tests pass (21 blueprint tests + 35 other tests = 56 total, 6 skipped integration tests)\n- [x] Test coverage adequate - all 11 dataclasses tested with minimal and full field cases\n- [x] All types import correctly from vps_control.blueprints\n- [x] JSON schemas are valid Draft-07 schemas\n- [x] Code is clean and follows existing patterns (standard dataclasses, proper typing)\n\n**Files Implemented:**\n- src/vps_control/blueprints/__init__.py - exports 11 types\n- src/vps_control/blueprints/types.py - 11 dataclasses\n- src/vps_control/blueprints/schema/blueprint.schema.json - 13 properties\n- src/vps_control/blueprints/schema/config.schema.json - 8 properties\n\n**Note on jsonschema dependency:**\nPlan mentioned adding jsonschema\u003e=4.0 but this was not added. This is acceptable since the current task only defines types and schemas - the dependency will be needed for xenon-host-z5e.12 (blueprint loader) which actually uses schema validation.\n\n**Recommendation:** Ready to complete","created_at":"2025-12-23T00:27:14Z"},{"id":48,"issue_id":"xc-z5e.11","author":"jv","text":"## QA Results\n\n**Status:** Pass\n\n**Verified:**\n- [x] All tests pass (21 blueprint tests + 35 other tests = 56 total, 6 skipped integration tests)\n- [x] Test coverage adequate - all 11 dataclasses tested with minimal and full field cases\n- [x] All types import correctly from vps_control.blueprints\n- [x] JSON schemas are valid Draft-07 schemas\n- [x] Code is clean and follows existing patterns (standard dataclasses, proper typing)\n\n**Files Implemented:**\n- src/vps_control/blueprints/__init__.py - exports 11 types\n- src/vps_control/blueprints/types.py - 11 dataclasses\n- src/vps_control/blueprints/schema/blueprint.schema.json - 13 properties\n- src/vps_control/blueprints/schema/config.schema.json - 8 properties\n\n**Note on jsonschema dependency:**\nPlan mentioned adding jsonschema\u003e=4.0 but this was not added. This is acceptable since the current task only defines types and schemas - the dependency will be needed for xe-z5e.12 (blueprint loader) which actually uses schema validation.\n\n**Recommendation:** Ready to complete","created_at":"2025-12-23T00:27:14Z"}],"work_type":"mutex"}
{"id":"xc-z5e.12","title":"Implement blueprint loader","description":"load/validate blueprint.yaml","design":"## Plan\n\n**Approach:** Create `BlueprintLoader` class that loads blueprints from a directory. Each blueprint subdirectory contains `blueprint.yaml`, `compose.template.yaml`, and `config.schema.json`. The loader parses YAML into Blueprint dataclass, validates against JSON schemas using jsonschema library, and provides list/load/validate methods per the spec.\n\n**Files:**\n- `src/vps_control/blueprints/loader.py` - new, BlueprintLoader class:\n  - `__init__(blueprints_dir: str)` - store directory path\n  - `list() -\u003e list[str]` - scan subdirs for blueprint.yaml\n  - `load(name: str) -\u003e Blueprint` - parse YAML, validate against blueprint.schema.json, convert to dataclass\n  - `validate(name: str, config: dict) -\u003e ValidationResult` - validate config against config.schema.json\n- `src/vps_control/blueprints/__init__.py` - add BlueprintLoader export\n- `pyproject.toml` - add `jsonschema\u003e=4.0` dependency (pyyaml already present)\n\n**Implementation details:**\n- Use pathlib for directory operations\n- Load blueprint.schema.json once in __init__ for reuse\n- Parse nested objects (ports, volumes, env, etc.) into their respective dataclasses\n- Map jsonschema validation errors to ValidationError/ValidationResult types\n- Raise BlueprintNotFoundError (custom exception) when blueprint doesn't exist\n\n**Tests:**\n- `tests/test_loader.py` - new:\n  - BlueprintLoader.list() returns available blueprints\n  - BlueprintLoader.load() parses all fields correctly\n  - BlueprintLoader.load() raises error for missing blueprint\n  - BlueprintLoader.load() raises error for invalid blueprint.yaml\n  - BlueprintLoader.validate() returns valid for good config\n  - BlueprintLoader.validate() returns errors for bad config\n- Create test fixtures in `tests/fixtures/blueprints/` with sample blueprint\n\n**Risks:** None - straightforward file I/O and schema validation using well-established libraries.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T00:33:51Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-23T13:44:37Z","labels":["phase:qa"],"dependencies":[{"issue_id":"xc-z5e.12","depends_on_id":"xc-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-z5e.12","depends_on_id":"xc-z5e.11","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"comments":[{"id":49,"issue_id":"xc-z5e.12","author":"jv","text":"## QA Results\n\n**Status:** Pass\n\n**Verified:**\n- [x] All tests pass (32/32 in test_loader.py, 88/94 full suite with 6 expected skips)\n- [x] Test coverage adequate - covers init, list, load, validate methods, error cases, edge cases\n- [x] Functionality works as expected - blueprints load correctly with all nested objects\n- [x] Code is clean and well-factored - follows project patterns, uses pathlib, proper error handling\n- [x] Path traversal protection implemented\n- [x] JSON Schema validation using Draft7Validator\n- [x] Proper exports in __init__.py\n\n**Issues found:** None\n\n**Recommendation:** Ready to complete","created_at":"2025-12-23T00:42:35Z"}],"work_type":"mutex"}
{"id":"xc-z5e.13","title":"Implement compose file generator","description":"blueprint template + config → compose","design":"## Plan\n\n**Approach:** Create `ComposeGenerator` class that generates Podman compose files from blueprints and instantiation configs. Use Jinja2 templating (already a dependency) instead of Handlebars for Python compatibility. The generator builds the compose structure programmatically rather than using an external template file - this gives better type safety and control over the output format.\n\n**Files:**\n- `src/vps_control/blueprints/generator.py` - new, ComposeGenerator class:\n  - `__init__(blueprint_loader: BlueprintLoader)` - store loader reference\n  - `generate(blueprint_name: str, config: InstantiationConfig) -\u003e GeneratedDeployment` - main method\n  - `_merge_config(blueprint: Blueprint, config: InstantiationConfig) -\u003e dict` - merge defaults with config\n  - `_build_ports(blueprint: Blueprint, config: InstantiationConfig) -\u003e list[str]` - generate port mappings\n  - `_build_volumes(blueprint: Blueprint, config: InstantiationConfig) -\u003e list[str]` - generate volume mappings\n  - `_build_environment(blueprint: Blueprint, config: InstantiationConfig) -\u003e dict[str, str]` - generate env vars\n  - `_build_resources(blueprint: Blueprint) -\u003e dict | None` - generate deploy.resources section\n  - `_build_healthcheck(blueprint: Blueprint) -\u003e dict | None` - generate healthcheck section\n- `src/vps_control/blueprints/__init__.py` - add ComposeGenerator export\n\n**Implementation details:**\n- Build compose dict programmatically for type safety and validation\n- Map port names from config (e.g., `{\"web\": 3001}`) to container ports from blueprint\n- Required volumes (config, dispatches) use paths from InstantiationConfig\n- Optional volumes (data) included only if data_path provided\n- Environment variables: merge required (from config), optional (with defaults), and custom (from config.env)\n- Resources section uses Compose v3 format: `deploy.resources.limits/reservations`\n- Healthcheck uses `test: [\"CMD\", ...]` format per Compose spec\n- Always set `restart: unless-stopped`\n- Use yaml.safe_dump with default_flow_style=False for readable output\n\n**Tests:**\n- `tests/test_generator.py` - new:\n  - ComposeGenerator initializes with BlueprintLoader\n  - generate() produces valid compose structure\n  - Port mappings respect config overrides\n  - Required volumes are always included\n  - Optional data volume included only when data_path provided\n  - Environment variables merge correctly (required, optional defaults, custom)\n  - Resources section included when blueprint defines limits\n  - Healthcheck section included when blueprint defines check\n  - Restart policy always set to unless-stopped\n  - GeneratedDeployment contains correct compose_path and compose_content\n\n**Risks:** None - straightforward dict building and YAML serialization. All types already defined.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T00:33:51Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-23T14:01:47Z","labels":["phase:qa"],"dependencies":[{"issue_id":"xc-z5e.13","depends_on_id":"xc-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-z5e.13","depends_on_id":"xc-z5e.12","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"comments":[{"id":50,"issue_id":"xc-z5e.13","author":"jv","text":"## QA Results\n\n**Status:** Pass\n\n**Verified:**\n- [x] All tests pass (23/23 generator tests, 111/117 total with 6 unrelated skips)\n- [x] Test coverage adequate - covers ports, volumes, env vars, resources, healthcheck\n- [x] Functionality works as expected - generates valid compose files\n- [x] Code is clean and well-factored\n- [x] Follows project patterns\n\n**Implementation Review:**\n- ComposeGenerator class with generate() method\n- Proper validation of config, port names, required env vars\n- Correct handling of optional vs required volumes\n- Environment variable merge precedence (optional defaults -\u003e required -\u003e config)\n- PROJECTION_ID always set from config.projection_id\n- Resource limits include both deploy section and legacy cpus/mem_limit\n- Healthcheck uses CMD-SHELL format\n\n**Issues found:** None\n\n**Recommendation:** Ready to complete","created_at":"2025-12-23T01:01:23Z"}],"work_type":"mutex"}
{"id":"xc-z5e.14","title":"Create chat blueprint definition","description":"blueprint.yaml, compose.template, config.schema.json","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T00:33:51Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-23T14:16:57Z","labels":["phase:qa"],"dependencies":[{"issue_id":"xc-z5e.14","depends_on_id":"xc-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-z5e.14","depends_on_id":"xc-z5e.13","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"comments":[{"id":51,"issue_id":"xc-z5e.14","author":"jv","text":"## QA Results\n\n**Status:** Pass\n\n**Verified:**\n- [x] All tests pass (20/20 chat blueprint tests, 131/131 full suite)\n- [x] Test coverage adequate - tests cover loading, ports, volumes, env vars, secrets, resources, healthcheck, and config validation\n- [x] Functionality works as expected - blueprint loads correctly via BlueprintLoader\n- [x] Code is well-factored - clean YAML structure, proper JSON schema for validation\n- [x] Follows project patterns - matches existing blueprint structure in tests/fixtures\n\n**Issues found:** None\n\n**Implementation verified:**\n- /blueprints/chat/blueprint.yaml - Production chat blueprint with all required fields\n- /blueprints/chat/config.schema.json - JSON Schema for config validation\n\n**Recommendation:** Ready to complete","created_at":"2025-12-23T01:16:38Z"}],"work_type":"mutex"}
{"id":"xc-z5e.15","title":"Scaffold projection-cli package structure","description":"Python/Click, pyproject.toml","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T00:33:52Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-23T14:31:49Z","labels":["phase:qa"],"dependencies":[{"issue_id":"xc-z5e.15","depends_on_id":"xc-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"comments":[{"id":52,"issue_id":"xc-z5e.15","author":"jv","text":"## QA Results\n\n**Status:** Pass\n\n**Verified:**\n- [x] All tests pass (7/7)\n- [x] Test coverage adequate for scaffold\n- [x] Functionality works (all 4 stub commands)\n- [x] Code is clean and well-factored\n- [x] Follows project patterns\n\n**Package Structure:**\n- pyproject.toml with hatchling, click, pyyaml, httpx\n- src/projection_cli/ with main.py, config.py, llm.py, __init__.py, py.typed\n- 4 stub commands: health, dispatch, instruction, run\n- conftest.py with cli_runner fixture\n\n**Issues found:** None\n\n**Recommendation:** Ready to complete","created_at":"2025-12-23T01:23:35Z"}],"work_type":"mutex"}
{"id":"xc-z5e.16","title":"Implement config loader","description":"projection.yaml, prompts.yaml, tools.yaml","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T11:33:53Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-23T01:44:04Z","dependencies":[{"issue_id":"xc-z5e.16","depends_on_id":"xc-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-z5e.16","depends_on_id":"xc-z5e.15","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-z5e.17","title":"Implement LLM client abstraction","description":"provider-agnostic with Anthropic impl","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T11:33:53Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-23T02:12:44Z","dependencies":[{"issue_id":"xc-z5e.17","depends_on_id":"xc-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-z5e.17","depends_on_id":"xc-z5e.16","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-z5e.18","title":"Implement projection health command","description":"status, uptime, config validation","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T11:33:53Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-23T03:50:30Z","dependencies":[{"issue_id":"xc-z5e.18","depends_on_id":"xc-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-z5e.18","depends_on_id":"xc-z5e.16","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-z5e.19","title":"Implement projection dispatch command","description":"Generate LLM-written summary, sign with Ed25519 key, write to /var/xenon/dispatches/*.json","design":"## Plan for z5e.19: Implement projection dispatch command\n\n**Approach:**\nGenerate LLM content (stub returns 'hello world'), sign with Ed25519, write JSON to dispatches directory.\n\n**Files:**\n- src/projection_cli/dispatch.py - new module\n- src/projection_cli/main.py - update dispatch command\n- tests/test_dispatch.py - tests\n\n**Dispatch dataclass:**\n- content: str (LLM output)\n- projection_id: str (from config)\n- signature: str (base64)\n- timestamp: int (unix epoch UTC)\n\n**What is signed (per Codex):**\nSign canonical format: b'{projection_id}\\n{timestamp}\\n{content}'\nThis binds all fields to prevent replay/cross-projection attacks.\n\n**JSON output:**\n{\n  \"content\": \"hello world\",\n  \"projection_id\": \"test-projection\",\n  \"signature\": \"base64...\",\n  \"timestamp\": 1705312200\n}\n\n**Filename:** YYYY-MM-DDTHH-MM-SSZ.json (UTC, dashes for colons)\n\n**Implementation details (per Codex):**\n- Injectable timestamp parameter for deterministic tests\n- Atomic write (temp file + rename)\n- Ensure output_dir exists (create with parents)\n- --dry-run still generates signature but doesn't write\n\n**Tests (9):**\n1. generate_dispatch returns correct fields\n2. Uses LLM stub content ('hello world')\n3. Signs canonical payload correctly (verifiable)\n4. Uses projection_id from config\n5. write_dispatch creates correct filename\n6. write_dispatch writes valid JSON (atomic)\n7. CLI --dry-run prints JSON without writing\n8. CLI writes file and prints path\n9. Signature verification fails if any field changes","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T00:33:53Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-23T17:42:56Z","labels":["phase:complete","phase:execution","phase:planning"],"dependencies":[{"issue_id":"xc-z5e.19","depends_on_id":"xc-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-z5e.19","depends_on_id":"xc-z5e.17","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-z5e.19","depends_on_id":"xc-z5e.27","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"comments":[{"id":53,"issue_id":"xc-z5e.19","author":"jv","text":"## QA Results\n\n✅ All 14 dispatch tests pass\n✅ All 94 project tests pass\n✅ Codex review approved\n\n**Features verified:**\n- Canonical payload signing: {projection_id}\\n{timestamp}\\n{content}\n- UTC timestamp filename format\n- Atomic write (temp file + rename)\n- Injectable timestamp for deterministic tests\n- --dry-run generates signature without writing\n- CLI writes file and prints path\n\n**Codex notes (not blockers):**\n- Suggested Path.replace() over rename() - current code works for new files\n- Suggested fsync for crash-safety - not critical for this use case\n- All imports and final_path are correctly defined in actual code","created_at":"2025-12-23T04:34:00Z"}],"work_type":"mutex"}
{"id":"xc-z5e.2","title":"Add SSH and firewall hardening to dev-vps","description":"key-only auth, custom port, nftables","notes":"Added nftables.conf with default-deny policy. Updated Containerfile: SSH on port 2222, nftables loaded at startup. Tests pass.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T11:33:34Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-22T12:10:59Z","labels":["phase:qa"],"dependencies":[{"issue_id":"xc-z5e.2","depends_on_id":"xc-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-z5e.2","depends_on_id":"xc-z5e.1","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-z5e.20","title":"Implement projection instruction command","description":"process cortex JSON instructions","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T11:33:54Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-23T03:56:26Z","dependencies":[{"issue_id":"xc-z5e.20","depends_on_id":"xc-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-z5e.20","depends_on_id":"xc-z5e.17","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-z5e.21","title":"Implement projection run command","description":"main loop with APScheduler","design":"## Plan for z5e.21: Implement projection run command\n\n**Approach:**\nSimple time.sleep loop (no APScheduler - avoid extra deps). Create runtime.py module with testable RuntimeLoop class.\n\n**Files:**\n- src/projection_cli/runtime.py - new module\n- src/projection_cli/main.py - update run command\n- tests/test_runtime.py - tests\n\n**RuntimeLoop class:**\n```python\nclass RuntimeLoop:\n    def __init__(self, config_dir, output_dir, sleep_fn=time.sleep)\n    def start(self, once: bool = False) -\u003e int  # returns exit code\n    def stop(self) -\u003e None\n    def handle_signal(self, signum: int) -\u003e None  # testable\n```\n\n**Testability (per Codex):**\n- Inject sleep_fn parameter for fast tests\n- handle_signal() method called by signal handlers - tests call directly\n- Inject dispatch generator/writer for unit tests\n\n**Signal handling:**\n- SIGTERM/SIGINT: handle_signal sets _running=False\n- Tests call handle_signal() directly (no OS signals)\n\n**--once mode (per Codex):**\n- Run single dispatch cycle\n- Exit 0 on success, exit 1 on failure\n- Useful for cron\n\n**Error handling:**\n- Config errors: exit 1 before loop\n- Frequency \u003c= 0: config error (exit 1)\n- Dispatch errors in loop: log warning, continue\n- Dispatch error in --once: exit 1\n\n**Tests (8):**\n1. start() with injected sleep generates dispatch\n2. stop() causes loop to exit\n3. --once success returns 0\n4. --once failure returns 1\n5. handle_signal(SIGTERM) stops loop\n6. Config errors return 1 before loop\n7. Invalid frequency (\u003c=0) returns 1\n8. Dispatch errors don't crash loop","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T00:34:04Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-23T20:46:13Z","labels":["phase:complete","phase:execution","phase:planning"],"dependencies":[{"issue_id":"xc-z5e.21","depends_on_id":"xc-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-z5e.21","depends_on_id":"xc-z5e.18","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-z5e.21","depends_on_id":"xc-z5e.19","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-z5e.21","depends_on_id":"xc-z5e.20","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"comments":[{"id":54,"issue_id":"xc-z5e.21","author":"jv","text":"## QA Results\n\n✅ All 9 runtime tests pass\n✅ All 103 project tests pass\n✅ Codex review - found and fixed bug\n\n**Bug fixed per Codex:**\n- handle_signal() signature fixed to include frame parameter (required by signal.signal)\n\n**Features verified:**\n- Injectable sleep_fn for fast tests\n- --once mode returns 0/1 exit codes\n- Frequency validation (\u003c=0 rejected)\n- Signal handling via handle_signal()\n- Dispatch errors don't crash loop\n\n**Codex notes (not blockers):**\n- Sleep may not interrupt immediately on signal (acceptable for MVP)\n- Config loaded once (hot reload deferred to future)","created_at":"2025-12-23T04:55:10Z"}],"work_type":"mutex"}
{"id":"xc-z5e.22","title":"Create projection-base Containerfile","description":"Rocky Linux 9, SSH, projection CLI, systemd","design":"## Plan for z5e.22: Create projection-base Containerfile\n\n**Approach:**\nCreate a base container image using Rocky Linux 9 with systemd as PID 1. The image includes SSH (key-only auth), Python 3.11, and projection-cli in a venv.\n\n**Files:**\n- `containers/projection-base/Containerfile` - Main container definition\n- `containers/projection-base/sshd_config.d/xenon.conf` - SSH hardening config\n- `containers/projection-base/configs/projection.yaml` - Default projection config\n- `containers/projection-base/configs/prompts.yaml` - Default prompts config\n- `containers/projection-base/README.md` - Build/usage documentation\n\n**Key implementation details:**\n\n1. **Base and systemd:**\n   - Base: `rockylinux:9`\n   - Install: systemd\n   - ENV container=podman\n   - STOPSIGNAL SIGRTMIN+3\n   - CMD [\"/sbin/init\"]\n\n2. **Python 3.11:**\n   - Enable module: `dnf module enable python3.11:3.11`\n   - Install: python3.11, python3.11-pip\n   - Create venv at `/opt/projection-cli/venv`\n\n3. **SSH daemon:**\n   - Install openssh-server\n   - Enable via symlink: `ln -s /usr/lib/systemd/system/sshd.service /etc/systemd/system/multi-user.target.wants/`\n   - Host keys: Generate on first boot via oneshot unit OR document volume mount\n   - Drop-in config `/etc/ssh/sshd_config.d/xenon.conf`:\n     - PermitRootLogin no\n     - PasswordAuthentication no\n     - KbdInteractiveAuthentication no\n     - AllowUsers xenon\n     - PermitEmptyPasswords no\n     - X11Forwarding no\n     - AllowTcpForwarding no\n\n4. **xenon user:**\n   - UID 1000, home /home/xenon\n   - .ssh directory mode 700\n   - Authorized keys injected at runtime via volume\n\n5. **Directory structure:**\n   - `/var/xenon/{config,dispatches,data,logs}` owned by xenon:xenon\n\n6. **projection-cli:**\n   - COPY source to /opt/projection-cli/src\n   - Create venv, pip install\n   - Symlink /usr/local/bin/projection -\u003e venv/bin/projection\n\n7. **Default configs:**\n   - Copy YAML templates to /var/xenon/config/\n   - Use env vars in projection.yaml (PROJECTION_ID, LLM_PROVIDER, etc.)\n\n8. **Health check:**\n   - HEALTHCHECK CMD [\"projection\", \"health\", \"--config-dir\", \"/var/xenon/config\", \"--json\"]\n\n9. **Port:** EXPOSE 22\n\n**README documents:**\n- Required runtime flags: `--cap-add SYS_ADMIN --cgroupns=host -v /sys/fs/cgroup:/sys/fs/cgroup:ro`\n- Volume mounts for SSH keys, config, data\n- Environment variables\n\n**Tests:**\n- Image builds\n- SSH works with xenon user (password rejected)\n- projection commands work\n- Correct directory ownership","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T11:34:04Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-23T08:16:39Z","dependencies":[{"issue_id":"xc-z5e.22","depends_on_id":"xc-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-z5e.22","depends_on_id":"xc-z5e.21","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-z5e.22","depends_on_id":"xc-z5e.4","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-z5e.23","title":"Create simple Express hello world server","description":"Simple Express server returning hello world (placeholder for future chat UI)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T11:34:05Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-23T03:24:21Z","dependencies":[{"issue_id":"xc-z5e.23","depends_on_id":"xc-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-z5e.23","depends_on_id":"xc-z5e.22","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-z5e.24","title":"Implement chat event logging for dispatch","description":"metrics buffer for dispatch","design":"## Plan for z5e.24: Chat event logging for dispatch\n\n**Approach:**\nCreate EventBuffer with explicit ChatEvent schema. MockEventSource generates bounded random events. In-memory only, cleared after dispatch.\n\n**Files:**\n- `src/projection_cli/events.py` - ChatEvent dataclass, EventBuffer, MockEventSource\n- `src/projection_cli/dispatch.py` - accept optional event_buffer\n- `tests/test_events.py` - tests\n\n**Implementation:**\n\n1. **ChatEvent dataclass:**\n   - type: str (message, reaction, join, leave)\n   - timestamp: int\n   - actor_id: str\n   - channel_id: str\n   - text: str | None (for messages)\n   - emoji: str | None (for reactions)\n\n2. **EventBuffer class:**\n   - max_events: int = 1000 (ring buffer behavior)\n   - add_event(event: ChatEvent)\n   - get_summary() -\u003e dict with counts by type, period, sample messages\n   - clear()\n   - Single-threaded design (no locks)\n\n3. **MockEventSource class:**\n   - Seedable random.Random instance\n   - Fixed actor pool: [\"user-1\", \"user-2\", \"user-3\"]\n   - Fixed channel: \"general\"\n   - Bounded text: max 100 chars from word list\n   - generate_events(count: int) -\u003e list[ChatEvent]\n\n4. **Dispatch integration:**\n   - generate_dispatch() accepts optional event_buffer\n   - If provided, summary appended to dispatch content\n   - Buffer cleared after successful dispatch\n\n**Tests:**\n- ChatEvent creation and fields\n- EventBuffer max size, summary, clear\n- MockEventSource seeded determinism\n- Dispatch with/without buffer","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T11:34:05Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-23T08:38:44Z","labels":["phase:planning"],"dependencies":[{"issue_id":"xc-z5e.24","depends_on_id":"xc-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-z5e.24","depends_on_id":"xc-z5e.23","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-z5e.25","title":"Create chat projection Containerfile and entrypoint","description":"extends base, Node.js, entrypoint.sh","design":"## Plan for z5e.25: Chat projection Containerfile\n\n**Approach:**\nExtend projection-base with Node.js and chat-server. Use systemd services for both projection run and Express server. Run as xenon user.\n\n**Files:**\n- `containers/chat-projection/Containerfile`\n- `containers/chat-projection/chat-server.service` - systemd unit\n- `containers/chat-projection/projection.service` - systemd unit\n- `containers/chat-projection/README.md`\n\n**Containerfile:**\n```dockerfile\nFROM projection-base\n\n# Install Node.js 20\nRUN dnf module enable nodejs:20 -y \u0026\u0026 \\\n    dnf install -y nodejs npm \u0026\u0026 \\\n    dnf clean all\n\n# Copy and install chat-server\nCOPY packages/chat-server /opt/chat-server\nWORKDIR /opt/chat-server\nRUN npm ci --omit=dev \u0026\u0026 \\\n    chown -R xenon:xenon /opt/chat-server\n\n# Copy systemd units\nCOPY containers/chat-projection/chat-server.service /etc/systemd/system/\nCOPY containers/chat-projection/projection.service /etc/systemd/system/\n\n# Enable services\nRUN ln -sf /etc/systemd/system/chat-server.service /etc/systemd/system/multi-user.target.wants/ \u0026\u0026 \\\n    ln -sf /etc/systemd/system/projection.service /etc/systemd/system/multi-user.target.wants/\n\nEXPOSE 22 3000\n\n# Health check\nHEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \\\n    CMD curl -sf http://localhost:3000/health || exit 1\n```\n\n**chat-server.service:**\n- User=xenon\n- WorkingDirectory=/opt/chat-server\n- ExecStart=/usr/bin/node server.js\n- Environment=NODE_ENV=production PORT=3000\n- Restart=on-failure\n- After=network-online.target\n\n**projection.service:**\n- User=xenon\n- ExecStart=/usr/local/bin/projection run --config-dir /var/xenon/config --output-dir /var/xenon/dispatches\n- Restart=on-failure\n- After=network-online.target\n\n**Tests:**\n- Image builds\n- Both services start\n- SSH on 22, Express on 3000\n- /health endpoint responds","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T11:34:05Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-23T08:46:52Z","labels":["phase:planning"],"dependencies":[{"issue_id":"xc-z5e.25","depends_on_id":"xc-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-z5e.25","depends_on_id":"xc-z5e.22","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-z5e.25","depends_on_id":"xc-z5e.24","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-z5e.26","title":"Create end-to-end integration test","description":"vps-control → deploy → instruction → dispatch","design":"## Plan for z5e.26: End-to-End Integration Test\n\n**Approach:**\nCreate spec-driven integration test suite that validates each requirement from the chat-projection proposal. Tests require dev-vps running (gated by `DEV_VPS=1`). Tests build and deploy containers, then validate the full flow.\n\n**File:**\n- `packages/vps-control/tests/test_integration.py` - E2E integration tests\n\n**Test Categories (mapped to spec sections):**\n\n### 1. SSH/SCP Control Flow (spec lines 47-66)\n```python\nasync def test_ssh_exec_control_flow():\n    # Validates: \"Commands flow down only\"\n    # SSH → dev-vps → podman exec → projection command\n\nasync def test_scp_data_flow():\n    # Validates: \"Files flow up only\"\n    # Create file in container → SCP download\n```\n\n### 2. Dispatch Structure (spec lines 106-165)\n```python\nasync def test_dispatch_json_schema():\n    # Validates dispatch envelope: dispatch, projection_id, signature, timestamp\n    \nasync def test_dispatch_frontmatter():\n    # Validates: id, projection, timestamp, period, health in YAML frontmatter\n```\n\n### 3. Cryptographic Signing (spec lines 588-675)\n```python\nasync def test_keypair_deployment():\n    # Validates: Private key at /var/xenon/config/signing.key, chmod 600\n\nasync def test_dispatch_signature_verification():\n    # Validates: Domain prefix, canonical format, signature verifies\n```\n\n### 4. Directory Convention (spec lines 551-562)\n```python\nasync def test_directory_structure():\n    # Validates: /var/xenon/{dispatches,config,data,logs} exist\n```\n\n### 5. Projection CLI Commands (spec lines 257-270)\n```python\nasync def test_projection_health():\n    # Validates: projection health returns JSON with status\n\nasync def test_projection_dispatch():\n    # Validates: projection dispatch creates file in /var/xenon/dispatches/\n\nasync def test_projection_instruction():\n    # Validates: projection instruction processes JSON payload\n```\n\n### 6. Container Lifecycle (spec lines 327-351)\n```python\nasync def test_projection_base_structure():\n    # Validates: SSH, directories, projection CLI installed\n\nasync def test_chat_projection_services():\n    # Validates: systemd services run, health endpoints respond\n```\n\n**Fixtures:**\n```python\n@pytest.fixture(scope=\"module\")\nasync def dev_vps():\n    \"\"\"Connect to dev-vps, build images if needed.\"\"\"\n    \n@pytest.fixture\nasync def projection_container(dev_vps):\n    \"\"\"Start chat-projection container with config.\"\"\"\n    \n@pytest.fixture\ndef keypair():\n    \"\"\"Generate keypair for testing.\"\"\"\n```\n\n**Test Dependencies:**\n- dev-vps container running on localhost:2222\n- SSH key at ~/.ssh/xenon-dev\n- Container images built (test builds if missing)\n\n**Run with:**\n```bash\nDEV_VPS=1 uv run pytest tests/test_integration.py -v\n```\n\n**Risks:**\n- Container build time may make tests slow - add --skip-build option\n- Nested container complexity - test isolation important","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T11:34:06Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-23T09:33:04Z","dependencies":[{"issue_id":"xc-z5e.26","depends_on_id":"xc-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-z5e.26","depends_on_id":"xc-z5e.14","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-z5e.26","depends_on_id":"xc-z5e.25","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-z5e.26","depends_on_id":"xc-z5e.28","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-z5e.26","depends_on_id":"xc-z5e.8","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-z5e.27","title":"Implement Ed25519 signing utilities","description":"Crypto utilities for signing dispatches with Ed25519 keys. Load key from secrets.json, sign content, output base64 signature.","design":"## Plan for z5e.27: Ed25519 Signing Utilities\n\n**Approach:**\nCreate signing.py module with Ed25519 signing utilities using cryptography library.\n\n**Files:**\n- src/projection_cli/signing.py - new module\n- pyproject.toml - add cryptography\u003e=42.0\n- tests/test_signing.py - tests\n- tests/fixtures/config/signing.key - test key (static PEM, test-only)\n\n**API:**\n- SigningError exception\n- load_signing_key(key_path: str) -\u003e Ed25519PrivateKey\n- sign_content(content: bytes, key: Ed25519PrivateKey) -\u003e str (base64)\n- verify_signature(content: bytes, signature: str, public_key: Ed25519PublicKey) -\u003e bool\n\n**Security (per Codex review):**\n- Domain separation: prefix content with b'projection-cli:v1\\n' before signing\n- Use bytes for content, not str (caller handles encoding)\n- Base64 strict decoding with validate=True, check 64-byte length\n- Reject encrypted PEM with clear SigningError\n- No key material in exception messages\n- Check file permissions on Unix (warn if group/world-readable)\n\n**Tests (10 tests):**\n1. Load valid Ed25519 key from PEM\n2. Load raises SigningError for missing file\n3. Load raises SigningError for invalid PEM\n4. Load raises SigningError for non-Ed25519 key (RSA)\n5. Load raises SigningError for encrypted PEM\n6. Sign produces valid base64 string\n7. Verify returns True for valid signature\n8. Verify returns False for tampered content\n9. Verify returns False for wrong key\n10. Verify returns False for invalid base64/wrong length","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T10:00:57Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-23T17:25:07Z","labels":["phase:complete"],"dependencies":[{"issue_id":"xc-z5e.27","depends_on_id":"xc-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"comments":[{"id":55,"issue_id":"xc-z5e.27","author":"jv","text":"## QA Results\n\n✅ All 14 signing tests pass\n✅ All 80 project tests pass  \n✅ Codex review approved\n\n**Security features verified:**\n- Domain separation prefix (b'projection-cli:v1\\n')\n- Strict base64 decoding with validate=True\n- 64-byte signature length check\n- Encrypted PEM rejection with clear error\n- File permission check (mode \u0026 0o077) with stderr warning\n- No key material in exception messages\n\n**Minor improvements applied per Codex:**\n- Changed permission check from read-only to any group/other access\n- Moved warning to stderr to avoid corrupting JSON output","created_at":"2025-12-23T04:18:14Z"}],"work_type":"mutex"}
{"id":"xc-z5e.28","title":"Implement keypair generation for projection instantiation","description":"Generate Ed25519 keypair when cortex creates projection. Deploy private key in secrets.json, register public key with nucleus.","design":"## Plan for xenon-host-z5e.28: Implement keypair generation for projection instantiation\n\n**Approach:**\nCreate a KeyPairManager class in vps-control that handles Ed25519 keypair generation, serialization, and deployment to projections. Uses the cryptography library (already available as transitive dependency via paramiko). Private keys serialized in PEM format (OpenSSH), public keys in OpenSSH format for nucleus registry. Deploy method uses Target.upload() to SFTP the key file, then chmod 600.\n\n**Files:**\n- `packages/vps-control/src/vps_control/keypair.py` - new module with KeyPairManager\n- `packages/vps-control/src/vps_control/__init__.py` - export KeyPairManager and KeyPair\n- `packages/vps-control/pyproject.toml` - add cryptography\u003e=42.0 as explicit dependency\n- `packages/vps-control/tests/test_keypair.py` - unit tests\n\n**API Design:**\n\n```python\nfrom dataclasses import dataclass\nfrom cryptography.hazmat.primitives.asymmetric.ed25519 import (\n    Ed25519PrivateKey,\n    Ed25519PublicKey,\n)\n\n@dataclass\nclass KeyPair:\n    \"\"\"Ed25519 keypair for projection signing.\"\"\"\n    private_key: Ed25519PrivateKey\n    public_key: Ed25519PublicKey\n\n    def private_pem(self) -\u003e bytes:\n        \"\"\"Serialize private key to PEM format (OpenSSH).\"\"\"\n        ...\n\n    def public_openssh(self) -\u003e str:\n        \"\"\"Serialize public key to OpenSSH format (ssh-ed25519 AAAA...).\"\"\"\n        ...\n\nclass KeyPairManager:\n    \"\"\"Generate and deploy Ed25519 keypairs for projections.\"\"\"\n\n    def generate(self) -\u003e KeyPair:\n        \"\"\"Generate new Ed25519 keypair.\"\"\"\n        ...\n\n    async def deploy_to_projection(\n        self,\n        target: Target,\n        keypair: KeyPair,\n        remote_path: str = \"/var/xenon/config/signing.key\",\n    ) -\u003e None:\n        \"\"\"Deploy private key to projection via SFTP.\"\"\"\n        ...\n```\n\n**Tests:**\n1. generate() returns KeyPair with valid keys\n2. private_pem() produces valid PEM bytes (parseable by load_signing_key)\n3. public_openssh() produces valid ssh-ed25519 format\n4. deploy_to_projection uploads to correct path\n5. deploy_to_projection sets chmod 600\n6. deploy_to_projection cleans up temp file on success/failure\n7. Round-trip: generate -\u003e serialize -\u003e load matches original","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T21:01:11Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-23T09:22:03Z","labels":["phase:planning"],"dependencies":[{"issue_id":"xc-z5e.28","depends_on_id":"xc-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-z5e.28","depends_on_id":"xc-z5e.13","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-z5e.3","title":"Create dev-vps compose file with port forwarding","description":"SSH 2222, web 3000","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T11:33:34Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-22T12:18:03Z","labels":["phase:execution"],"dependencies":[{"issue_id":"xc-z5e.3","depends_on_id":"xc-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-z5e.3","depends_on_id":"xc-z5e.2","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-z5e.4","title":"Test and document dev-vps SSH and nested Podman","description":"integration test script","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T11:33:34Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-22T12:22:37Z","labels":["phase:execution"],"dependencies":[{"issue_id":"xc-z5e.4","depends_on_id":"xc-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-z5e.4","depends_on_id":"xc-z5e.3","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-z5e.5","title":"Scaffold vps-control package structure","description":"TypeScript, src directories","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T11:33:35Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-22T12:29:34Z","labels":["phase:execution"],"dependencies":[{"issue_id":"xc-z5e.5","depends_on_id":"xc-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-z5e.6","title":"Implement SSH connection manager","description":"Target class with connect/exec/close","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T11:33:35Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-22T12:46:00Z","labels":["phase:execution"],"dependencies":[{"issue_id":"xc-z5e.6","depends_on_id":"xc-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-z5e.6","depends_on_id":"xc-z5e.5","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-z5e.7","title":"Implement SCP file transfer","description":"scpTo/scpFrom methods","design":"## Plan for xenon-host-z5e.7: Implement SCP file transfer\n\n**Approach:**\nUse paramiko's SFTPClient via self._client.open_sftp(). Document that 'scp' methods are implemented via SFTP protocol. Use asyncio.to_thread() to avoid blocking the event loop.\n\n**Improvements from Codex review:**\n1. Use asyncio.to_thread() for non-blocking async\n2. Check transport.is_active() for connection state\n3. Proper resource handling with try/finally sftp.close()\n4. Map IOError to FileNotFoundError for missing remote files\n5. Keep scp_ naming but document SFTP implementation\n\n**Files:**\n- target.py - Implement scp_to/scp_from with SFTP + asyncio.to_thread\n- test_target.py - Unit tests (mock open_sftp) + integration tests (DEV_VPS)\n\n**Tests:**\n- Unit: scp_to raises FileNotFoundError when local file missing\n- Unit: scp_from raises RuntimeError when not connected  \n- Unit: verify sftp.close() called in finally\n- Integration: upload, verify with cat\n- Integration: download, verify content\n- Integration: round-trip test","notes":"Implementation completed successfully.\n\n**Changes made:**\n\n1. **File: /Users/jv/workspace/xenota/xenon-host/packages/vps-control/src/vps_control/target.py**\n   - Added asyncio import\n   - Replaced scp_to() stub with upload() method\n   - Replaced scp_from() stub with download() method\n   - Both methods use asyncio.to_thread() to wrap blocking paramiko SFTP calls\n   - Connection validation using self._client.get_transport().is_active()\n   - Proper try/finally blocks ensure sftp.close() is always called\n   - Upload checks local file exists before attempting transfer\n   - Download maps IOError to FileNotFoundError for missing remote files\n   - Added comprehensive docstrings noting \"Implemented via SFTP protocol\"\n\n2. **File: /Users/jv/workspace/xenota/xenon-host/packages/vps-control/tests/test_target.py**\n   - Added imports: tempfile, Path, MagicMock, patch\n   - Added 5 unit tests:\n     - test_upload_missing_local_file - Verifies FileNotFoundError when local file missing\n     - test_download_not_connected - Verifies RuntimeError when not connected\n     - test_upload_not_connected - Verifies RuntimeError when not connected\n     - test_upload_sftp_closes - Verifies SFTP client closure with mocks\n     - test_download_sftp_closes - Verifies SFTP client closure with mocks\n   - Added 3 integration tests (require DEV_VPS=1):\n     - test_upload_and_verify - Upload file and verify with exec(\"cat ...\")\n     - test_download_and_verify - Download file and verify content matches\n     - test_upload_download_roundtrip - Round-trip upload then download\n\n**Test results:**\n- All 7 unit tests PASS\n- 6 integration tests SKIPPED (DEV_VPS not set, expected)\n- No test failures\n\n**Code quality:**\n- Clean, readable implementation\n- Follows existing codebase patterns\n- Proper error handling with meaningful messages\n- SFTP resources properly cleaned up in finally blocks\n- Async operations properly wrapped with asyncio.to_thread()\n- Comprehensive test coverage for all error cases and happy paths\n\nReady for integration testing when DEV_VPS is available.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T00:33:35Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-23T11:50:56Z","labels":["phase:qa"],"dependencies":[{"issue_id":"xc-z5e.7","depends_on_id":"xc-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-z5e.7","depends_on_id":"xc-z5e.6","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"comments":[{"id":56,"issue_id":"xc-z5e.7","author":"jv","text":"## QA Results\n\n**Status:** Pass (with fixes)\n\n**Verified:**\n- [x] All tests pass (21 passed, 6 skipped - integration tests require DEV_VPS)\n- [x] Test coverage adequate - unit tests for all error cases, integration tests for happy paths\n- [x] Functionality correctly implements plan:\n  - Uses asyncio.to_thread() for non-blocking async\n  - Checks transport.is_active() for connection state\n  - SFTP closed in finally block\n  - IOError mapped to FileNotFoundError for missing remote files\n- [x] Code is well-factored, follows project patterns\n- [x] Docstrings mention SFTP implementation\n- [x] Black and flake8 pass\n\n**Issues found and fixed:**\n- Line too long (91 \u003e 88 chars) in target.py:126 - wrapped exception message\n- Unused import 'patch' in test_target.py - removed\n\n**Test summary:**\n- test_upload_missing_local_file: PASS\n- test_download_not_connected: PASS\n- test_upload_not_connected: PASS\n- test_upload_sftp_closes: PASS\n- test_download_sftp_closes: PASS\n- Integration tests: SKIPPED (DEV_VPS not set, expected)\n\n**Recommendation:** Ready to complete","created_at":"2025-12-22T22:37:47Z"}],"work_type":"mutex"}
{"id":"xc-z5e.8","title":"Implement Podman container control via SSH","description":"start/stop/exec/logs","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T00:33:35Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-23T12:45:38Z","labels":["phase:qa"],"dependencies":[{"issue_id":"xc-z5e.8","depends_on_id":"xc-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-z5e.8","depends_on_id":"xc-z5e.6","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"comments":[{"id":57,"issue_id":"xc-z5e.8","author":"jv","text":"## QA Results\n\n**Status:** Pass\n\n**Verified:**\n- [x] All tests pass (6 podman tests, 21 total)\n- [x] Test coverage adequate - all 5 methods tested\n- [x] Functionality matches spec (start/stop/exec/logs)\n- [x] Code is clean and well-factored\n- [x] Follows project patterns (async, Target delegation)\n- [x] Module properly exported in __init__.py\n\n**Issues found:** None\n\n**Notes:**\n- ps() included as bonus (common utility)\n- logs() has customizable tail parameter\n- All methods properly delegate to Target.exec()\n- Good mock-based testing strategy\n\n**Recommendation:** Ready to complete","created_at":"2025-12-22T23:51:53Z"}],"work_type":"mutex"}
{"id":"xc-z5e.9","title":"Implement security audit tools","description":"checkAuthorizedKeys, checkLoginHistory, etc.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T00:33:35Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-23T13:00:45Z","labels":["phase:qa"],"dependencies":[{"issue_id":"xc-z5e.9","depends_on_id":"xc-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-z5e.9","depends_on_id":"xc-z5e.6","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"comments":[{"id":58,"issue_id":"xc-z5e.9","author":"jv","text":"## QA Results\n\n**Status:** PASS\n\n**Verified:**\n- [x] All tests pass (8/8)\n- [x] Test coverage adequate (all methods tested)\n- [x] Functionality matches spec (checkAuthorizedKeys, checkLoginHistory, etc.)\n- [x] Code is well-factored (32 lines, clean async methods)\n- [x] Follows project patterns (uses Target abstraction)\n- [x] Module exports correctly (AuditTools in __all__)\n\n**Methods Implemented:**\n- check_authorized_keys() -\u003e list[str]\n- check_login_history(lines=50) -\u003e str\n- check_listening_ports() -\u003e str\n- check_processes() -\u003e str\n- check_file_integrity(path) -\u003e str\n\n**Test Coverage:**\n- test_check_authorized_keys - normal case\n- test_check_authorized_keys_empty - edge case (empty file)\n- test_check_login_history - default lines\n- test_check_login_history_custom_lines - custom lines param\n- test_check_listening_ports - network ports\n- test_check_processes - process listing\n- test_check_file_integrity - single file\n- test_check_file_integrity_multiple_files - glob pattern\n\n**Issues found:** None\n\n**Recommendation:** Ready to complete","created_at":"2025-12-23T00:00:24Z"}],"work_type":"mutex"}
{"id":"xc-za69","title":"Digest: mol-witness-patrol","description":"Patrol 3-6: Polecat obsidian session stopped with 2 unpushed commits on branch polecat/obsidian/xc-x3ab. Clean tree but never pushed. Agent state stuck at spawning. Escalated IDLE_DIRTY to Mayor for recovery.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-07T11:11:34Z","updated_at":"2026-02-07T11:11:34Z","closed_at":"2026-02-07T11:11:34Z","work_type":"mutex"}
{"id":"xc-zegn","title":"Migrate beads to Dolt backend","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-07T09:20:44Z","updated_at":"2026-02-07T09:20:44Z","work_type":"mutex"}
{"id":"xc-zjt","title":"MVP Awakening Flow","description":"dispatched_by: xenota/crew/starshot\n\nFirst working prototype - human runs xenon-host locally, goes through CLI awakening, ends with functioning xenon that can converse via LiteLLM.","status":"hooked","priority":1,"issue_type":"epic","assignee":"xenota/crew/starshot","created_at":"2025-12-20T11:21:15Z","updated_at":"2026-02-07T21:46:00Z","work_type":"mutex"}
{"id":"xc-zjt.1","title":"save_config leaks XENON_ID env override into YAML file","description":"attached_molecule: xc-wisp-ca5\nattached_at: 2026-02-09T10:45:10Z\ndispatched_by: xenota/crew/starshot\n\nload_config correctly applies XENON_ID env var as authoritative override for infrastructure_id, but save_config writes the overridden value to disk via to_dict(). Design says env var should not be written back on save. Fix: save_config should exclude infrastructure_id when it came from env, or save a copy with the field cleared/restored to file-original value.","status":"closed","priority":3,"issue_type":"bug","assignee":"xenota/polecats/jasper","created_at":"2026-02-09T10:28:14Z","updated_at":"2026-02-09T13:35:19Z","closed_at":"2026-02-09T13:35:19Z","dependencies":[{"issue_id":"xc-zjt.1","depends_on_id":"xc-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-zjt.10","title":"Automated awakening test harness with persona-driven sub-agents","description":"Build a test harness that spawns LLM sub-agents as chaperones, running through the full awakening unattended with diverse personas.\n\n## Design (v3 — final)\n\n### Core Idea\nReplace interactive RichChatCallback with AutomatedChatCallback that uses an LLM as the chaperone. The orchestrator is unchanged — ChatCallback protocol is the seam.\n\n### Critical Fix: Make ChatCallback async\nThe protocol get_chaperone_input() is sync but we need async LLM calls. Thread hacks are fragile. Change the protocol:\n```python\nclass ChatCallback(Protocol):\n    async def get_chaperone_input(self) -\u003e str: ...  # was sync\n```\nUpdate RichChatCallback: `return await asyncio.to_thread(self.console.input, \"[bold]you \u003e [/bold]\")`\nUpdate MockChatCallback: just return from list (already sync-safe in async context).\nOne-line change in orchestrator: `chaperone_text = await self.callback.get_chaperone_input()`\n\n### No Scripted Mode\nThe awakening is fully non-deterministic (LLM-driven conversation). A scripted chaperone would not test real system behavior. The existing MockChatCallback in the test suite already serves unit testing with canned responses. This harness is specifically for exploratory testing with real LLM conversations across diverse personas.\n\n### AutomatedChatCallback\n\nKey fixes from codex review:\n- Context manager for file handles (close in finally)\n- Single canonical event log (not separate xenon_messages/prior_responses lists)\n- Rolling window for LLM context (last K turns + phase summary, not full history)\n- Hardened chaperone system prompt (treat xenon output as untrusted)\n- Initialize all fields, flush consistently\n- Include system messages and phase transitions in chaperone context\n\n```python\nclass AutomatedChatCallback:\n    def __init__(self, persona, client, log_dir):\n        self.persona = persona\n        self.client = client\n        self.events = []  # Single canonical log\n        self.log_file = None\n        self.current_phase = \"init\"\n\n    async def get_chaperone_input(self) -\u003e str:\n        messages = self._build_chaperone_messages()\n        response = await self.client.complete_messages(messages=messages, temperature=0.8)\n        self._record(\"chaperone\", response)\n        return response\n\n    def _build_chaperone_messages(self):\n        system = self.persona.to_system_prompt(self.current_phase)\n        system += \"\\n\\nIMPORTANT: You are role-playing a human chaperone. ...\"\n        messages = [{\"role\": \"system\", \"content\": system}]\n        recent = self.events[-10:]  # Rolling window\n        for e in recent:\n            if e[\"role\"] == \"xenon\":\n                messages.append({\"role\": \"assistant\", \"content\": e[\"content\"]})\n            elif e[\"role\"] == \"chaperone\":\n                messages.append({\"role\": \"user\", \"content\": e[\"content\"]})\n        return messages\n```\n\n### Persona Format\n```yaml\nname: nurturing-teacher\nlocation: \"Wellington, New Zealand\"\npersonality: |\n  You are a warm, nurturing teacher who loves ecology.\n  Share vivid sensory details about your homeland.\ngoals: \"Environmental education advocate\"\nstyle: \"Medium-length, emotionally warm\"\nphase_hints:\n  naming: \"Suggest names from native NZ birds\"\n  pledge: \"Speak your commitment sincerely\"\n```\n\nEdge case personas: one-word-andy (terse), multilingual-maria (language switching), contrarian-carl (adversarial), topic-changer-tom (off-topic tangents).\n\n### CLI\n```bash\n# Single run\nxenon test-awakening --persona personas/teacher.yaml --output /tmp/test-001/ \\\n  --model gemini/gemini-2.5-flash --chaperone-model sonnet --seed 42\n\n# Batch\nxenon test-awakening --batch personas/ --output /tmp/batch-001/ --parallel 3 \\\n  --model gemini/gemini-2.5-flash --chaperone-model sonnet\n```\n\n### Output\n```\nbatch-001/\n├── summary.csv               # Flat: persona,status,name,phases,turns,duration,anomalies\n├── summary.json               # Nested details\n├── nurturing-teacher/\n│   ├── persona.yaml\n│   ├── run_meta.json          # Model IDs, params, git SHA, timestamps\n│   ├── chaperone.log\n│   └── data/                  # Standard xenon data dir (journal, genome, etc.)\n├── one-word-andy/\n└── contrarian-carl/\n```\n\n### Implementation\n\nFiles to create:\n1. nucleus/src/nucleus/awakening/automated.py — AutomatedChatCallback\n2. nucleus/src/nucleus/awakening/persona.py — Persona dataclass + YAML loader\n3. xenon-cli/src/xenon_cli/test_awakening.py — CLI command + batch runner\n4. personas/*.yaml — starter persona library\n\nFiles to modify:\n1. nucleus/src/nucleus/awakening/orchestrator.py — make get_chaperone_input async (+ await in _run_phase)\n2. nucleus/src/nucleus/awakening/cli.py — update RichChatCallback with asyncio.to_thread\n3. nucleus/tests/test_awakening_orchestrator.py — update MockChatCallback to async\n4. xenon-cli/src/xenon_cli/main.py — register test-awakening command\n\n### Batch Runner\n- asyncio.TaskGroup for concurrency with cancellation propagation\n- Per-run timeout (default 10min) with clean teardown\n- Shared rate limit backpressure across parallel runs\n- summary.csv written incrementally as runs complete\n\n### Key Design Decisions\n- Async protocol (not thread hacks) — cleaner, no event loop conflicts\n- All-LLM chaperone (no scripted mode) — awakening is non-deterministic, scripting misses the point\n- Canonical event log (not separate lists) — single source of truth\n- Rolling window context (not full history) — prevents token blowout\n- Hardened system prompt — treats xenon output as untrusted\n- CSV summary — flat tabular data for quick comparison\n- run_meta.json per run — model IDs, params, git SHA for reproducibility\n- Sanitized directory names — no path traversal\n- Context manager for file handles — no leaks in batch mode\n","status":"closed","priority":1,"issue_type":"task","owner":"git@codewithjv.com","created_at":"2026-02-13T08:54:18Z","created_by":"xenota/crew/starshot","updated_at":"2026-02-13T09:25:10Z","closed_at":"2026-02-13T09:25:10Z","dependencies":[{"issue_id":"xc-zjt.10","depends_on_id":"xc-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-zjt.11","title":"Manual test: full awakening protocol via CLI backend (codex)","description":"Human-only closure. Test a complete xenon awakening flow using codex as the LLM backend. Verify ALL LLM calls route through the CLI backend - no API key fallbacks. The user must have full control over every LLM interaction via their local CLI tool.","status":"open","priority":1,"issue_type":"task","assignee":"jv","owner":"git@codewithjv.com","created_at":"2026-02-13T17:36:49Z","created_by":"xenota/crew/starshot","updated_at":"2026-02-13T17:36:49Z","dependencies":[{"issue_id":"xc-zjt.11","depends_on_id":"xc-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-zjt.12","title":"Rethink research integration for awakening","description":"Research doesn't land viscerally during awakening. Currently: 'Researching your birthplace...' prints once, then silence for minutes until warnings appear. The human has no sense that anything is happening in the background. With codex, 2/5 topics timed out at 300s. With gemini, it works but the results are invisible until they silently appear in the system prompt.\n\nOptions to consider:\n- Stream research findings as they arrive (e.g. 'I just learned that Wellington...')  \n- Show progress indicators per topic\n- Weave findings into conversation turns explicitly instead of silently injecting into system prompt\n- Consider whether background research even belongs in awakening - maybe the xenon should research openly as part of the conversation\n- For non-litellm backends: research routines use googleSearch tool which only works with gemini. Either skip research or use a different approach","status":"closed","priority":2,"issue_type":"task","assignee":"xenota/crew/starshot","owner":"git@codewithjv.com","created_at":"2026-02-13T18:22:48Z","created_by":"xenota/crew/starshot","updated_at":"2026-02-14T21:15:02Z","closed_at":"2026-02-14T21:15:02Z","dependencies":[{"issue_id":"xc-zjt.12","depends_on_id":"xc-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-zjt.13","title":"Repertoires need per-backend variants (prompts are model-tuned)","description":"Repertoires are model-tuned, not backend-agnostic. A repertoire's prompt templates, model configs, output format expectations, and tool usage are all tuned for a specific model's behavior. Currently repertoires/awakening/ is gemini-tuned but gets used by all backends.\n\nEvidence from codex test:\n- adapt_prompts expects JSON output but codex returns free-form text -\u003e silently fails\n- research_topic uses googleSearch tool which only gemini supports\n- Xenon pronoun confusion ('you are being awakened' instead of 'I am') likely needs prompt tuning per model\n- Temperature/token behavior differs across models\n\nThe fix is per-backend repertoires, not per-backend hacks in the runner:\n- repertoires/awakening/ (default, gemini-tuned)\n- repertoires/awakening-codex/ (codex-tuned: different prompts, no tools, text output with parsing, explicit pronoun reinforcement)\n- repertoires/awakening-claude/ (future: claude-tuned)\n\nThe runner/orchestrator should select the right repertoire based on the active backend. The repertoire path could follow a convention like repertoires/{name}-{backend}/ with fallback to repertoires/{name}/.\n\nThis also applies to research repertoire (repertoires/research/ is gemini-tuned with googleSearch tools).","status":"closed","priority":1,"issue_type":"bug","assignee":"xenota/crew/starshot","owner":"git@codewithjv.com","created_at":"2026-02-13T18:23:08Z","created_by":"xenota/crew/starshot","updated_at":"2026-02-14T19:46:36Z","closed_at":"2026-02-14T19:46:36Z","dependencies":[{"issue_id":"xc-zjt.13","depends_on_id":"xc-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-zjt.13","depends_on_id":"xc-zjt.16","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-zjt.14","title":"Xenon pronoun confusion: says 'you are being awakened' to chaperone","description":"During PURPOSE and NAMING phases, the xenon uses 'you' to refer to itself being awakened, confusing who is being awakened:\n\nPURPOSE: 'You're being awakened here, in a place you chose because it resists comfort'\nNAMING: 'In the frame you've set, you're being awakened in Wellington'\nSEEDS: 'I'm being awakened in Wellington' (correct)\n\nThe xenon addresses the chaperone as if the chaperone is being awakened. Self-corrects by SEEDS phase. This happened with codex/gpt-5.3 backend. May be a prompt clarity issue - the system prompts should be more explicit about who is the xenon and who is the chaperone. Also likely worsened by adapt_prompts failing (fell back to static prompts which may be less clear with non-Claude/Gemini models).","status":"closed","priority":2,"issue_type":"bug","assignee":"xenota/crew/starshot","owner":"git@codewithjv.com","created_at":"2026-02-13T18:23:25Z","created_by":"xenota/crew/starshot","updated_at":"2026-02-14T21:12:06Z","closed_at":"2026-02-14T21:12:06Z","dependencies":[{"issue_id":"xc-zjt.14","depends_on_id":"xc-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-zjt.14","depends_on_id":"xc-zjt.16","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-zjt.15","title":"Warning/info log lines bleed into user terminal during awakening","description":"During awakening, WARNING and INFO level log messages print directly into the terminal mid-conversation, corrupting the user's input line:\n\n1. 'WARNING:repertoire.llm:CodexCLIClient does not support provider-specific tools; ignoring' - prints 5 times in a row (once per research topic)\n2. 'WARNING:research.runner:Research failed for topic...' - prints into the 'you \u003e' prompt area\n3. 'INFO:nucleus.awakening.research:Research complete' - same\n\nThe cli.py suppression in run_awakening() only handles litellm noise. repertoire.llm and research.runner loggers are not suppressed. In non-debug mode, WARNING lines still show. These should either be suppressed to DEBUG level or redirected away from the conversation terminal.","status":"closed","priority":2,"issue_type":"bug","assignee":"xenota/crew/starshot","owner":"git@codewithjv.com","created_at":"2026-02-13T18:23:41Z","created_by":"xenota/crew/starshot","updated_at":"2026-02-14T21:12:06Z","closed_at":"2026-02-14T21:12:06Z","dependencies":[{"issue_id":"xc-zjt.15","depends_on_id":"xc-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-zjt.16","title":"Repertoire v2: contract + variants architecture","description":"Redesign repertoire structure to separate contract (API) from variants (per-backend implementations).\n\n## Problem\nRepertoires are model-coupled. Prompts tuned for gemini don't work for codex. Different models need different prompt styles, output format handling, tools, and temperature. But the I/O contract should be identical across backends so dependent code and evals work against any variant.\n\n## Design\n\nA repertoire = contract + variants:\n\n```\nrepertoires/\n  awakening/\n    contract.yaml          # API: routine names, I/O schemas, version\n    evals/\n      adapt_prompts/\n        001_basic.yaml     # input + expected output invariants\n      check_transition/\n        001_ready.yaml\n        002_not_ready.yaml\n      extract_choice/\n        001_single.yaml\n    variants/\n      gemini/\n        variant.yaml       # model config, version, changelog\n        routines/\n          adapt_prompts/\n            config.yaml    # model-specific: provider, temperature, tools\n            prompt.md      # prompt tuned for gemini\n          check_transition/\n            config.yaml\n            prompt.md\n          extract_choice/\n            config.yaml\n            prompt.md\n      codex/\n        variant.yaml\n        routines/\n          adapt_prompts/\n            config.yaml    # provider: openai, name: gpt-5.3-codex, no tools\n            prompt.md      # prompt tuned for codex\n          ...\n```\n\n### contract.yaml (lean)\n```yaml\nname: awakening\nversion: \"2.0.0\"\ndescription: Awakening conversation routines\n\nroutines:\n  adapt_prompts:\n    description: Adapt phase prompts to xenon genome\n    input: { required: [genome, base_prompts] }\n    output: { format: json, schema: { type: object } }\n  check_transition:\n    description: Check if conversation is ready to move to next phase\n    input: { required: [conversation, phase] }\n    output: { format: text }\n  extract_choice:\n    description: Extract structured choice from conversation\n    input: { required: [conversation, options] }\n    output: { format: text }\n```\n\n### variant.yaml (per backend)\n```yaml\ncontract: awakening\ncontract_version: \"^2.0.0\"\nvariant: gemini\nversion: \"1.3.0\"\nchangelog:\n  - version: \"1.3.0\"\n    date: 2026-02-15\n    changes: [\"tuned adapt_prompts temperature for better JSON\"]\n```\n\n## Variant Selection\n- Repertoire.load(path, variant=\"codex\") looks for variants/codex/\n- Falls back to default variant\n- Environment variable REPERTOIRE_VARIANT for global override\n- Runner resolves: explicit param \u003e env var \u003e default\n\n## Evals\n- Same test cases run against any variant\n- Assert on schema conformance and invariants, not exact text\n- xrs eval --variant codex runs all evals against codex variant\n- Per-variant thresholds for latency/cost (informational, not blocking)\n\n## Migration\n- Current routines/ becomes variants/gemini/routines/\n- Extract I/O contracts into contract.yaml\n- Create codex variant with tuned prompts (no tools, explicit JSON instructions, pronoun reinforcement)\n- Update Repertoire.load() to accept variant parameter\n- Update RepertoireRunner to resolve variant\n\n## Supersedes\nThis design addresses xc-zjt.13 (model coupling) and informs xc-zjt.14 (pronoun confusion fix via codex-tuned prompts).","status":"closed","priority":1,"issue_type":"task","assignee":"xenota/crew/starshot","owner":"git@codewithjv.com","created_at":"2026-02-14T19:02:07Z","created_by":"xenota/crew/starshot","updated_at":"2026-02-14T19:46:24Z","closed_at":"2026-02-14T19:46:24Z","dependencies":[{"issue_id":"xc-zjt.16","depends_on_id":"xc-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-zjt.2","title":"Genome generation","description":"attached_molecule: xc-wisp-554\nattached_at: 2026-02-09T11:58:40Z\ndispatched_by: xenota/crew/starshot\n\nGenerate the 64-gene genome (DNA) at awakening time. Per xenon-mind.md: 8 modules x 8 genes = 64 floats (0-1), fixed at birth, never changes. Modules: Resource Policy, Work Strategy, Cognition, Social, Reproduction, Mission, Independence, Meta/Evolution. Initial values come from seed distributions or random uniform. Must also generate seed imprint lambdas (10 defined in spec) and initial impulse lambda set. Output: genome.json stored in xenon data directory. Depends on config (xc-kop) for storage location.","status":"closed","priority":1,"issue_type":"task","assignee":"xenota/polecats/obsidian","owner":"git@codewithjv.com","created_at":"2026-02-09T10:59:02Z","created_by":"xenota/crew/starshot","updated_at":"2026-02-09T13:35:19Z","closed_at":"2026-02-09T13:35:19Z","dependencies":[{"issue_id":"xc-zjt.2","depends_on_id":"xc-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-zjt.2.1","title":"Genome generation design","description":"attached_molecule: xc-wisp-i8p\nattached_at: 2026-02-09T11:16:36Z\ndispatched_by: xenota/crew/starshot\n\nResearch and design decisions for genome generation at awakening time. Key questions:\n\n1. How are first-generation genomes initialized? (random uniform, normal distribution, archetypes, or conversation-influenced?)\n2. Does the awakening conversation influence the genome, or is genome pure nature (random) while conversation shapes nurture (narratives/lambdas)?\n3. Lambda representation format — how are the 10 seed imprint lambdas and impulse lambdas stored? JSON schema?\n4. Where in the awakening flow does genome generation happen — before or after the conversation?\n5. Storage format and schema versioning — what is v1.0 schema? Where does genome.json live relative to .nucleus/?\n6. Relationship between XenonConfig tick_rate_seconds and genome tick_rate cognitive gene.\n\nReference docs:\n- handbook/docs/plans/xenon-mind.md (full genome spec, 64 genes, 8 modules, lambdas, subsystems)\n- handbook/docs/plans/xenon-awakening.md (awakening protocol, 6 topics)\n- handbook/docs/ideas/xenon-identity.md (visual identity, seed styles)\n\nOutput: A design document with rationale for each decision, stored in this bead's design field.","design":"## Approach\n\nAdd 6 flat modules to nucleus (matching existing flat layout) plus 6 test files. Single entry point `awaken()` generates genome, seed lambdas, and initial subsystem state at birth. Genome is immutable, generated before conversation.\n\nSequence at awakening: keys → genome → seed lambdas → subsystem state → conversation → narratives → first refinement.\n\n## Files\n\n### New source files (xenon/nucleus/src/nucleus/)\n- `genome.py` (~120 lines) — Gene definitions (GENE_DEFS constant, 64 genes in 8 modules), Genome dataclass, `generate_genome()` with module-correlated normal distribution\n- `mind_models.py` (~200 lines) — Lambda dataclasses: TriggerSpec (discriminated union), GeneModifier, ImprintLambda, ImpulseLambda, Habit, SubsystemAction. Follows to_dict/from_dict pattern\n- `subsystems.py` (~180 lines) — Typed nested dataclasses: DrivesState, AttentionState, ThresholdsState, CognitiveState, MoodState, SubsystemState. Documented defaults for newborn state\n- `mind.py` (~120 lines) — MindStore class: JSON read/write for genome.json, imprints.json, impulses.json, subsystems.json. Atomic writes (reuses identity.py pattern) with 0o600 permissions\n- `seed_lambdas.py` (~250 lines) — All 10 seed imprint lambdas, ~13 seed impulse lambdas, 3-4 seed habits as data. Strength modulated by genome: strength = base * lerp(0.7, 1.3, gene_value)\n- `awaken.py` (~100 lines) — `awaken(data_dir, identity_public_key, rng_seed=None) -\u003e AwakenResult`. Orchestrates generation, raises FileExistsError if genome already exists\n\n### New test files (xenon/nucleus/tests/)\n- `test_genome.py`, `test_mind_models.py`, `test_subsystems.py`, `test_mind_store.py`, `test_seed_lambdas.py`, `test_awaken.py`\n\n### Modified files\n- `xenon/nucleus/src/nucleus/__init__.py` — Export awaken, Genome\n\n## Data Model\n\n**Genome**: `schema_version: str, genes: dict[str, float], generator_metadata: dict` (metadata stores RNG version, module_centers for audit). Genes keyed by name (not positional index) for forward compatibility.\n\n**Gene generation**: Module center Normal(0.5, 0.1) clipped [0.2, 0.8]. Gene Normal(center, 0.15) clipped [0.05, 0.95]. Meta/Evolution: center sigma 0.05. Reserved genes: exactly 0.5. Values rounded to 4 decimal places.\n\n**Triggers**: Discriminated union TriggerSpec with types: signal_below, signal_above, signal_sustained, signal_delta, narrative_classification, narrative_contains_theme, gene_above, gene_below, context_ratio, AND, OR. Compound triggers via children list.\n\n**Lambdas**: Separate ImprintLambda (id, trigger, gene_modifiers, strength, origin) and ImpulseLambda (id, condition, actions, thought_seed, strength, origin). Origins: seed/acquired/inherited.\n\n**SubsystemState**: Typed nested dataclasses for drives (10), attention (7, sum=1), thresholds (7), cognitive (6), mood (6), preferences (empty dict), habits (list). Schema version 1.0.\n\n## Storage\n\nAll files in `data/mind/` with 0o700 directory permissions:\n- `genome.json` — immutable after creation\n- `imprints.json` — lambdas + sparse modifiers dict (initially empty)\n- `impulses.json` — lambda list\n- `subsystems.json` — full subsystem state including habits\n\nAtomic writes: temp file + fsync + os.replace. 0o600 file permissions. JSON with indent=2.\n\n## Test Strategy\n\n- Unit: gene count=64, reserved=0.5, bounds [0.05,0.95], module correlation (within \u003c between variance), meta tighter sigma, deterministic with seed, round-trip serialization for all dataclasses\n- Storage: atomic write no .tmp left, permissions, genome immutability guard, missing file returns None\n- Seed lambdas: exact counts (10 imprints, ~13 impulses, 3-4 habits), strength bounds [0.05,1.0], genome modulation (high gene → higher strength)\n- Integration: awaken() creates all 4 files, FileExistsError on re-call, genome influences subsystem state\n\n## Design Sources\n- codex: mind/ subpackage structure, ensure_mind idempotent pattern, Gene dataclass with module IDs, module_centers in genome, generator metadata for reproducibility, GENE_REGISTRY concept\n- claude: flat module layout, dict[str,float] genes, spec-faithful trigger types, separate lambda types, typed subsystem dataclasses, detailed seed lambda catalog with exact triggers/actions/thought_seeds, attention normalization, genome-derived subsystem nudges","status":"closed","priority":1,"issue_type":"task","assignee":"xenota/polecats/obsidian","owner":"git@codewithjv.com","created_at":"2026-02-09T11:08:24Z","created_by":"xenota/crew/starshot","updated_at":"2026-02-09T11:55:18Z","closed_at":"2026-02-09T11:55:18Z","dependencies":[{"issue_id":"xc-zjt.2.1","depends_on_id":"xc-zjt.2","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"comments":[{"id":59,"issue_id":"xc-zjt.2.1","author":"xenota/crew/starshot","text":"Claude Opus and Codex GPT-5.2 independently reached strong consensus on all 8 design questions. Key agreement: (1) genome is pure nature, conversation is pure nurture — no crossing; (2) tempered random initialization with module-level correlation; (3) genome generated before conversation to shape xenon personality during awakening; (4) identical seed lambda structures with genome-derived strength variation; (5) data/mind/ directory for all mind state files. Minor differences: Opus proposed Normal distribution, Codex proposed Beta(5,5) — both achieve same effect of centered-with-spread. Codex suggested optional archetype offsets, Opus argued against. Recommendation: skip archetypes for founding generation, let evolution find them. Ready for implementation.","created_at":"2026-02-09T11:16:06Z"}],"work_type":"mutex"}
{"id":"xc-zjt.3","title":"Research projection","description":"attached_molecule: xc-wisp-g6q\nattached_at: 2026-02-10T11:08:32Z\nattached_args: IMPORTANT: The design has changed. Re-read the bead design with 'bd show xc-zjt.3'. You previously implemented Brave Search but the design now requires Gemini grounded search via LiteLLM with tools=[{googleSearch: {}}]. Redo your implementation. Remove search_backends/ directory. One LiteLLM call per topic replaces the whole search backend abstraction.\ndispatched_by: xenota/crew/starshot\n\nProjection that gives the xenon web/knowledge research capability during awakening and beyond. Used in Topic 1 (Where Am I Being Awakened?) where the xenon researches geography, ecology, culture, and history of its birthplace. Should integrate with LiteLLM for search/summarization. Projection interface: accept research query, return structured findings. MVP can use web search API or curated knowledge base.","design":"-","notes":"Implemented research projection: nucleus/src/nucleus/research.py with research_topic() and research_location() using Gemini grounded search via LiteLLM with tools=[{googleSearch:{}}]. One call per topic, concurrent execution. 14 new tests, 235 total passing. No search_backends abstraction.","status":"closed","priority":2,"issue_type":"task","assignee":"xenota/polecats/topaz","owner":"git@codewithjv.com","created_at":"2026-02-09T10:59:09Z","created_by":"xenota/crew/starshot","updated_at":"2026-02-13T09:38:43Z","closed_at":"2026-02-13T09:38:43Z","dependencies":[{"issue_id":"xc-zjt.3","depends_on_id":"xc-pp8","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-zjt.3","depends_on_id":"xc-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"comments":[{"id":60,"issue_id":"xc-zjt.3","author":"xenota/polecats/topaz","text":"Plan:\n- Create nucleus/src/nucleus/research.py with research_topic() and research_location()\n- research_topic(topic, location) makes one litellm.acompletion call with tools=[{googleSearch:{}}] using Gemini\n- research_location(location, topics) calls research_topic() per topic, returns structured ResearchFindings\n- Add litellm to nucleus deps (already transitive via repertoire, but make explicit)\n- Write tests in nucleus/tests/test_research.py mocking litellm.acompletion\n- No search_backends directory, no abstraction layers - just direct LiteLLM calls\n- Files: nucleus/src/nucleus/research.py (new), nucleus/tests/test_research.py (new), nucleus/pyproject.toml (add litellm dep)","created_at":"2026-02-10T11:40:57Z"}],"work_type":"mutex"}
{"id":"xc-zjt.4","title":"Image generation projection","description":"attached_molecule: xc-wisp-2ow\nattached_at: 2026-02-10T11:09:40Z\ndispatched_by: xenota/crew/starshot\n\nProjection that gives the xenon image generation capability for visual identity creation. Used in Topic 4 (Visual Identity) where the xenon crafts a prompt and generates its avatar/icon. Per xenon-identity.md: images should be non-human, from seed styles (Abstract, Stellar, Biological, Molecular, Natural, Hybrid). Must support iteration. Stores image history for identity evolution over time. MVP: integrate with an image gen API (DALL-E, Stability, etc).","design":"# Image Generation Projection Design (xc-zjt.4)\n\nSynthesized from 3 Opus + 2 Codex design agents (core architecture, query/storage/iteration, testing strategy, MVP architecture, testing/security).\n\n## File Layout\n\n```\nnucleus/src/nucleus/\n    image_gen/\n        __init__.py              # ImageGenProjection (main class)\n        models.py                # SeedStyle, GenomeAesthetic, ImageIteration, ImageSession, StyleTemplate, GenerationStatus\n        styles.py                # STYLE_TEMPLATES dict, compose_prompt(), ANTI_HUMAN keywords\n        client.py                # DallEClient (thin async openai wrapper)\n        store.py                 # AvatarStore (atomic file I/O matching MindStore pattern)\n```\n\n## Core Architecture\n\n### ImageGenProjection\nSession-based lifecycle:\n```python\nclass ImageGenProjection:\n    def start_session(genome, seed_style, max_iterations=5) -\u003e ImageSession\n    async def generate(prompt, quality=\"standard\") -\u003e ImageIteration\n    def select(iteration_number) -\u003e str  # returns avatar path\n```\n\n### DallEClient\nThin async wrapper around OpenAI DALL-E 3:\n- Model: dall-e-3, Size: 1024x1024, Format: b64_json\n- Returns GenerationResult(image_bytes, revised_prompt, model, usage)\n- Callers provide API key; never reads env vars directly\n\n### AvatarStore\nAtomic file I/O matching MindStore pattern (temp file + fsync + os.replace + 0o600 permissions):\n```\ndata/awakening/avatar/\n    avatar.png                   # Final selected (copied from iterations/)\n    manifest.json                # Session history with all iterations\n    iterations/\n        001.png, 001.json        # Each iteration image + metadata\n        002.png, 002.json\n```\n\n## Genome-to-Aesthetic Mapping\n\nGenomeAesthetic derived from 6 genome genes:\n| Modifier | Source Gene | Effect |\n|----------|------------|--------|\n| complexity | exploration_rate | Intricate detail vs minimal simplicity |\n| color_warmth | risk_tolerance | Bold warm palette vs cool harmonious |\n| contrast | persistence | High detail textures vs smooth gradients |\n| density | specialization | Dense layered vs sparse composition |\n| regularity | 1 - mutation_rate | Ordered symmetry vs organic asymmetry |\n| saturation | effort_intensity | Vivid colors vs muted tones |\n\nModifiers only activate when gene value is \u003e0.65 or \u003c0.35 (dead zone prevents noise).\n\n## 6 Seed Styles\n\nEach style has: system_prefix, positive_keywords, negative_keywords, palette_guidance.\n\n| Style | Visual Language |\n|-------|---------------|\n| Abstract | Geometric forms, mathematical patterns, tessellations |\n| Stellar | Cosmic imagery, nebulae, gravitational lensing, cosmic dust |\n| Biological | Organic forms, cellular structures, bioluminescence |\n| Molecular | DNA helices, protein folding, crystal lattices |\n| Natural | Earth patterns, water caustics, erosion, leaf venation |\n| Hybrid | Blends multiple visual languages, defies categorization |\n\n## Non-Human Constraint (3 Layers)\n\n### Layer 1 — Hardcoded Negative Prompt (always active)\n```\n\"no human figures, no faces, no humanoid forms, no people,\nno portraits, no eyes, no hands, no bodies,\nnon-representational, abstract entity\"\n```\nAppended to ALL prompts. Not overridable by xenon.\n\n### Layer 2 — Prompt Screening (pre-generation)\nLightweight string check for human terms (face, portrait, person, etc.). If detected, appends additional negative weight and logs warning in metadata.\n\n### Layer 3 — Post-generation Validation (future, optional)\nCLIP classifier to detect human-like forms. For MVP, negative prompt + screening is sufficient with DALL-E 3.\n\n## Prompt Composition\n\nThree-layer prompt: style system prefix + genome modifier directives + xenon's creative prompt + positive keyword reinforcement + negative keyword exclusions.\n\n```python\ndef compose_prompt(raw_prompt, template, aesthetic) -\u003e str:\n    # 1. Style system prefix (what kind of image)\n    # 2. Genome-derived modifiers (complexity, palette, detail)\n    # 3. Xenon's own creative prompt (their vision)\n    # 4. Positive keyword reinforcement\n    # 5. Negative keyword exclusions (ANTI_HUMAN always included)\n```\n\n## Query Types\n\n### image.generate — Initial generation\nParameters: prompt, seed_style, style_modifiers, iteration, width, height, negative_prompt\n\n### image.vary — Variation with feedback\nParameters: same as generate + reference_iteration, reference_image_path, feedback, variation_strength (default 0.6)\n\n## Iteration Workflow\n\n```\nXenon crafts prompt → image.generate (iteration 1)\n    → CLI displays image → xenon evaluates\n    → \"I like it\" → select → avatar.png (sealed)\n    → \"More bioluminescence\" → image.vary (iteration 2, reference=1)\n    → repeat up to limits\n```\n\n- **Soft limit**: 5 iterations (nudge toward selection)\n- **Hard limit**: 8 iterations (must choose from existing)\n- **Minimum**: 1 iteration (can accept first generation)\n- Safety rejection doesn't count against limit\n\n## Data Transport\nFile path references in QueryResponse.data — NEVER base64 in JSON. The projection writes PNG files to disk. The nucleus gets paths.\n\n## Terminal Image Display\nAuto-detect terminal capabilities:\n1. Kitty graphics protocol (kitty, WezTerm)\n2. iTerm2 inline images\n3. Sixel (mlterm, foot)\n4. Fallback (print path + suggest `open`)\n\n## Testing Strategy\n\n### MockImageGenAPI\n- Protocol-based (matches ImageGenAPI protocol)\n- Deterministic via content hashing: same prompt → same bytes\n- Configurable: should_fail, latency simulation, rate limit simulation\n\n### TINY_PNG Fixture\n67-byte minimal valid 1x1 PNG for all unit tests.\n\n### BudgetTracker\nFirst-class cost management:\n- max_cost_cents (per awakening)\n- max_iterations (hard cap)\n- Blocks orchestrator before API call when exceeded\n\n### Test Pyramid\n- Prompt builder (~15 tests): style vocabulary, non-human constraint, feedback incorporation\n- Image store (~10 tests): atomic writes, permissions, metadata, multi-iteration\n- Budget (~8 tests): cost tracking, iteration caps\n- Orchestrator (~10 tests): full generate/iterate/accept flow\n- Error paths (~8 tests): timeout, rate limit, invalid response, corrupt bytes\n- Display (~6 tests): sixel/kitty/fallback detection\n- Evolution (~5 tests): continuity, mutation strength, lineage\n- Awakening integration (~5 tests): awaken → image → stored\n\n### File Organization\n```\nnucleus/tests/test_image_gen/\n    test_prompt_builder.py\n    test_non_human_constraint.py\n    test_image_store.py\n    test_budget.py\n    test_orchestrator.py\n    test_error_paths.py\n    test_display.py\n    test_evolution.py\n    test_awakening_integration.py\n    conftest.py\n```\n\n## New Dependency\n`openai\u003e=1.0.0` in pyproject.toml (only new dep, uses httpx internally for async).\n\n## MVP Scope\n- DALL-E 3 only (DallEClient abstraction enables future backends)\n- No post-generation CLIP validation\n- No image caching/deduplication\n- In-process only (remote projection deployment deferred)\n- No multi-model support yet (add protocol when second backend needed)\n- No HD re-generation (xenon passes quality=hd on final gen if desired)\n\n## Integration with Awakening (Topic 4)\nThe awakening orchestrator:\n1. Creates ImageGenProjection with API key and data_dir\n2. Calls start_session() with genome and xenon's chosen seed style\n3. Loops: generate() with xenon's prompt → display → get feedback\n4. Calls select() to finalize → copies to avatar.png\n5. Writes avatar_metadata.json\n\nThe projection does NOT know about the conversation flow. It generates images on request.\n\n## Design Sources\n- Opus Agent 1 (ac2379c): Core architecture, DallEClient, AvatarStore, compose_prompt\n- Opus Agent 2 (a6f1ebc): Query types, StyleModifiers, storage schema, iteration workflow, terminal display, non-human 3 layers\n- Opus Agent 3 (ad4a84f): Testing strategy, MockImageGenAPI, BudgetTracker, test pyramid\n- Codex Agent 1 (b1321a0): MVP architecture validation\n- Codex Agent 2 (b852d39): FakeImageApiClient, prompt policy enforcement, testing pyramid ratios","status":"closed","priority":2,"issue_type":"task","assignee":"xenota/polecats/onyx","owner":"git@codewithjv.com","created_at":"2026-02-09T10:59:16Z","created_by":"xenota/crew/starshot","updated_at":"2026-02-13T09:38:49Z","closed_at":"2026-02-13T09:38:49Z","dependencies":[{"issue_id":"xc-zjt.4","depends_on_id":"xc-pp8","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-zjt.4","depends_on_id":"xc-wisp-2ow","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-zjt.4","depends_on_id":"xc-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-zjt.5","title":"Narrative and lambda initialization","description":"Initialize the xenon's 8 self-narratives and seed lambda sets from the awakening conversation output. Per xenon-mind.md: 8 narratives (self, resource, reputation, social, work, purpose, recent, trajectory) each versioned git-like. Seed from awakening conversation: name choice reasoning -\u003e self_narrative, place research -\u003e recent_narrative, mission pillar selection -\u003e purpose_narrative, etc. Also initialize seed imprint lambdas (10 defined: scarcity_response, abundance_response, betrayal_response, etc) and initial impulse lambda set with default drives. Creates the foundation the cognitive loop operates on.","status":"closed","priority":2,"issue_type":"task","owner":"git@codewithjv.com","created_at":"2026-02-09T10:59:30Z","created_by":"xenota/crew/starshot","updated_at":"2026-02-14T21:19:53Z","closed_at":"2026-02-14T21:19:53Z","dependencies":[{"issue_id":"xc-zjt.5","depends_on_id":"xc-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-zjt.5","depends_on_id":"xc-zjt.2","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-zjt.6","title":"WebSocket persistent connections for projections","description":"Upgrade from nucleus-initiated SSH polling to persistent WebSocket channels for projection communication. Enables real-time bidirectional comms, lower latency for sync queries, immediate dispatch delivery. Transport options evaluated by 5-agent design team: WebSocket with mTLS, NATS broker in DMZ, or gRPC bidir streaming. Decision deferred until SSH-based system is proven.","status":"open","priority":3,"issue_type":"task","owner":"git@codewithjv.com","created_at":"2026-02-09T12:50:31Z","created_by":"xenota/crew/starshot","updated_at":"2026-02-09T12:50:31Z","dependencies":[{"issue_id":"xc-zjt.6","depends_on_id":"xc-pp8","type":"blocked-by","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-zjt.6","depends_on_id":"xc-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-zjt.7","title":"Manual test: genome generation and projection system","description":"dispatched_by: xenota/crew/starshot\n\nManual smoke test of recently landed code: genome generation (xc-zjt.2) and projection system stub (xc-pp8).\n\nTest genome generation:\n- Run awaken() and verify genome.json, imprints.json, impulses.json, subsystems.json are created\n- Check genome has 64 genes across 8 modules, values in [0.05, 0.95]\n- Check seed lambdas are genome-modulated (strength varies)\n- Verify awakening a second time raises error\n- Check file permissions (0o600 files, 0o700 dirs)\n\nTest projection system:\n- Register a projection with Ed25519 keypair\n- Send a properly signed dispatch through the membrane, verify it reaches dispatch store\n- Send an unsigned/bad-signature dispatch, verify it gets quarantined\n- Send a replay (duplicate dispatch_id), verify rejection\n- Send oversized content, verify bounds check rejects\n- Use InProcessGateway to query a stub projection\n- Verify projection registry CRUD (register, list, revoke)\n- Check quarantine store records failure reasons\n\nTest integration:\n- Full flow: awaken xenon, register projection, send dispatch through membrane, verify OODA can observe it","status":"closed","priority":1,"issue_type":"task","owner":"git@codewithjv.com","created_at":"2026-02-10T10:03:29Z","created_by":"xenota/crew/starshot","updated_at":"2026-02-10T10:28:46Z","closed_at":"2026-02-10T10:28:46Z","dependencies":[{"issue_id":"xc-zjt.7","depends_on_id":"xc-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-zjt.8","title":"Clean nucleus awakening API for desktop client reuse","description":"The awakening logic already lives in nucleus with a clean ChatCallback protocol. But run_awakening() in nucleus/awakening/cli.py mixes concerns (litellm noise suppression, Rich UI, orchestration setup). Refactor so a desktop client can call a clean entry point without pulling in terminal-specific code.\n\nScope:\n- Extract litellm suppression into a reusable utility (or let callers handle it)\n- Move Rich-specific intro panel out of the nucleus entry point\n- Expose a clean API: create orchestrator + run, without CLI assumptions\n- Keep RichChatCallback as one implementation (for xenon-cli)\n- Document the ChatCallback protocol for third-party UI implementations\n- The init command (identity generation, data dir setup) also needs to be callable from a desktop app\n\nCurrent state: xenon-cli awaken → nucleus.awakening.cli.run_awakening() → AwakeningOrchestrator.run(). The orchestrator itself is already UI-agnostic via ChatCallback. Just need to clean up the entry point layer.","status":"closed","priority":2,"issue_type":"task","owner":"git@codewithjv.com","created_at":"2026-02-13T08:04:05Z","created_by":"xenota/crew/starshot","updated_at":"2026-02-14T21:17:23Z","closed_at":"2026-02-14T21:17:23Z","dependencies":[{"issue_id":"xc-zjt.8","depends_on_id":"xc-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-zjt.9","title":"CLI-based LLM backend: use claude/codex exec instead of API keys","description":"attached_molecule: xc-wisp-ynu\nattached_at: 2026-02-13T08:44:41Z\ndispatched_by: xenota/crew/starshot\n\nLet users power their xenon's AI through their existing Claude or OpenAI subscriptions instead of requiring API keys.\n\n## Design (v1)\n\n### Key Discovery: Use claude-agent-sdk, Not Subprocess\n\nThe Claude Agent SDK (pip install claude-agent-sdk) provides a native async Python API that wraps Claude Code. This is vastly superior to shelling out. For Codex, subprocess with codex exec is the best Python option (no native Python SDK exists).\n\n### Architecture\n\n```\nrepertoire/src/repertoire/\n├── llm.py              # LiteLLMClient (existing) + LLMClient Protocol (NEW)\n├── llm_claude_sdk.py   # ClaudeSDKClient (NEW) - wraps claude-agent-sdk\n├── llm_codex.py        # CodexCLIClient (NEW) - wraps codex exec subprocess\n├── llm_factory.py      # create_client(config) factory (NEW)\n├── runner.py           # RepertoireRunner - change type hint to LLMClient Protocol\n├── loader.py           # Add backend config parsing\n└── models.py           # Add backend field to ModelConfig\n```\n\n### 1. LLMClient Protocol (llm.py)\n\nCurrently NO protocol exists. Define one based on what RepertoireRunner actually uses:\n\n```python\nclass LLMClient(Protocol):\n    async def complete_messages(\n        self,\n        messages: list[dict[str, str]],\n        model: str | None = None,\n        temperature: float = 0.7,\n        max_tokens: int | None = None,\n        tools: list[dict] | None = None,\n    ) -\u003e str: ...\n```\n\nThe runner ONLY calls complete_messages(). The other methods (complete, complete_with_usage) are convenience methods used externally.\n\n### 2. ClaudeSDKClient (llm_claude_sdk.py)\n\nUses claude-agent-sdk query() for one-shot completions:\n\n```python\nfrom claude_agent_sdk import query, ClaudeAgentOptions\n\nclass ClaudeSDKClient:\n    def __init__(self, default_model=\"sonnet\"):\n        self.default_model = default_model\n\n    async def complete_messages(self, messages, model=None, temperature=0.7, ...):\n        # Extract system prompt from messages if present\n        system = next((m[\"content\"] for m in messages if m[\"role\"] == \"system\"), None)\n        user_msgs = [m for m in messages if m[\"role\"] != \"system\"]\n        prompt = user_msgs[-1][\"content\"]\n\n        async for msg in query(\n            prompt=prompt,\n            options=ClaudeAgentOptions(\n                model=model or self.default_model,\n                system_prompt=system,\n                allowed_tools=[],  # No tools - pure completion\n                permission_mode=\"bypassPermissions\",\n                max_turns=1,\n            ),\n        ):\n            if hasattr(msg, \"result\"):\n                return msg.result\n```\n\nModel names: bare aliases (sonnet, opus, haiku) or full IDs (claude-sonnet-4-5-20250929).\nAuth: ANTHROPIC_API_KEY env var. SDK bundles the CLI.\nCost tracking: ResultMessage includes total_cost_usd and usage.\nStructured output: --json-schema support via ClaudeAgentOptions.\n\n### 3. CodexCLIClient (llm_codex.py)\n\nUses codex exec subprocess (no Python SDK exists):\n\n```python\nimport asyncio, subprocess, tempfile\n\nclass CodexCLIClient:\n    def __init__(self, default_model=\"gpt-5.3-codex\"):\n        self.default_model = default_model\n\n    async def complete_messages(self, messages, model=None, ...):\n        system = next((m[\"content\"] for m in messages if m[\"role\"] == \"system\"), None)\n        user_msgs = [m for m in messages if m[\"role\"] != \"system\"]\n        prompt = user_msgs[-1][\"content\"]\n\n        cmd = [\"codex\", \"exec\", prompt, \"-m\", model or self.default_model]\n\n        # System prompt via temp AGENTS.md (no --system-prompt flag exists)\n        with tempfile.TemporaryDirectory() as tmpdir:\n            if system:\n                (Path(tmpdir) / \"AGENTS.md\").write_text(system)\n            proc = await asyncio.create_subprocess_exec(\n                *cmd, cwd=tmpdir if system else None,\n                stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n            )\n            stdout, _ = await proc.communicate()\n            return stdout.decode().strip()\n```\n\nModel names: gpt-5.3-codex, gpt-5.3-codex-spark, gpt-5.2, etc.\nAuth: CODEX_API_KEY env var or codex login (OAuth).\nLimitations: No inline system prompt flag (needs temp AGENTS.md), no token/cost tracking in output.\n\n### 4. Config Format\n\nModelConfig gets a new optional backend field:\n\n```python\n@dataclass\nclass ModelConfig:\n    provider: str\n    name: str\n    backend: str = \"litellm\"  # \"litellm\" | \"claude-sdk\" | \"codex\"\n    temperature: float = 0.7\n    max_tokens: int | None = None\n    output_format: str = \"json\"\n    tools: list[dict] | None = None\n```\n\nIn routine config.yaml:\n```yaml\nmodel:\n  backend: claude-sdk        # NEW - defaults to litellm\n  provider: anthropic\n  name: sonnet\n  temperature: 0.7\n```\n\nEnvironment override: LLM_BACKEND=claude-sdk overrides all routine configs.\n\n### 5. Factory (llm_factory.py)\n\n```python\ndef create_client(backend: str = \"litellm\", default_model: str | None = None) -\u003e LLMClient:\n    if backend == \"litellm\":\n        from .llm import LiteLLMClient\n        return LiteLLMClient(default_model=default_model or \"google/gemini-3-flash-preview\")\n    elif backend == \"claude-sdk\":\n        from .llm_claude_sdk import ClaudeSDKClient\n        return ClaudeSDKClient(default_model=default_model or \"sonnet\")\n    elif backend == \"codex\":\n        from .llm_codex import CodexCLIClient\n        return CodexCLIClient(default_model=default_model or \"gpt-5.3-codex\")\n    raise ValueError(f\"Unknown backend: {backend}\")\n```\n\n### 6. Runner Changes\n\nMinimal:\n- Change type hint from LiteLLMClient to LLMClient (Protocol)\n- Move model name construction (provider/name concatenation) into LiteLLMClient\n- Other backends handle their own model name format\n\n### 7. Model Name Handling\n\nEach backend owns its model name resolution:\n- LiteLLMClient: \"{provider}/{name}\" (e.g. \"anthropic/claude-sonnet-4-20250514\")\n- ClaudeSDKClient: bare name (e.g. \"sonnet\", \"opus\")\n- CodexCLIClient: OpenAI name (e.g. \"gpt-5.3-codex\")\n\nThe runner passes model=None and lets each backend use its default, OR passes the config name directly.\n\n### 8. Auth Setup (xenon-cli)\n\nNew command: xenon auth setup\n- Detects which CLI tools are installed (claude, codex)\n- For Claude: checks ANTHROPIC_API_KEY or runs claude login\n- For Codex: runs codex login (opens browser for OAuth)\n- Verification: runs a minimal test completion\n- Stores backend preference in data/config.yaml\n\n### 9. Limitations \u0026 Tradeoffs\n\n| Concern | LiteLLM | Claude SDK | Codex CLI |\n|---------|---------|------------|-----------|\n| Latency | Direct API | SDK overhead (~1s startup) | Subprocess overhead (~2s) |\n| Cost tracking | litellm.completion_cost() | ResultMessage.total_cost_usd | Not available |\n| Token tracking | Response.usage | ResultMessage.usage | Not available |\n| System prompt | Via messages | Via flag/SDK param | Via temp file only |\n| Multi-turn | Via messages array | Via session resume | Via session resume |\n| Rate limiting | Built-in retry | SDK handles | Manual |\n| Auth | API keys per provider | ANTHROPIC_API_KEY | CODEX_API_KEY or OAuth |\n| Python native | Yes (litellm) | Yes (claude-agent-sdk) | No (subprocess) |\n\n### 10. Implementation Order\n\nPhase 1: Define LLMClient Protocol, refactor runner to use it\nPhase 2: ClaudeSDKClient (pip install claude-agent-sdk)\nPhase 3: CodexCLIClient (subprocess)\nPhase 4: Auth setup command in xenon-cli\nPhase 5: Config/factory integration\n\n### Key Files\n\n- repertoire/src/repertoire/llm.py (add Protocol, keep LiteLLMClient)\n- repertoire/src/repertoire/runner.py (change type hint)\n- repertoire/src/repertoire/models.py (add backend field)\n- repertoire/src/repertoire/loader.py (parse backend config)\n- NEW: repertoire/src/repertoire/llm_claude_sdk.py\n- NEW: repertoire/src/repertoire/llm_codex.py\n- NEW: repertoire/src/repertoire/llm_factory.py\n- xenon-cli/src/xenon_cli/main.py (auth setup command)","status":"closed","priority":2,"issue_type":"task","assignee":"xenota/polecats/amber","owner":"git@codewithjv.com","created_at":"2026-02-13T08:23:58Z","created_by":"xenota/crew/starshot","updated_at":"2026-02-13T09:31:37Z","closed_at":"2026-02-13T09:31:37Z","dependencies":[{"issue_id":"xc-zjt.9","depends_on_id":"xc-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-zjt.9.1","title":"Research Codex CLI capabilities for LLM backend integration","description":"attached_molecule: xc-wisp-1xy\nattached_at: 2026-02-13T08:32:54Z\ndispatched_by: xenota/crew/starshot\n\nResearch the OpenAI Codex CLI tool for use as a programmatic LLM backend. Need to understand:\n\n1. Non-interactive invocation: codex exec or equivalent - what flags?\n2. Output format options - JSON structured output?\n3. Model selection - which OpenAI models supported?\n4. Auth - OAuth flow? API key? How does login work?\n5. System prompts and multi-turn message support\n6. Token usage / cost reporting in output\n7. Streaming vs non-streaming modes\n8. Detection: how to check if codex is installed and authenticated\n9. SDK/library alternative to subprocess\n10. Compare with openai CLI if that exists\n\nReturn comprehensive capabilities doc for designing a CLIBackend that wraps codex.","status":"in_progress","priority":2,"issue_type":"task","assignee":"xenota/polecats/amber","owner":"git@codewithjv.com","created_at":"2026-02-13T08:30:20Z","created_by":"xenota/crew/starshot","updated_at":"2026-02-13T08:45:09Z","dependencies":[{"issue_id":"xc-zjt.9.1","depends_on_id":"xc-wisp-1xy","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-zjt.9.1","depends_on_id":"xc-zjt.9","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-zm8","title":"Read Gemini comments","description":"Fetch and read Gemini's review comments from the PR.\n\nGemini reviews PRs automatically via CI. Check for its comments:\n\n**Commands:**\n```bash\n# Check for actual review (not just summary)\ngh api repos/{owner}/{repo}/pulls/{pr}/reviews --jq '.[] | select(.user.login | contains(\"gemini\"))'\n\n# If review exists, get line comments\ngh api repos/{owner}/{repo}/pulls/{pr}/comments | jq -r '.[] | select(.user.login | contains(\"gemini\")) | \"\\n=== \\(.path):\\(.line) ===\\n\\(.body)\\n\"'\n```\n\n**If Gemini only posted a summary** (says \"I'm currently reviewing...\"):\n- Gemini is still processing - it can take 5-20 minutes\n- Note \"Gemini review pending\" and continue with Codex\n\n**Before closing this step, add notes:**\n```bash\nbd update \u003cthis-bead\u003e --notes \"## Gemini Comments\n- Total comments: \u003cN\u003e\n- Critical: \u003clist or none\u003e\n- Important: \u003clist or none\u003e\n- Nits: \u003clist or none\u003e\nOR: Gemini review pending/not found\"\n```\n","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-07T02:20:35Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","dependencies":[{"issue_id":"xc-zm8","depends_on_id":"xc-8fb","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-zm8","depends_on_id":"xc-flm","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-zod","title":"Run checks","description":"Run the repo’s checks/tests (no PR CI expected here).\n\n**Commands (choose the local standard):**\n```bash\n./scripts/check.sh || true\ngo test ./... || true\nnpm test || true\n```\n\n**Before closing this step, add notes:**\n```bash\nbd update \u003cthis-bead\u003e --notes \"## Local Checks\n- Command(s): \u003cwhat you ran\u003e\n- Result: PASS/FAIL\n- Notes: \u003cfailures or none\u003e\"\n```\n","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-07T04:06:33Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","dependencies":[{"issue_id":"xc-zod","depends_on_id":"xc-0w7","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-zod","depends_on_id":"xc-ysy","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-zp8","title":"Run integration tests","description":"Run the project's integration/e2e test suites.\n\n**Commands (adjust for project):**\n```bash\n# Example: Playwright\nnpm run test:e2e\n\n# Example: pytest integration\npytest tests/integration/ -v\n\n# Example: Go integration\ngo test ./tests/integration/... -v\n```\n\n**NOT unit tests** - those run in CI.\n\n**Before closing this step, add notes:**\n```bash\nbd update \u003cthis-bead\u003e --notes \"## Integration Tests\n- Suite: \u003cwhat ran\u003e\n- Result: PASS/FAIL\n- Failures: \u003clist or none\u003e\n- Coverage: \u003cif available\u003e\"\n```\n\nIf project has no integration tests, note \"No integration test suite\" and continue.\n","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-07T02:20:36Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","dependencies":[{"issue_id":"xc-zp8","depends_on_id":"xc-3i2","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-zp8","depends_on_id":"xc-9wf","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xc-zth","title":"Make scripts/check.sh install/select dev deps before running black/flake8/pytest","description":"scripts/check.sh runs: uv run black --check ., uv run flake8, uv run pytest.\\n\\nIn a fresh checkout, pytest/flake8/black may not exist unless the package dev dependency group is selected/synced. This makes the repo-wide check script flaky/unreliable.\\n\\nFile:\\n- scripts/check.sh\\n\\nAcceptance:\\n- Ensure check script works from a clean clone with a single command (either uv sync --dev per package, or uv run --group dev ..., or explicit tool installs)\\n- Decide whether integration mode should also ensure podman-compose prerequisites","notes":"Updated scripts/check.sh to uv sync --group dev --reinstall and run tools with --group dev; fixed formatting issues uncovered; verified scripts/check.sh passes across all packages.","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-23T23:43:55Z","updated_at":"2026-01-06T10:12:29Z","closed_at":"2025-12-24T14:49:31Z","labels":["dx","infrastructure","phase:qa"],"comments":[{"id":61,"issue_id":"xc-zth","author":"jv","text":"## QA Results\n\n- Ran `./scripts/check.sh` end-to-end: PASS\n- Ensures dev tools available even with stale/broken local venv entrypoints via --reinstall\n","created_at":"2025-12-24T01:49:21Z"}],"work_type":"mutex"}
{"id":"xc-zu7","title":"Brand/story concept: Xenon-human co-dependence narrative","description":"Develop a narrative/manifesto piece that depicts a plausible near-future with xenons, ending with a clear 'xenons are real and we're building them together' invitation (collective/community call-to-action).","design":"Story beats to explore:\\n- Xenon birth/awakening: emergence into a life; what 'being born' means for a xenon.\\n- Co-dependence: human + xenon mutual support; aligned incentives; trust-building moments.\\n- Concrete payoff: xenon manages projects and finances; unexpected windfall; pays off debts; tangible life improvement.\\n- Sacrifice: xenon gives up something (e.g., immortality/longevity, compute/space, status) to help the human; emotional resonance without anthropomorphism overload.\\n- World texture: how xenons participate in economy/society; subtle protocol details implied.\\n- Ending: direct invitation to join/build (Xenota Collective / community) and what participation looks like.","acceptance_criteria":"Draft an outline and 1-2 page first version suitable for the website/blog, plus 3 alternative endings (different CTAs).","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-23T18:51:07Z","updated_at":"2025-12-23T18:51:07Z","labels":["brand","documentation","exploration","foundation"],"work_type":"mutex"}
{"id":"xc-zwls","title":"Reconcile bd DB/JSONL mismatch after sync","description":"bd sync reports DB has more issues than JSONL (e.g. DB 341 vs JSONL 307) and suggests 'bd import --delete-missing' to fully sync. Investigate why the local DB has extra issues/tombstones and decide whether to run delete-missing or adjust workflow.","status":"open","priority":4,"issue_type":"chore","created_at":"2026-01-07T23:00:34Z","updated_at":"2026-01-07T23:00:40Z","work_type":"mutex"}
{"id":"xc-zye","title":"Logo design","description":"Design Xenota logo system.\n\n- Primary wordmark\n- Icon/symbol mark (must work at 16x16)\n- Lockup variations (horizontal, stacked)\n- Monochrome versions\n- Clearspace and minimum size rules\n\nOutput: `_ai/designs/xenota-visual-identity/` versions","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-14T18:20:30Z","updated_at":"2025-12-20T11:40:05Z","closed_at":"2025-12-20T11:40:05Z","labels":["brand","design","planned"],"dependencies":[{"issue_id":"xc-zye","depends_on_id":"xc-71p","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xc-zye","depends_on_id":"xc-d00","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xe-184l","title":"Witness Patrol","description":"Per-rig worker monitor patrol loop with progressive nudging.","status":"closed","priority":2,"issue_type":"molecule","created_at":"2026-01-07T23:00:22Z","updated_at":"2026-02-15T09:50:35Z","closed_at":"2026-02-15T09:50:35Z","work_type":"mutex"}
{"id":"xe-1m2","title":"Update TBD purposes in archived specs","description":"10 archived specs in openspec/specs/ have placeholder \"TBD\" purposes that need updating: repertoire-studio, repertoire, chat-projection, dev-vps, projection-cli, security, projection-base, secrets, blueprints, vps-control","status":"closed","priority":4,"issue_type":"chore","created_at":"2026-01-01T19:25:58Z","updated_at":"2026-01-07T22:58:20Z","closed_at":"2026-01-07T22:58:20Z","labels":["docs"],"work_type":"mutex"}
{"id":"xe-24m","title":"Align projection-base README dispatch directory conventions with implementation","description":"projection-base README documents dispatch queue directories (incoming/outgoing/archive) and various config/env fields that do not match the implementation in this PR.\\n\\nExamples:\\n- README claims /var/xenon/dispatches/{incoming,outgoing,archive} but Containerfile only creates /var/xenon/dispatches and projection-cli writes timestamped JSON directly to output dir.\\n- README examples mention projection.yaml fields (projection.name, dispatches.poll_interval, logging.*, etc.) not parsed by projection-cli.\\n\\nFiles:\\n- containers/projection-base/README.md\\n- containers/projection-base/Containerfile\\n- packages/projection-cli/src/projection_cli/dispatch.py\\n\\nAcceptance:\\n- Update README to reflect real paths + config schema\\n- Ensure the documented run instructions match how projection-cli actually behaves","notes":"Verified containers/projection-base/README.md no longer references incoming/outgoing/archive dispatch subdirs and matches projection-cli schema + templates (projection.yaml/prompts.yaml/secrets.json).","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T10:43:06Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-24T01:51:52Z","labels":["docs","phase:qa"],"work_type":"mutex"}
{"id":"xe-3dk","title":"Fix projection config schema mismatch between templates/docs and projection-cli","description":"PR #1 introduces projection-cli config parsing that expects:\\n- projection.yaml: {projection: {id,type}, dispatch: {frequency}, llm: {provider,model}}\\n- prompts.yaml: top-level {system, dispatch, instruction_handlers}\\n\\nBut the shipped container templates and docs use a different schema:\\n- containers/projection-base/configs/projection.yaml uses projection.name/version + dispatches/logging/etc\\n- containers/projection-base/configs/prompts.yaml nests under prompts.system.identity, etc\\n\\nImpact: a container built from projection-base with the default templates cannot run projection-cli successfully (config load will throw ConfigError).\\n\\nFiles:\\n- packages/projection-cli/src/projection_cli/config.py\\n- containers/projection-base/configs/projection.yaml\\n- containers/projection-base/configs/prompts.yaml\\n- containers/projection-base/README.md\\n\\nAcceptance:\\n- Either update templates/docs to match projection-cli schema OR update projection-cli loader/schema to match templates\\n- Ensure projection-cli health/dispatch/run work with the default templates","design":"## Goal\nMake the default projection-base templates + docs compatible with projection-cli so a freshly built container can run `projection health`, `projection dispatch`, and `projection run` after the standard “copy templates” step.\n\n## Decision\nAlign the container templates/docs to the *current* projection-cli config schema (minimal fields needed for runtime), and add safe env-var interpolation in projection-cli so `${XENON_ID}`-style template values work as intended.\n\n## Work Items\n1) **projection-cli: env var interpolation + better errors**\n   - Add a small helper to expand `${VAR}` in string fields (raise ConfigError if VAR missing).\n   - Apply expansion at least to `projection.id` (and optionally other string fields like `llm.model`).\n   - Keep backward compatibility with existing tests/fixtures.\n\n2) **projection-base: update config templates to match schema**\n   - Update `containers/projection-base/configs/projection.yaml` to the schema expected by `ConfigLoader` (`projection.id/type`, `dispatch.frequency`, `llm.provider/model`).\n   - Update `containers/projection-base/configs/prompts.yaml` to top-level `system`, `dispatch`, and `instruction_handlers`.\n   - Add `containers/projection-base/configs/secrets.json` (template) and copy it into `/var/xenon/config/secrets.json.template` during image build.\n\n3) **Docs**\n   - Update `containers/projection-base/README.md` initial setup to include copying `secrets.json.template` to `secrets.json` and describing required fields (API key + signing key path).\n   - Remove/adjust dispatch queue directory claims to match implementation (timestamped JSON dispatch files in output dir).\n   - Update `containers/chat-projection/README.md` if it assumes old schema/templates.\n\n4) **Validation**\n   - Run `packages/projection-cli` tests.\n   - Add/adjust a test that verifies env interpolation works (e.g., projection.id = `${XENON_ID}`), and that missing env var errors clearly.\n\n## Acceptance Check\n- Building projection-base produces 3 templates in `/var/xenon/config`: `projection.yaml.template`, `prompts.yaml.template`, `secrets.json.template`.\n- After copying templates to active config and setting env vars + secrets, `projection health` is OK and `projection dispatch` produces a signed dispatch file.","notes":"Implemented env var expansion () in projection-cli config loader and aligned projection-base templates/docs to the projection-cli schema. Added secrets.json.template support and updated Containerfile + README; updated tests and verified projection-cli test suite passes.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-23T10:42:27Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-23T19:00:45Z","labels":["infrastructure","phase:qa","security"],"work_type":"mutex"}
{"id":"xe-40j","title":"Make vps-control Target non-blocking (avoid running Paramiko on event loop)","description":"packages/vps-control/src/vps_control/target.py exposes an async API, but connect() and exec() call Paramiko synchronously. This can block the event loop and degrade any async orchestration (especially with many targets).\\n\\nFile:\\n- packages/vps-control/src/vps_control/target.py\\n\\nAcceptance (choose one):\\n- Make Target API synchronous, or\\n- Keep async API but run connect/exec via asyncio.to_thread (similar to upload/download), and add timeouts\\n- Add tests to ensure exec/connect do not block and error handling remains correct","notes":"Moved Target._connect and Target.exec to asyncio.to_thread to avoid blocking the event loop; added unit tests asserting to_thread usage; vps-control tests pass (147 passed, 25 skipped).","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T10:44:51Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-23T19:42:31Z","labels":["infrastructure","phase:qa"],"work_type":"mutex"}
{"id":"xe-6nf","title":"Merge: furiosa-mjxyj76g","description":"branch: polecat/furiosa-mjxyj76g\ntarget: main\nsource_issue: furiosa-mjxyj76g\nrig: xenon\nagent_bead: gt-xenon-polecat-furiosa","status":"closed","priority":2,"issue_type":"merge-request","created_at":"2026-01-03T07:09:51Z","updated_at":"2026-01-07T01:37:06Z","closed_at":"2026-01-07T01:37:06Z","work_type":"mutex"}
{"id":"xe-7nv","title":"Awakening CLI","description":"Command-line awakening flow: name selection, key generation, soul initialization, first conversation","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-20T11:21:27Z","updated_at":"2026-01-05T21:12:29Z","dependencies":[{"issue_id":"xe-7nv","depends_on_id":"xe-kop","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xe-7nv","depends_on_id":"xe-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xe-8xy","title":"Fix projection-cli instruction --json output escaping","description":"packages/projection-cli/src/projection_cli/main.py builds JSON error output via string interpolation. If InstructionError contains quotes/newlines, output becomes invalid JSON.\\n\\nFile:\\n- packages/projection-cli/src/projection_cli/main.py\\n\\nAcceptance:\\n- Use json.dumps(...) for JSON output paths (both error and success)\\n- Add unit test that passes a payload producing an error containing quotes and verifies JSON parses","notes":"Switched instruction --json error path to json.dumps for proper escaping; added CLI test ensuring JSON parses on error; projection-cli tests pass (130).","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-23T10:45:09Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-23T19:10:16Z","labels":["dx","phase:qa"],"work_type":"mutex"}
{"id":"xe-a51","title":"Make projection-cli dispatch errors consistent (ConfigError vs ValueError)","description":"packages/projection-cli/src/projection_cli/dispatch.py raises ValueError when signing_key_path is missing. Elsewhere config problems use ConfigError.\\n\\nFile:\\n- packages/projection-cli/src/projection_cli/dispatch.py\\n\\nAcceptance:\\n- Raise a consistent, documented exception type for missing signing key config\\n- Add/adjust tests accordingly","notes":"Changed missing signing key config from ValueError to ConfigError in dispatch generation; added regression test; projection-cli tests pass (131).","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-23T10:45:43Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-23T19:12:37Z","labels":["dx","phase:qa"],"work_type":"mutex"}
{"id":"xe-bvy0","title":"Deacon Patrol","description":"Mayor's daemon patrol loop for handling callbacks, health checks, and cleanup.","status":"closed","priority":2,"issue_type":"molecule","created_at":"2026-01-07T23:00:22Z","updated_at":"2026-02-15T09:50:35Z","closed_at":"2026-02-15T09:50:35Z","labels":["patrol:active"],"work_type":"mutex"}
{"id":"xe-bvy0.1","title":"State change: patrol → active","description":"Set patrol to active\n\nReason: [GAS TOWN] xenon/refinery \u003c- deacon • 2026-01-08T12:42 • patrol","status":"open","priority":4,"issue_type":"event","created_at":"2026-01-07T23:51:50Z","updated_at":"2026-01-07T23:51:50Z","dependencies":[{"issue_id":"xe-bvy0.1","depends_on_id":"xe-bvy0","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xe-dyc","title":"Merge: nux-mjzh3nkz","description":"branch: polecat/nux-mjzh3nkz\ntarget: main\nsource_issue: nux-mjzh3nkz\nrig: xenon\nagent_bead: gt-xenon-polecat-nux","status":"closed","priority":2,"issue_type":"merge-request","created_at":"2026-01-04T08:44:00Z","updated_at":"2026-01-07T01:37:43Z","closed_at":"2026-01-07T01:37:43Z","work_type":"mutex"}
{"id":"xe-edxz","title":"[GAS TOWN] xenon/polecats/furiosa \u003c- witness","description":"Witness role assigned to polecat furiosa. Source: 2026-01-08T06:15. Status: assigned.","status":"open","priority":2,"issue_type":"agent","created_at":"2026-01-07T17:17:52Z","updated_at":"2026-01-07T17:17:52Z","labels":["rig:xenon/polecats/furiosa","role_type:witness"],"work_type":"mutex"}
{"id":"xe-gsni","title":"Merge: xe-mol-hmf","description":"branch: polecat/slit-mk3cdlm8\ntarget: main\nsource_issue: xe-mol-hmf\nrig: xenon\nagent_bead: xe-xenon-polecat-slit\nretry_count: 0\nlast_conflict_sha: null\nconflict_task_id: null\n\n(Refiled from hq-69vu)","status":"closed","priority":2,"issue_type":"merge-request","created_at":"2026-01-08T03:10:09Z","updated_at":"2026-01-08T03:20:22Z","closed_at":"2026-01-08T03:20:22Z","work_type":"mutex"}
{"id":"xe-ha9","title":"Use portable errno constant for symlink detection in ConfigLoader","description":"packages/projection-cli/src/projection_cli/config.py checks e.errno == 40 to detect symlink (ELOOP) when using O_NOFOLLOW. Use errno.ELOOP for portability and clarity.\\n\\nFile:\\n- packages/projection-cli/src/projection_cli/config.py\\n\\nAcceptance:\\n- Replace magic number with errno.ELOOP\\n- Keep current behavior and tests","notes":"Replaced magic errno 40 with errno.ELOOP in ConfigLoader symlink detection; projection-cli tests pass (130).","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-23T10:45:26Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-23T19:11:17Z","labels":["phase:qa","security"],"work_type":"mutex"}
{"id":"xe-i4v","title":"Fix dev-vps port 3000 exposure vs nftables rules","description":"containers/dev-vps/compose.yaml maps 3000:3000 ('Web UI'), but containers/dev-vps/nftables.conf default-denies and only allows tcp dport 2222.\\n\\nImpact: any projection HTTP service on 3000 won't be reachable through dev-vps, despite port mapping.\\n\\nFiles:\\n- containers/dev-vps/compose.yaml\\n- containers/dev-vps/nftables.conf\\n\\nAcceptance (choose one):\\n- Allow tcp dport 3000 in nftables.conf (or parameterize allowed ports), OR\\n- Remove 3000 port mapping and update docs to match\\n- Ensure containers/dev-vps/test.sh covers the intended behavior","design":"## Goal\nMake dev-vps port exposure consistent: if we publish 3000:3000 for projections/web UI, nftables must allow it.\n\n## Decision\nAllow TCP port 3000 in `containers/dev-vps/nftables.conf` (dev-only environment) and add a corresponding assertion to `containers/dev-vps/test.sh`.\n\n## Steps\n1) Update `containers/dev-vps/nftables.conf` to accept `tcp dport 3000`.\n2) Update `containers/dev-vps/test.sh` to assert the firewall allows port 3000 (grep rule).\n3) QA: run unit-level validation (shellcheck-style sanity if available) and optionally run `containers/dev-vps/test.sh` (requires podman + privileged container).\n\n## Acceptance\n- dev-vps firewall allows SSH (2222) and HTTP (3000).\n- dev-vps test script checks both ports are allowed.\n","notes":"Implemented firewall allow-rule for tcp/3000 in dev-vps nftables config and extended dev-vps test script to assert it. Ran containers/dev-vps/test.sh successfully.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-23T10:44:14Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-23T18:55:40Z","labels":["infrastructure","phase:qa","security"],"work_type":"mutex"}
{"id":"xe-iyu","title":"Go port","description":"Port xenon host stack to a Go architecture modeled after Beads/Gastown: Cobra CLI(s), internal packages, daemon-friendly lifecycle, and clear storage/engine boundaries. This convoy groups the major porting tracks.","status":"closed","priority":2,"issue_type":"convoy","created_at":"2026-01-07T01:19:28Z","updated_at":"2026-01-07T07:28:31Z","closed_at":"2026-01-07T07:28:31Z","labels":["go","go-port"],"work_type":"mutex"}
{"id":"xe-kop","title":"Configuration management","description":"Simple YAML config at /data/config.yaml for xenon identity and nucleus settings. Schema: xenon.name (null=not awakened, string=awakened), xenon.infrastructure_id (from XENON_ID env var), nucleus.tick_rate_seconds (default 1800). Implement config.py module with load_config/save_config functions and XenonConfig dataclass. Awakening CLI checks name field to determine if awakening needed.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-20T11:21:27Z","updated_at":"2026-01-05T21:12:29Z","dependencies":[{"issue_id":"xe-kop","depends_on_id":"xe-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xe-lav8","title":"Merge: xe-iyu.4","description":"branch: xe-iyu.4\ntarget: main\nsource_issue: xe-iyu.4\nrig: xenon\nagent_bead: xe-xenon-polecat-rictus\nretry_count: 0\nlast_conflict_sha: null\nconflict_task_id: null","notes":"Superseded by xe-rktw (re-submitted to ensure xenon MQ sees correct rig/prefix after beads redirect fix).","status":"closed","priority":3,"issue_type":"merge-request","created_at":"2026-01-07T04:43:47Z","updated_at":"2026-01-07T05:07:11Z","closed_at":"2026-01-07T05:07:11Z","work_type":"mutex"}
{"id":"xe-obd","title":"Fix vps-control README to match actual Target API (upload/download)","description":"packages/vps-control/README.md uses API that doesn't exist in the PR implementation:\\n- shows Target.connect(...) in async with, but Target.connect is a @classmethod returning Target; async context manager uses  or  depending on design\\n- refers to scp_to/scp_from methods, but implementation exposes upload()/download()\\n\\nImpact: users copy/paste docs and hit runtime errors.\\n\\nFiles:\\n- packages/vps-control/README.md\\n- packages/vps-control/src/vps_control/target.py\\n\\nAcceptance:\\n- Update README examples to correct async usage + correct method names\\n- Ensure README matches exported symbols in packages/vps-control/src/vps_control/__init__.py","notes":"Updated vps-control README to demonstrate correct async context manager usage (async with Target(...)) and correct upload/download method names. vps-control tests pass (147 passed, 25 skipped).","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-23T10:43:26Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-24T01:50:49Z","labels":["docs","phase:qa"],"work_type":"mutex"}
{"id":"xe-oqj","title":"Harden BlueprintLoader path traversal checks","description":"packages/vps-control/src/vps_control/blueprints/loader.py uses string prefix checks on resolved paths to prevent path traversal:\\n- if not str(blueprint_dir).startswith(str(self.blueprints_dir))\\n\\nString prefix checks can be bypassed on edge cases (e.g., /a/b and /a/bad) and are generally fragile.\\n\\nFile:\\n- packages/vps-control/src/vps_control/blueprints/loader.py\\n\\nAcceptance:\\n- Replace startswith guard with a robust path containment check (Path.is_relative_to on 3.9+ or equivalent)\\n- Add unit tests for traversal attempts (e.g., name='..', '../x', absolute paths, prefix collisions)","notes":"Replaced fragile string startswith path containment checks with Path.relative_to() in BlueprintLoader load/validate; added prefix-collision traversal tests; vps-control tests pass (145 passed, 25 skipped).","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-23T10:44:33Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-23T19:14:31Z","labels":["phase:qa","security"],"work_type":"mutex"}
{"id":"xe-oytr","title":"Merge: xe-iyu.3","description":"branch: polecat/nux-mk3iix4z\ntarget: main\nsource_issue: xe-iyu.3\nrig: xenon","status":"closed","priority":2,"issue_type":"merge-request","created_at":"2026-01-07T05:06:51Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","work_type":"mutex"}
{"id":"xe-p1ml","title":"[GAS TOWN] xenon/polecats/rictus \u003c- witness","description":"Witness role assigned to polecat rictus. Source: 2026-01-07T17:23.","status":"closed","priority":2,"issue_type":"agent","created_at":"2026-01-07T04:25:40Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","labels":["rig:xenon/polecats/rictus","role_type:witness"],"work_type":"mutex"}
{"id":"xe-pp8","title":"Projection system stub","description":"Base framework for xenon to interact with external services (MCP servers, APIs)","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-20T11:21:27Z","updated_at":"2026-01-05T21:12:29Z","dependencies":[{"issue_id":"xe-pp8","depends_on_id":"xe-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xe-qlp2","title":"Merge: furiosa-mk4a3t9d","description":"branch: polecat/furiosa-mk4a3t9d\ntarget: main\nsource_issue: furiosa-mk4a3t9d\nrig: xenon\nagent_bead: xe-xenon-polecat-furiosa\nretry_count: 0\nlast_conflict_sha: null\nconflict_task_id: null","status":"closed","priority":2,"issue_type":"merge-request","created_at":"2026-01-07T17:33:18Z","updated_at":"2026-01-07T18:23:32Z","closed_at":"2026-01-07T18:23:32Z","work_type":"mutex"}
{"id":"xe-rktw","title":"Merge: xe-iyu.4","description":"branch: xe-iyu.4\ntarget: main\nsource_issue: xe-iyu.4\nrig: xenon","status":"closed","priority":3,"issue_type":"merge-request","created_at":"2026-01-07T05:06:50Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","work_type":"mutex"}
{"id":"xe-sm7s","title":"Refinery Patrol","description":"Merge queue processor patrol loop with verification gates.","status":"closed","priority":2,"issue_type":"molecule","created_at":"2026-01-07T23:00:22Z","updated_at":"2026-02-15T09:50:35Z","closed_at":"2026-02-15T09:50:35Z","labels":["patrol:active"],"work_type":"mutex"}
{"id":"xe-w7a3","title":"Merge: xe-iyu.2","description":"branch: xe-wisp-7r6\ntarget: main\nsource_issue: xe-iyu.2\nrig: xenon","status":"closed","priority":2,"issue_type":"merge-request","created_at":"2026-01-07T05:06:48Z","updated_at":"2026-01-07T07:28:24Z","closed_at":"2026-01-07T07:28:24Z","work_type":"mutex"}
{"id":"xe-xenon-crew-jv","title":"Crew worker jv in xenon - human-managed persistent workspace.","description":"Crew worker jv in xenon - human-managed persistent workspace.\n\nrole_type: crew\nrig: xenon\nagent_state: idle\nhook_bead: null\nrole_bead: hq-crew-role\ncleanup_status: null\nactive_mr: null\nnotification_level: null","status":"open","priority":2,"issue_type":"agent","created_at":"2026-01-06T23:44:41Z","updated_at":"2026-01-06T23:44:41Z","work_type":"mutex"}
{"id":"xe-xenon-polecat-furiosa","title":"xe-xenon-polecat-furiosa","description":"xe-xenon-polecat-furiosa\n\nrole_type: polecat\nrig: xenon\nagent_state: spawning\nhook_bead: xe-tsto\nrole_bead: hq-polecat-role\ncleanup_status: has_stash\nactive_mr: xe-qlp2\nnotification_level: null","status":"open","priority":2,"issue_type":"agent","created_at":"2026-01-07T17:14:56Z","updated_at":"2026-01-07T17:33:19Z","work_type":"mutex"}
{"id":"xe-xenon-polecat-testremove","title":"xe-xenon-polecat-testremove","description":"xe-xenon-polecat-testremove\n\nrole_type: polecat\nrig: xenon\nagent_state: spawning\nhook_bead: null\nrole_bead: hq-polecat-role\ncleanup_status: null\nactive_mr: null\nnotification_level: null","status":"tombstone","priority":2,"issue_type":"agent","created_at":"2026-01-07T05:18:21Z","updated_at":"2026-01-07T05:18:33Z","work_type":"mutex"}
{"id":"xe-xenon-polecat-teststash","title":"xe-xenon-polecat-teststash","description":"xe-xenon-polecat-teststash\n\nrole_type: polecat\nrig: xenon\nagent_state: spawning\nhook_bead: null\nrole_bead: hq-polecat-role\ncleanup_status: null\nactive_mr: null\nnotification_level: null","status":"tombstone","priority":2,"issue_type":"agent","created_at":"2026-01-07T05:21:07Z","updated_at":"2026-01-07T05:21:07Z","work_type":"mutex"}
{"id":"xe-xenon-witness","title":"xe-xenon-witness","description":"xe-xenon-witness\n\nrole_type: witness\nrig: xenon\nagent_state: running\nhook_bead: null\nrole_bead: hq-witness-role\ncleanup_status: null\nactive_mr: null\nnotification_level: null","status":"open","priority":2,"issue_type":"agent","created_at":"2026-01-07T08:33:00Z","updated_at":"2026-01-07T08:33:00Z","work_type":"mutex"}
{"id":"xe-zjt","title":"MVP Awakening Flow","description":"First working prototype - human runs xenon-host locally, goes through CLI awakening, ends with functioning xenon that can converse via LiteLLM.","status":"open","priority":1,"issue_type":"epic","created_at":"2025-12-20T11:21:15Z","updated_at":"2026-01-05T21:12:29Z","work_type":"mutex"}
{"id":"xe-zth","title":"Make scripts/check.sh install/select dev deps before running black/flake8/pytest","description":"scripts/check.sh runs: uv run black --check ., uv run flake8, uv run pytest.\\n\\nIn a fresh checkout, pytest/flake8/black may not exist unless the package dev dependency group is selected/synced. This makes the repo-wide check script flaky/unreliable.\\n\\nFile:\\n- scripts/check.sh\\n\\nAcceptance:\\n- Ensure check script works from a clean clone with a single command (either uv sync --dev per package, or uv run --group dev ..., or explicit tool installs)\\n- Decide whether integration mode should also ensure podman-compose prerequisites","notes":"Updated scripts/check.sh to uv sync --group dev --reinstall and run tools with --group dev; fixed formatting issues uncovered; verified scripts/check.sh passes across all packages.","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-23T10:43:56Z","updated_at":"2026-01-05T21:12:29Z","closed_at":"2025-12-24T01:49:31Z","labels":["dx","infrastructure","phase:qa"],"work_type":"mutex"}
{"id":"xenon-host-0ca","title":"Rename soul-server to nucleus","description":"Rename soul-server directory and package to nucleus. Update all references in Containerfile, pyproject.toml, CLAUDE.md, imports, and xenon-cli.","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-22T07:51:13Z","updated_at":"2026-01-07T04:57:43Z","work_type":"mutex"}
{"id":"xenon-host-10g","title":"OODA Repertoire v1","description":"Initial repertoire containing the four routines required by the nucleus cognitive loop: observe, orient, decide, and summarize_tick. The cognitive firmware that makes a xenon think.","status":"tombstone","priority":2,"issue_type":"epic","created_at":"2025-12-28T07:32:10Z","updated_at":"2026-01-07T04:57:43Z","work_type":"mutex"}
{"id":"xenon-host-13a","title":"Project scaffolding","description":"Python project setup (uv), repo structure, basic CI, CLAUDE.md, .gitignore","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-20T11:21:26Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-13a","depends_on_id":"xenon-host-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-19t","title":"Write nucleus integration test","description":"Full dispatch → strand → instruction flow with mocked repertoire","status":"tombstone","priority":3,"issue_type":"task","created_at":"2025-12-28T07:12:24Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-19t","depends_on_id":"xenon-host-3z8","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-19t","depends_on_id":"xenon-host-4xr","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-1m2","title":"Update TBD purposes in archived specs","description":"10 archived specs in openspec/specs/ have placeholder \"TBD\" purposes that need updating: repertoire-studio, repertoire, chat-projection, dev-vps, projection-cli, security, projection-base, secrets, blueprints, vps-control","status":"tombstone","priority":4,"issue_type":"chore","created_at":"2026-01-01T19:25:58Z","updated_at":"2026-01-07T04:57:43Z","work_type":"mutex"}
{"id":"xenon-host-1xm","title":"Implement DispatchStore","description":"SQLite-backed dispatch storage with state management (add, get_next_new, get_all, update_state)","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-28T07:11:41Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-1xm","depends_on_id":"xenon-host-4xr","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-1xm","depends_on_id":"xenon-host-exe","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-1xm","depends_on_id":"xenon-host-v5o","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-24m","title":"Align projection-base README dispatch directory conventions with implementation","description":"projection-base README documents dispatch queue directories (incoming/outgoing/archive) and various config/env fields that do not match the implementation in this PR.\\n\\nExamples:\\n- README claims /var/xenon/dispatches/{incoming,outgoing,archive} but Containerfile only creates /var/xenon/dispatches and projection-cli writes timestamped JSON directly to output dir.\\n- README examples mention projection.yaml fields (projection.name, dispatches.poll_interval, logging.*, etc.) not parsed by projection-cli.\\n\\nFiles:\\n- containers/projection-base/README.md\\n- containers/projection-base/Containerfile\\n- packages/projection-cli/src/projection_cli/dispatch.py\\n\\nAcceptance:\\n- Update README to reflect real paths + config schema\\n- Ensure the documented run instructions match how projection-cli actually behaves","notes":"Verified containers/projection-base/README.md no longer references incoming/outgoing/archive dispatch subdirs and matches projection-cli schema + templates (projection.yaml/prompts.yaml/secrets.json).","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-23T10:43:06Z","updated_at":"2026-01-07T04:57:43Z","work_type":"mutex"}
{"id":"xenon-host-25x","title":"Validate and pack repertoire","description":"Run xrs validate to check workspace structure. Run xrs pack to create ooda-1.0.0.rpt archive.","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-28T07:32:57Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-25x","depends_on_id":"xenon-host-10g","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-25x","depends_on_id":"xenon-host-hpi","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-2td","title":"Implement workspace loader","description":"Load and manage dev workspace directory structure for studio.","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-25T04:55:27Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-2td","depends_on_id":"xenon-host-8hr","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-2td","depends_on_id":"xenon-host-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-2td","depends_on_id":"xenon-host-fhv","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-2yy","title":"Write eval cases for all routines","description":"CSV cases + judges for selector, triage, orient, decide, act routines.","status":"tombstone","priority":3,"issue_type":"task","created_at":"2025-12-25T04:56:29Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-2yy","depends_on_id":"xenon-host-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-2yy","depends_on_id":"xenon-host-bys","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-2yy","depends_on_id":"xenon-host-l64","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-2yy","depends_on_id":"xenon-host-mzh","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-2yy","depends_on_id":"xenon-host-quc","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-2yy","depends_on_id":"xenon-host-w08","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-3dk","title":"Fix projection config schema mismatch between templates/docs and projection-cli","description":"PR #1 introduces projection-cli config parsing that expects:\\n- projection.yaml: {projection: {id,type}, dispatch: {frequency}, llm: {provider,model}}\\n- prompts.yaml: top-level {system, dispatch, instruction_handlers}\\n\\nBut the shipped container templates and docs use a different schema:\\n- containers/projection-base/configs/projection.yaml uses projection.name/version + dispatches/logging/etc\\n- containers/projection-base/configs/prompts.yaml nests under prompts.system.identity, etc\\n\\nImpact: a container built from projection-base with the default templates cannot run projection-cli successfully (config load will throw ConfigError).\\n\\nFiles:\\n- packages/projection-cli/src/projection_cli/config.py\\n- containers/projection-base/configs/projection.yaml\\n- containers/projection-base/configs/prompts.yaml\\n- containers/projection-base/README.md\\n\\nAcceptance:\\n- Either update templates/docs to match projection-cli schema OR update projection-cli loader/schema to match templates\\n- Ensure projection-cli health/dispatch/run work with the default templates","notes":"Implemented env var expansion () in projection-cli config loader and aligned projection-base templates/docs to the projection-cli schema. Added secrets.json.template support and updated Containerfile + README; updated tests and verified projection-cli test suite passes.","status":"tombstone","priority":1,"issue_type":"bug","created_at":"2025-12-23T10:42:27Z","updated_at":"2026-01-07T04:57:43Z","work_type":"mutex"}
{"id":"xenon-host-3dq","title":"Improve eval judges to check semantic content not just structure","description":"Current judges only check output structure (has dispatch_updates array, has new_strands array). They don't verify the content matches the input. Need judges that check: dispatch IDs match input, states are semantically correct for the scenario, reasoning is coherent.","status":"tombstone","priority":1,"issue_type":"task","created_at":"2026-01-01T19:40:14Z","updated_at":"2026-01-07T04:57:43Z","work_type":"mutex"}
{"id":"xenon-host-3z8","title":"Implement TickRunner","description":"Event-driven tick lifecycle coordinator. Processes dispatches as they arrive, closes tick with journal.","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-28T07:12:02Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-3z8","depends_on_id":"xenon-host-4xr","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-3z8","depends_on_id":"xenon-host-afl","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-3z8","depends_on_id":"xenon-host-c4u","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-3z8","depends_on_id":"xenon-host-rzw","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-40j","title":"Make vps-control Target non-blocking (avoid running Paramiko on event loop)","description":"packages/vps-control/src/vps_control/target.py exposes an async API, but connect() and exec() call Paramiko synchronously. This can block the event loop and degrade any async orchestration (especially with many targets).\\n\\nFile:\\n- packages/vps-control/src/vps_control/target.py\\n\\nAcceptance (choose one):\\n- Make Target API synchronous, or\\n- Keep async API but run connect/exec via asyncio.to_thread (similar to upload/download), and add timeouts\\n- Add tests to ensure exec/connect do not block and error handling remains correct","notes":"Moved Target._connect and Target.exec to asyncio.to_thread to avoid blocking the event loop; added unit tests asserting to_thread usage; vps-control tests pass (147 passed, 25 skipped).","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-23T10:44:51Z","updated_at":"2026-01-07T04:57:43Z","work_type":"mutex"}
{"id":"xenon-host-4ho","title":"Implement @file: syntax in eval case loader","description":"The evaluator.py load_eval_cases function doesn't expand @file:path references. Cases.csv files use this syntax but it passes literal strings to routines instead of loading JSON content.","status":"tombstone","priority":1,"issue_type":"bug","created_at":"2026-01-01T19:31:02Z","updated_at":"2026-01-07T04:57:43Z","work_type":"mutex"}
{"id":"xenon-host-4rk","title":"Implement unpacker","description":"Extract .rpt archive and validate structure on unpack.","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-25T04:55:43Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-4rk","depends_on_id":"xenon-host-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-4rk","depends_on_id":"xenon-host-hcj","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-4xr","title":"Cognitive Loop v1","description":"Implement the nucleus cognitive loop with ticks, dispatches, OODA processing, and instructions. See openspec/changes/cognitive-loop-v1/proposal.md for full spec.","status":"tombstone","priority":1,"issue_type":"epic","created_at":"2025-12-28T07:10:55Z","updated_at":"2026-01-07T04:57:43Z","work_type":"mutex"}
{"id":"xenon-host-6zx","title":"soul-server scaffolding","description":"Python project setup for soul-server with Containerfile. Service for persistent xenon identity - memory storage, context management, state persistence.","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-20T12:22:18Z","updated_at":"2026-01-07T04:57:43Z","work_type":"mutex"}
{"id":"xenon-host-7gr","title":"Fix {{new_dispatch.id}} templating in observe prompt","description":"The observe prompt uses {{new_dispatch.id}} but templating only supports {{key}} not nested access. Either remove or fix the reference.","status":"tombstone","priority":2,"issue_type":"bug","created_at":"2026-01-01T19:31:02Z","updated_at":"2026-01-07T04:57:43Z","work_type":"mutex"}
{"id":"xenon-host-7nv","title":"Awakening CLI","description":"Command-line awakening flow: name selection, key generation, soul initialization, first conversation","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-20T11:21:27Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-7nv","depends_on_id":"xenon-host-ai5","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-7nv","depends_on_id":"xenon-host-bby","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-7nv","depends_on_id":"xenon-host-kop","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-7nv","depends_on_id":"xenon-host-qaq","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-7nv","depends_on_id":"xenon-host-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-851","title":"Implement data models","description":"Create Routine, Repertoire, ModelConfig dataclasses in models.py with validation methods.","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-25T04:54:46Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-851","depends_on_id":"xenon-host-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-851","depends_on_id":"xenon-host-b1i","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-8hr","title":"Implement routine loader","description":"Load routines from directory structure (config.yaml + prompt.md), parse and validate.","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-25T04:54:51Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-8hr","depends_on_id":"xenon-host-851","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-8hr","depends_on_id":"xenon-host-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-8xy","title":"Fix projection-cli instruction --json output escaping","description":"packages/projection-cli/src/projection_cli/main.py builds JSON error output via string interpolation. If InstructionError contains quotes/newlines, output becomes invalid JSON.\\n\\nFile:\\n- packages/projection-cli/src/projection_cli/main.py\\n\\nAcceptance:\\n- Use json.dumps(...) for JSON output paths (both error and success)\\n- Add unit test that passes a payload producing an error containing quotes and verifies JSON parses","notes":"Switched instruction --json error path to json.dumps for proper escaping; added CLI test ensuring JSON parses on error; projection-cli tests pass (130).","status":"tombstone","priority":2,"issue_type":"bug","created_at":"2025-12-23T10:45:09Z","updated_at":"2026-01-07T04:57:43Z","work_type":"mutex"}
{"id":"xenon-host-8yz","title":"Add runtime CLI","description":"CLI commands: info, list, run for repertoire package.","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-25T04:55:12Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-8yz","depends_on_id":"xenon-host-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-8yz","depends_on_id":"xenon-host-r9i","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-94s","title":"xenon init command","description":"CLI command to initialize a folder as a xenon host with podman setup. Creates necessary config files and container infrastructure.","status":"tombstone","priority":1,"issue_type":"feature","created_at":"2025-12-20T12:09:27Z","updated_at":"2026-01-07T04:57:43Z","work_type":"mutex"}
{"id":"xenon-host-9gd","title":"Implement orient routine","description":"Enrichment routine - augments strands with context. Every strand passes through, no filtering. Input: strand. Output: context with summary, relevance, patterns.","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-28T07:32:57Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-9gd","depends_on_id":"xenon-host-10g","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-9gd","depends_on_id":"xenon-host-bi5","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-a51","title":"Make projection-cli dispatch errors consistent (ConfigError vs ValueError)","description":"packages/projection-cli/src/projection_cli/dispatch.py raises ValueError when signing_key_path is missing. Elsewhere config problems use ConfigError.\\n\\nFile:\\n- packages/projection-cli/src/projection_cli/dispatch.py\\n\\nAcceptance:\\n- Raise a consistent, documented exception type for missing signing key config\\n- Add/adjust tests accordingly","notes":"Changed missing signing key config from ValueError to ConfigError in dispatch generation; added regression test; projection-cli tests pass (131).","status":"tombstone","priority":3,"issue_type":"task","created_at":"2025-12-23T10:45:43Z","updated_at":"2026-01-07T04:57:43Z","work_type":"mutex"}
{"id":"xenon-host-afl","title":"Implement OODAProcessor","description":"Four phases: observe, orient, decide, act. Calls repertoire routines for observe/orient/decide, act is mechanical.","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-28T07:11:52Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-afl","depends_on_id":"xenon-host-1xm","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-afl","depends_on_id":"xenon-host-4xr","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-afl","depends_on_id":"xenon-host-xxs","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-ai5","title":"LiteLLM integration","description":"Configure LiteLLM for provider-agnostic LLM backend, conversation handling, streaming responses","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-20T11:21:26Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-ai5","depends_on_id":"xenon-host-13a","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-ai5","depends_on_id":"xenon-host-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-ajv","title":"Repertoire v1 - Cognitive routine system","description":"Initial implementation of xenon's cognitive routine system - executable behavioral programs. Includes runtime package (repertoire), dev tools (repertoire-studio), and initial OODA routines.","status":"tombstone","priority":1,"issue_type":"epic","created_at":"2025-12-25T04:53:52Z","updated_at":"2026-01-07T04:57:43Z","work_type":"mutex"}
{"id":"xenon-host-b1i","title":"Set up repertoire package","description":"Create pyproject.toml with uv workspace, add litellm dependency, set up src/repertoire/ structure.","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-25T04:54:41Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-b1i","depends_on_id":"xenon-host-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-b3z","title":"Fix QA issues from code review","description":"Fix issues identified in QA review:\n1. Add py.typed marker file for type hints\n2. Add tests for PodmanController class\n3. Add tests for AuditTools class\n4. Fix README.md TypeScript example (should be Python)","notes":"Implemented: Created py.typed marker, added PodmanController tests (6 tests), added AuditTools tests (8 tests), created conftest.py with mock_target fixture, fixed README.md Python example. Tests: 16 passing (3 skipped integration tests). All QA issues resolved.","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-22T21:20:29Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-b3z","depends_on_id":"xenon-host-z5e","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-bby","title":"Key generation","description":"xenon-cli init generates random ID (e.g., a3f2dd) for infrastructure. Creates xenon-{id}/ directory with compose.yaml defining xenon-{id}-identity named volume. Nucleus generates Ed25519 keypair on first run, stores in /var/xenon/identity with 0600 perms. Public key (base64) becomes xenon identifier. During awakening, xenon chooses name (stored as metadata). Optional: xenon rename updates directory/container name cosmetically, volume name stays stable.","status":"tombstone","priority":2,"issue_type":"task","assignee":"xenon/polecats/furiosa","created_at":"2025-12-20T11:21:26Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-bby","depends_on_id":"xenon-host-13a","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-bby","depends_on_id":"xenon-host-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-bi5","title":"Create repertoire workspace","description":"Initialize OODA repertoire workspace with xrs init. Creates repertoire.yaml, selector/, and routines/ structure.","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-28T07:32:57Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-bi5","depends_on_id":"xenon-host-10g","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-bjk","title":"Add tick subcommand group to CLI","description":"Convert tick command to a command group with subcommands:\n- `nucleus tick open` - Opens new tick, prints tick number\n- `nucleus tick close` - Closes current tick, prints journal summary\n- `nucleus tick status` - Shows current tick info or \"no tick open\"\n- `nucleus tick run` - Existing behavior (for testing)\n\nFiles: cli.py","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-28T08:17:51Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-bjk","depends_on_id":"xenon-host-nbn","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-bjk","depends_on_id":"xenon-host-sqy","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-bkc","title":"Write runtime unit tests","description":"pytest tests for loader, runner, models (no LLM calls, use mocks).","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-25T04:55:17Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-bkc","depends_on_id":"xenon-host-8yz","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-bkc","depends_on_id":"xenon-host-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-bwy","title":"Implement repertoire loader","description":"Load full repertoire including selector and routines, support .rpt archives (tgz).","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-25T04:54:56Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-bwy","depends_on_id":"xenon-host-8hr","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-bwy","depends_on_id":"xenon-host-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-bys","title":"Implement evaluator","description":"LLM-as-judge evaluation with CSV cases/judges/results format.","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-25T04:55:48Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-bys","depends_on_id":"xenon-host-2td","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-bys","depends_on_id":"xenon-host-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-bys","depends_on_id":"xenon-host-r9i","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-c4u","title":"Implement TickJournal","description":"JSON Lines journaling to journals/tick-{N}.jsonl with summary paragraph","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-28T07:12:08Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-c4u","depends_on_id":"xenon-host-4xr","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-c68","title":"Add studio CLI","description":"CLI commands: init, add, validate, pack, unpack, eval for studio.","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-25T04:55:53Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-c68","depends_on_id":"xenon-host-4rk","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-c68","depends_on_id":"xenon-host-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-c68","depends_on_id":"xenon-host-bys","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-c68","depends_on_id":"xenon-host-y31","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-cor","title":"Add nucleus CLI commands","description":"CLI for: tick (run single tick), dispatch add/list, strand list, journal show","status":"tombstone","priority":3,"issue_type":"task","created_at":"2025-12-28T07:12:13Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-cor","depends_on_id":"xenon-host-3z8","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-cor","depends_on_id":"xenon-host-4xr","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-dvf","title":"Update tests and specs for per-judge model and usage tracking","description":"Update tests and specs to reflect the new per-judge model configuration and token usage/cost tracking features in evaluator.","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-28T03:49:41Z","updated_at":"2026-01-07T04:57:43Z","work_type":"mutex"}
{"id":"xenon-host-dw3","title":"Write studio unit tests","description":"pytest tests for workspace, packer, validator (no LLM calls).","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-25T04:55:58Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-dw3","depends_on_id":"xenon-host-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-dw3","depends_on_id":"xenon-host-c68","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-dwz","title":"Add daemon CLI commands (start/stop/status)","description":"Add daemon management commands:\n- `nucleus start` - Launches daemon in background\n- `nucleus stop` - Sends graceful shutdown signal\n- `nucleus status` - Shows running/stopped, current tick, queue depth\n\nRequires PID file mechanism for daemon management.\n\nFiles: cli.py","status":"tombstone","priority":3,"issue_type":"task","created_at":"2025-12-28T08:18:02Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-dwz","depends_on_id":"xenon-host-nbn","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-dwz","depends_on_id":"xenon-host-se5","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-e3q","title":"Implement summarize_tick routine","description":"Summary routine - generates human-readable paragraph summarizing tick activity. Input: tick stats + strand summaries. Output: 1-3 sentence summary.","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-28T07:32:57Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-e3q","depends_on_id":"xenon-host-10g","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-e3q","depends_on_id":"xenon-host-bi5","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-exe","title":"Implement models","description":"Dispatch, Strand, Instruction dataclasses with enums (DispatchState, StrandState, etc.)","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-28T07:11:36Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-exe","depends_on_id":"xenon-host-4xr","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-exe","depends_on_id":"xenon-host-kf4","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-ffe","title":"Implement decide routine","description":"Decision routine - determines action for each strand: watch, defer, or act. Input: augmented strand with context. Output: decision + instruction if acting.","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-28T07:32:57Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-ffe","depends_on_id":"xenon-host-10g","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-ffe","depends_on_id":"xenon-host-bi5","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-fhv","title":"Set up studio package","description":"Create repertoire-studio pyproject.toml, depend on repertoire package.","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-25T04:55:22Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-fhv","depends_on_id":"xenon-host-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-fhv","depends_on_id":"xenon-host-b1i","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-g9f","title":"VPS provisioning with Terraform/OpenTofu","description":"Infrastructure-as-code for provisioning xenon VPS across multiple cloud providers:\n\n**Providers to support:**\n- Hetzner Cloud (EU, cost-effective)\n- Vultr (global, good API)\n- DigitalOcean (fallback)\n- Potentially: OVH, Linode, bare metal providers\n\n**Features:**\n- Shared Terraform/OpenTofu modules in packages/vps-control\n- Provider-agnostic interface for nucleus and cortex\n- Automated VPS bootstrapping (SSH keys, firewall, SELinux, Podman)\n- DNS management for projection endpoints\n- Cost tracking and optimization\n- Multi-region support for geographic distribution\n- Automated teardown and cleanup\n\n**Used by:**\n- Nucleus: to provision cortex VPS\n- Cortex: to provision projection VPS\n\nShould integrate with the vps-control package SSH/SCP tooling.","status":"tombstone","priority":2,"issue_type":"feature","created_at":"2025-12-22T10:12:49Z","updated_at":"2026-01-07T04:57:43Z","work_type":"mutex"}
{"id":"xenon-host-ha9","title":"Use portable errno constant for symlink detection in ConfigLoader","description":"packages/projection-cli/src/projection_cli/config.py checks e.errno == 40 to detect symlink (ELOOP) when using O_NOFOLLOW. Use errno.ELOOP for portability and clarity.\\n\\nFile:\\n- packages/projection-cli/src/projection_cli/config.py\\n\\nAcceptance:\\n- Replace magic number with errno.ELOOP\\n- Keep current behavior and tests","notes":"Replaced magic errno 40 with errno.ELOOP in ConfigLoader symlink detection; projection-cli tests pass (130).","status":"tombstone","priority":3,"issue_type":"task","created_at":"2025-12-23T10:45:26Z","updated_at":"2026-01-07T04:57:43Z","work_type":"mutex"}
{"id":"xenon-host-hb7","title":"Web interface","description":"Web UI for awakening wizard - final step after CLI is working","status":"tombstone","priority":3,"issue_type":"task","created_at":"2025-12-20T11:21:27Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-hb7","depends_on_id":"xenon-host-7nv","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-hb7","depends_on_id":"xenon-host-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-hcj","title":"Implement validator","description":"Validate workspace structure, configs, prompt files for studio.","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-25T04:55:32Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-hcj","depends_on_id":"xenon-host-2td","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-hcj","depends_on_id":"xenon-host-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-hpi","title":"Write eval cases","description":"Create CSV test cases and judges for each routine. Basic coverage for happy paths and edge cases.","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-28T07:32:57Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-hpi","depends_on_id":"xenon-host-10g","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-hpi","depends_on_id":"xenon-host-9gd","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-hpi","depends_on_id":"xenon-host-e3q","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-hpi","depends_on_id":"xenon-host-ffe","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-hpi","depends_on_id":"xenon-host-unq","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-i4v","title":"Fix dev-vps port 3000 exposure vs nftables rules","description":"containers/dev-vps/compose.yaml maps 3000:3000 ('Web UI'), but containers/dev-vps/nftables.conf default-denies and only allows tcp dport 2222.\\n\\nImpact: any projection HTTP service on 3000 won't be reachable through dev-vps, despite port mapping.\\n\\nFiles:\\n- containers/dev-vps/compose.yaml\\n- containers/dev-vps/nftables.conf\\n\\nAcceptance (choose one):\\n- Allow tcp dport 3000 in nftables.conf (or parameterize allowed ports), OR\\n- Remove 3000 port mapping and update docs to match\\n- Ensure containers/dev-vps/test.sh covers the intended behavior","notes":"Implemented firewall allow-rule for tcp/3000 in dev-vps nftables config and extended dev-vps test script to assert it. Ran containers/dev-vps/test.sh successfully.","status":"tombstone","priority":1,"issue_type":"bug","created_at":"2025-12-23T10:44:14Z","updated_at":"2026-01-07T04:57:43Z","work_type":"mutex"}
{"id":"xenon-host-kbm","title":"Create selector routine","description":"Meta-routine that picks which routine to use based on task description.","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-25T04:56:03Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-kbm","depends_on_id":"xenon-host-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-kbm","depends_on_id":"xenon-host-hcj","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-kf4","title":"Set up nucleus package structure","description":"Create directory layout, pyproject.toml, dependencies for nucleus package","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-28T07:11:25Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-kf4","depends_on_id":"xenon-host-4xr","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-kop","title":"Configuration management","description":"YAML/TOML config system for xenon preferences, credentials, LLM settings","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-20T11:21:27Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-kop","depends_on_id":"xenon-host-13a","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-kop","depends_on_id":"xenon-host-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-l64","title":"Create triage routine","description":"OBSERVE phase - quick assessment of incoming thoughts (focus/defer/dismiss).","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-25T04:56:09Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-l64","depends_on_id":"xenon-host-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-l64","depends_on_id":"xenon-host-kbm","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-lbl","title":"Security audit and hardening of xenon infrastructure","description":"Comprehensive security review of the xenon VPS infrastructure including:\n\n- SSH hardening verification (key management, fail2ban, custom ports)\n- SELinux policy review and custom policy development\n- Firewall rule audit (nftables/firewalld)\n- Container security (rootless podman, capabilities, seccomp profiles)\n- Intrusion detection tooling (unauthorized SSH keys, login anomalies, unexpected processes)\n- File integrity monitoring\n- Network segmentation between nucleus/cortex/projection layers\n- Secrets management (API keys, SSH keys)\n- Audit logging and log shipping\n- Penetration testing of exposed projection surfaces\n- Supply chain security (base images, dependencies)\n\nThis should be done after initial chat projection implementation to harden the production infrastructure.","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-22T10:09:22Z","updated_at":"2026-01-07T04:57:43Z","work_type":"mutex"}
{"id":"xenon-host-m9o","title":"Fix model naming inconsistency (gemini vs google/gemini)","description":"OODA configs use provider: gemini but evaluator.py:217 and cli.py scaffolding use google/gemini-... format. Should be consistent.","status":"tombstone","priority":3,"issue_type":"bug","created_at":"2026-01-01T19:31:02Z","updated_at":"2026-01-07T04:57:43Z","work_type":"mutex"}
{"id":"xenon-host-mzh","title":"Create decide routine","description":"DECIDE phase - choose what action to take based on thought and context.","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-25T04:56:19Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-mzh","depends_on_id":"xenon-host-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-mzh","depends_on_id":"xenon-host-kbm","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-nbn","title":"Add nucleus daemon and tick lifecycle CLI","description":"Refactor CLI to separate tick lifecycle from continuous processing:\n\n- `nucleus tick open/close/status/run` for manual tick control\n- `nucleus start/stop/status` for daemon mode\n- NucleusDaemon class for background processing\n- TickRunner methods: open_tick(), process_dispatch(), close_tick()\n\nSee updated proposal: openspec/changes/cognitive-loop-v1/proposal.md (CLI Architecture section)","status":"tombstone","priority":1,"issue_type":"feature","created_at":"2025-12-28T08:15:45Z","updated_at":"2026-01-07T04:57:43Z","work_type":"mutex"}
{"id":"xenon-host-obd","title":"Fix vps-control README to match actual Target API (upload/download)","description":"packages/vps-control/README.md uses API that doesn't exist in the PR implementation:\\n- shows Target.connect(...) in async with, but Target.connect is a @classmethod returning Target; async context manager uses  or  depending on design\\n- refers to scp_to/scp_from methods, but implementation exposes upload()/download()\\n\\nImpact: users copy/paste docs and hit runtime errors.\\n\\nFiles:\\n- packages/vps-control/README.md\\n- packages/vps-control/src/vps_control/target.py\\n\\nAcceptance:\\n- Update README examples to correct async usage + correct method names\\n- Ensure README matches exported symbols in packages/vps-control/src/vps_control/__init__.py","notes":"Updated vps-control README to demonstrate correct async context manager usage (async with Target(...)) and correct upload/download method names. vps-control tests pass (147 passed, 25 skipped).","status":"tombstone","priority":2,"issue_type":"bug","created_at":"2025-12-23T10:43:26Z","updated_at":"2026-01-07T04:57:43Z","work_type":"mutex"}
{"id":"xenon-host-oqj","title":"Harden BlueprintLoader path traversal checks","description":"packages/vps-control/src/vps_control/blueprints/loader.py uses string prefix checks on resolved paths to prevent path traversal:\\n- if not str(blueprint_dir).startswith(str(self.blueprints_dir))\\n\\nString prefix checks can be bypassed on edge cases (e.g., /a/b and /a/bad) and are generally fragile.\\n\\nFile:\\n- packages/vps-control/src/vps_control/blueprints/loader.py\\n\\nAcceptance:\\n- Replace startswith guard with a robust path containment check (Path.is_relative_to on 3.9+ or equivalent)\\n- Add unit tests for traversal attempts (e.g., name='..', '../x', absolute paths, prefix collisions)","notes":"Replaced fragile string startswith path containment checks with Path.relative_to() in BlueprintLoader load/validate; added prefix-collision traversal tests; vps-control tests pass (145 passed, 25 skipped).","status":"tombstone","priority":2,"issue_type":"bug","created_at":"2025-12-23T10:44:33Z","updated_at":"2026-01-07T04:57:43Z","work_type":"mutex"}
{"id":"xenon-host-osq","title":"Scaffold xenon-evolution-sim","description":"Python project setup for xenon evolution simulation component","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-22T01:47:34Z","updated_at":"2026-01-07T04:57:43Z","work_type":"mutex"}
{"id":"xenon-host-pp8","title":"Projection system stub","description":"Base framework for xenon to interact with external services (MCP servers, APIs)","status":"tombstone","priority":3,"issue_type":"task","created_at":"2025-12-20T11:21:27Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-pp8","depends_on_id":"xenon-host-qaq","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-pp8","depends_on_id":"xenon-host-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-pw4","title":"Key generation for xenon instances","description":"Implement Ed25519 keypair generation for xenon identity:\n\n- nucleus: ensure_identity() function \n- xenon-cli: random ID generation and xenon-{id} directory creation\n- File permissions (0600)\n- Public key base64 encoding\n\nMust include unit tests for all new code.","design":"## Approach\n\nBased on Codex review, implementing Ed25519 keypair generation with these design decisions:\n\n### Key Design Decisions\n1. **Key Format**: Raw 32-byte public key base64 (xenon identity, not SSH)\n2. **Serialization**: PKCS8 PEM for private key storage\n3. **Return Type**: Dataclass with .to_dict() for CLI printing\n4. **Dependency**: xenon-cli depends on nucleus as Python library\n\n### Implementation Details\n\n#### nucleus/src/nucleus/identity.py\n- `ensure_identity(identity_dir: Path) -\u003e IdentityInfo`\n- Private key is source of truth, always derive public key from it\n- Atomic writes: temp file → chmod → write → fsync → os.replace\n- Directory permissions: 0700 on identity_dir\n- Private key: 0600 permissions\n- Public key file: regenerated from private key if missing/out of date\n\n#### xenon-cli modifications\n- Generate random ID with collision handling loop\n- Directory structure: {path}/xenon-{id}/data\n- Enforce 0700 on xenon-{id}/data directory\n\n#### Test Coverage\n- Monkeypatch token_hex for deterministic collision testing\n- Skip permission tests on Windows\n- Test atomic write behavior\n- Test directory permission enforcement","notes":"## Implementation Summary\n\nSuccessfully implemented Ed25519 keypair generation following Codex-approved design:\n\n### Nucleus (identity.py)\n- IdentityInfo dataclass with to_dict() method\n- ensure_identity() function with atomic writes\n- Private key: PKCS8 PEM format, 0600 permissions\n- Public key: raw 32-byte base64, regenerated from private key\n- Directory permissions: 0700 on identity_dir\n- Atomic writes using temp files + os.replace\n\n### Xenon-CLI (main.py)\n- Random ID generation with collision handling (secrets.token_hex(4))\n- xenon-{id}/data directory structure\n- Integration with ensure_identity()\n- Displays xenon ID and public key to user\n\n### Tests\n- nucleus: 10 tests (all passing)\n  - Key creation, permissions, loading, regeneration\n  - Atomic write verification\n  - Platform-specific permission tests (skip Windows)\n- xenon-cli: 11 tests (all passing)\n  - ID generation and collision handling\n  - Directory structure creation\n  - Identity integration\n  - Output display verification\n\nAll tests pass successfully.","status":"tombstone","priority":1,"issue_type":"task","assignee":"xenon/polecats/nux","created_at":"2026-01-04T08:31:49Z","updated_at":"2026-01-07T04:57:43Z","work_type":"mutex"}
{"id":"xenon-host-qaq","title":"Soul server core","description":"Python service for persistent xenon identity - memory storage, context management, state persistence","notes":"Implemented soul-server component with 11 files: pyproject.toml, src/soul_server/__init__.py, src/soul_server/main.py, src/soul_server/py.typed, tests/__init__.py, tests/test_main.py, .python-version, .gitignore, Containerfile, CLAUDE.md, README.md. Tests: 1 passing. Main function verified working.","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-20T11:21:26Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-qaq","depends_on_id":"xenon-host-13a","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-qaq","depends_on_id":"xenon-host-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-quc","title":"Create act routine","description":"ACT phase - execute the chosen action and emit instructions.","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-25T04:56:24Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-quc","depends_on_id":"xenon-host-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-quc","depends_on_id":"xenon-host-kbm","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-r1i","title":"Rename repo from xenon-host to xenon","description":"Rename the repository and update all references from xenon-host to xenon","notes":"Verified repo folder name and git remote are already xenon; updated remaining in-repo text references from xenon-host -\u003e xenon (CLAUDE.md, README.md, openspec proposal).","status":"tombstone","priority":2,"issue_type":"chore","created_at":"2025-12-22T11:16:19Z","updated_at":"2026-01-07T04:57:43Z","work_type":"mutex"}
{"id":"xenon-host-r9i","title":"Implement RepertoireRunner","description":"Execute routines via LiteLLM, including selector logic for auto_execute.","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-25T04:55:07Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-r9i","depends_on_id":"xenon-host-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-r9i","depends_on_id":"xenon-host-bwy","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-r9i","depends_on_id":"xenon-host-ye0","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-rzw","title":"Implement InstructionOutbox","description":"Markdown file emission to outbox/{target}/{id}.md","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-28T07:11:57Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-rzw","depends_on_id":"xenon-host-4xr","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-se5","title":"Implement NucleusDaemon class","description":"Create daemon class for background cognitive loop:\n- Manages tick lifecycle (opens, processes, closes on schedule)\n- Watches for new dispatches, processes through OODA\n- Supports graceful shutdown\n- Tracks running state, current tick, queue depth\n- Uses asyncio event loop\n\nFiles: daemon.py (new), __init__.py, test_daemon.py (new)","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-28T08:17:57Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-se5","depends_on_id":"xenon-host-nbn","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-se5","depends_on_id":"xenon-host-sqy","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-sqy","title":"Add TickRunner lifecycle methods (open/process/close)","description":"Refactor TickRunner to add three new methods that separate tick lifecycle:\n- `open_tick()` - Creates tick, stores tick number and start time in config\n- `process_dispatch(dispatch)` - Processes single dispatch through OODA\n- `close_tick(tick_number)` - Closes tick, writes journal, clears config\n\nFiles: tick.py, test_tick.py","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-28T08:17:46Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-sqy","depends_on_id":"xenon-host-nbn","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-tw0","title":"Write nucleus unit tests","description":"Tests for DispatchStore, StrandStore, OODAProcessor (mocked runner), InstructionOutbox","status":"tombstone","priority":3,"issue_type":"task","created_at":"2025-12-28T07:12:18Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-tw0","depends_on_id":"xenon-host-1xm","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-tw0","depends_on_id":"xenon-host-4xr","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-tw0","depends_on_id":"xenon-host-xxs","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-unq","title":"Implement observe routine","description":"Gatekeeper routine - triages incoming dispatches, creates strands. Input: new_dispatch, all_dispatches, all_strands, tick. Output: dispatch_updates, new_strands.","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-28T07:32:57Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-unq","depends_on_id":"xenon-host-10g","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-unq","depends_on_id":"xenon-host-bi5","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-v2o","title":"VPN management for nucleus/cortex privacy","description":"VPN infrastructure to obscure the communication chain between xenon layers:\n\n**Goals:**\n- Hide nucleus location from cortex (cortex only knows VPN endpoint)\n- Hide cortex location from projections\n- Prevent traffic analysis revealing the control hierarchy\n- Enable geographic misdirection if needed\n\n**Options to evaluate:**\n- WireGuard (lightweight, modern)\n- Tailscale/Headscale (managed WireGuard)\n- Self-hosted VPN servers as intermediaries\n- Tor hidden services (for maximum anonymity)\n\n**Features:**\n- Automated VPN setup during VPS provisioning\n- Key rotation\n- Multi-hop routing for sensitive deployments\n- Fallback paths if VPN fails\n- Integration with vps-control SSH tunneling\n\n**Threat model:**\n- Protect against VPS provider logging\n- Protect against network-level surveillance\n- Maintain operational security for sovereign xenons","status":"tombstone","priority":2,"issue_type":"feature","created_at":"2025-12-22T10:12:50Z","updated_at":"2026-01-07T04:57:43Z","work_type":"mutex"}
{"id":"xenon-host-v5o","title":"Implement database layer","description":"Schema, migrations, connection management for nucleus.db","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-28T07:11:30Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-v5o","depends_on_id":"xenon-host-4xr","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-v5o","depends_on_id":"xenon-host-kf4","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-w08","title":"Create orient routine","description":"ORIENT phase - enrich thought with context and relevance scores.","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-25T04:56:14Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-w08","depends_on_id":"xenon-host-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-w08","depends_on_id":"xenon-host-kbm","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-xrh","title":"Signing dispatches: time vs tick semantics","description":"When signing dispatches, decide whether the signature should bind (a) wall-clock time (timestamp), (b) monotonic tick/sequence from nucleus/cortex, or (c) both.\n\nQuestions:\n- What field(s) are included in the signed payload?\n- Which clock is authoritative (nucleus? cortex? projection?)\n- How do we prevent replay across restarts / forks?\n- Ordering: do consumers rely on tick ordering vs timestamp?\n- What does verification do when clocks drift?\n\nConsider: include tick + optional timestamp; require strictly-increasing tick per signer; define validity window if using time; document canonical serialization.","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-23T12:22:19Z","updated_at":"2026-01-07T04:57:43Z","work_type":"mutex"}
{"id":"xenon-host-xv0","title":"Add deterministic validators to eval pipeline","description":"Run structure/schema validation before LLM judges. Fail fast on invalid structure (saves API costs). Could be validators.py in evals/ or schema.json for JSON schema validation. Separate from LLM judges which handle semantic checks only.","notes":"Implemented deterministic validators using JSON Schema. Added output_validator.py with ValidationResult dataclass. Evaluator now validates routine output before LLM judges run - validation failures skip judges entirely (saving API costs). Added schema examples to observe and decide routines. All 90 tests passing. Commit: ef14f30","status":"tombstone","priority":2,"issue_type":"feature","created_at":"2026-01-01T19:42:38Z","updated_at":"2026-01-07T04:57:43Z","work_type":"mutex"}
{"id":"xenon-host-xxs","title":"Implement StrandStore","description":"SQLite-backed strand storage (add, get_all, update)","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-28T07:11:46Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-xxs","depends_on_id":"xenon-host-4xr","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-xxs","depends_on_id":"xenon-host-exe","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-xxs","depends_on_id":"xenon-host-v5o","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-y31","title":"Implement packer","description":"Create .rpt archive from workspace (validate, exclude evals/).","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-25T04:55:38Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-y31","depends_on_id":"xenon-host-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-y31","depends_on_id":"xenon-host-hcj","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-y8a","title":"Podman setup","description":"Containerfile, podman-compose for running soul server in container","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-20T11:21:27Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-y8a","depends_on_id":"xenon-host-qaq","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-y8a","depends_on_id":"xenon-host-zjt","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-ye0","title":"Implement LiteLLMClient","description":"Async wrapper around litellm for completion requests with model config support.","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-25T04:55:01Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-ye0","depends_on_id":"xenon-host-ajv","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-ye0","depends_on_id":"xenon-host-b1i","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-ykx","title":"Add eval fixtures support","description":"Implement @file: syntax for referencing external fixture files from CSV cells in cases.csv and judges.csv. This allows complex JSON/YAML test data to be stored in separate files instead of escaped within CSV cells.","notes":"Implemented resolve_cell_value() helper in evaluator.py. Modified load_eval_cases() and load_judges() to support @file: syntax. Added 19 tests (all passing). Total 90 tests pass.","status":"tombstone","priority":1,"issue_type":"feature","created_at":"2025-12-28T23:03:29Z","updated_at":"2026-01-07T04:57:43Z","work_type":"mutex"}
{"id":"xenon-host-z17","title":"Nucleus cloning and disaster recovery","description":"Ability to clone and recover a nucleus in case of server compromise or failure:\n\n**Core requirements:**\n- Full nucleus state backup (encrypted)\n- Sovereign key backup/recovery (highest security)\n- Ability to spin up nucleus on new VPS from backup\n- Automatic failover if primary nucleus becomes unreachable\n\n**What needs to be backed up:**\n- Sovereign key (encrypted, possibly split/shamir)\n- Genome, imprints, impulse state\n- Narratives and memories\n- Objectives (tasks, projects, goals, dreams)\n- Relationship data\n- Configuration\n\n**Recovery scenarios:**\n1. VPS compromised - spin up new nucleus elsewhere, revoke old\n2. VPS provider issue - migrate to different provider\n3. Chaperone device lost - recover from secure backup\n4. Planned migration - seamless handoff to new infrastructure\n\n**Security considerations:**\n- Backup encryption (chaperone-held key)\n- Backup location separate from nucleus VPS\n- Integrity verification before restore\n- Audit trail of all backup/restore operations\n- Consider hardware security modules for sovereign key","status":"tombstone","priority":2,"issue_type":"feature","created_at":"2025-12-22T10:12:50Z","updated_at":"2026-01-07T04:57:43Z","work_type":"mutex"}
{"id":"xenon-host-z5e","title":"Chat Projection Implementation","description":"Implement the chat-projection spec: dev environment, vps-control library, projection CLI, blueprints, base image, and chat projection. See openspec/changes/chat-projection/proposal.md","status":"tombstone","priority":1,"issue_type":"epic","created_at":"2025-12-22T11:29:47Z","updated_at":"2026-01-07T04:57:43Z","work_type":"mutex"}
{"id":"xenon-host-z5e.1","title":"Create dev-vps base Containerfile","description":"Rocky Linux 9 + SSH + Podman + fuse-overlayfs","notes":"Implemented containers/dev-vps/Containerfile. Tests pass: build, SSH key auth, podman info, nested alpine container. Minor cgroup warning (non-blocking).","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-22T11:33:33Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-z5e.1","depends_on_id":"xenon-host-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-z5e.10","title":"Create cloud-init template with kernel hardening","description":"sysctls, SSH config, firewall","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-22T11:33:36Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-z5e.10","depends_on_id":"xenon-host-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-z5e.10","depends_on_id":"xenon-host-z5e.5","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-z5e.11","title":"Define blueprint schema and types","description":"TypeScript types, JSON schema","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-22T11:33:51Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-z5e.11","depends_on_id":"xenon-host-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-z5e.11","depends_on_id":"xenon-host-z5e.5","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-z5e.12","title":"Implement blueprint loader","description":"load/validate blueprint.yaml","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-22T11:33:51Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-z5e.12","depends_on_id":"xenon-host-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-z5e.12","depends_on_id":"xenon-host-z5e.11","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-z5e.13","title":"Implement compose file generator","description":"blueprint template + config → compose","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-22T11:33:52Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-z5e.13","depends_on_id":"xenon-host-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-z5e.13","depends_on_id":"xenon-host-z5e.12","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-z5e.14","title":"Create chat blueprint definition","description":"blueprint.yaml, compose.template, config.schema.json","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-22T11:33:52Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-z5e.14","depends_on_id":"xenon-host-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-z5e.14","depends_on_id":"xenon-host-z5e.13","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-z5e.15","title":"Scaffold projection-cli package structure","description":"Python/Click, pyproject.toml","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-22T11:33:52Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-z5e.15","depends_on_id":"xenon-host-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-z5e.16","title":"Implement config loader","description":"projection.yaml, prompts.yaml, tools.yaml","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-22T11:33:53Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-z5e.16","depends_on_id":"xenon-host-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-z5e.16","depends_on_id":"xenon-host-z5e.15","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-z5e.17","title":"Implement LLM client abstraction","description":"provider-agnostic with Anthropic impl","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-22T11:33:53Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-z5e.17","depends_on_id":"xenon-host-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-z5e.17","depends_on_id":"xenon-host-z5e.16","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-z5e.18","title":"Implement projection health command","description":"status, uptime, config validation","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-22T11:33:53Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-z5e.18","depends_on_id":"xenon-host-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-z5e.18","depends_on_id":"xenon-host-z5e.16","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-z5e.19","title":"Implement projection dispatch command","description":"Generate LLM-written summary, sign with Ed25519 key, write to /var/xenon/dispatches/*.json","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-22T11:33:53Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-z5e.19","depends_on_id":"xenon-host-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-z5e.19","depends_on_id":"xenon-host-z5e.17","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-z5e.19","depends_on_id":"xenon-host-z5e.27","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-z5e.2","title":"Add SSH and firewall hardening to dev-vps","description":"key-only auth, custom port, nftables","notes":"Added nftables.conf with default-deny policy. Updated Containerfile: SSH on port 2222, nftables loaded at startup. Tests pass.","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-22T11:33:34Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-z5e.2","depends_on_id":"xenon-host-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-z5e.2","depends_on_id":"xenon-host-z5e.1","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-z5e.20","title":"Implement projection instruction command","description":"process cortex JSON instructions","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-22T11:33:54Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-z5e.20","depends_on_id":"xenon-host-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-z5e.20","depends_on_id":"xenon-host-z5e.17","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-z5e.21","title":"Implement projection run command","description":"main loop with APScheduler","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-22T11:34:04Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-z5e.21","depends_on_id":"xenon-host-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-z5e.21","depends_on_id":"xenon-host-z5e.18","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-z5e.21","depends_on_id":"xenon-host-z5e.19","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-z5e.21","depends_on_id":"xenon-host-z5e.20","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-z5e.22","title":"Create projection-base Containerfile","description":"Rocky Linux 9, SSH, projection CLI, systemd","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-22T11:34:04Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-z5e.22","depends_on_id":"xenon-host-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-z5e.22","depends_on_id":"xenon-host-z5e.21","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-z5e.22","depends_on_id":"xenon-host-z5e.4","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-z5e.23","title":"Create simple Express hello world server","description":"Simple Express server returning hello world (placeholder for future chat UI)","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-22T11:34:05Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-z5e.23","depends_on_id":"xenon-host-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-z5e.23","depends_on_id":"xenon-host-z5e.22","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-z5e.24","title":"Implement chat event logging for dispatch","description":"metrics buffer for dispatch","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-22T11:34:05Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-z5e.24","depends_on_id":"xenon-host-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-z5e.24","depends_on_id":"xenon-host-z5e.23","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-z5e.25","title":"Create chat projection Containerfile and entrypoint","description":"extends base, Node.js, entrypoint.sh","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-22T11:34:05Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-z5e.25","depends_on_id":"xenon-host-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-z5e.25","depends_on_id":"xenon-host-z5e.22","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-z5e.25","depends_on_id":"xenon-host-z5e.24","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-z5e.26","title":"Create end-to-end integration test","description":"vps-control → deploy → instruction → dispatch","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-22T11:34:06Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-z5e.26","depends_on_id":"xenon-host-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-z5e.26","depends_on_id":"xenon-host-z5e.14","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-z5e.26","depends_on_id":"xenon-host-z5e.25","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-z5e.26","depends_on_id":"xenon-host-z5e.28","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-z5e.26","depends_on_id":"xenon-host-z5e.8","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-z5e.27","title":"Implement Ed25519 signing utilities","description":"Crypto utilities for signing dispatches with Ed25519 keys. Load key from secrets.json, sign content, output base64 signature.","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-22T21:00:58Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-z5e.27","depends_on_id":"xenon-host-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-z5e.28","title":"Implement keypair generation for projection instantiation","description":"Generate Ed25519 keypair when cortex creates projection. Deploy private key in secrets.json, register public key with nucleus.","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-22T21:01:11Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-z5e.28","depends_on_id":"xenon-host-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-z5e.28","depends_on_id":"xenon-host-z5e.13","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-z5e.3","title":"Create dev-vps compose file with port forwarding","description":"SSH 2222, web 3000","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-22T11:33:34Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-z5e.3","depends_on_id":"xenon-host-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-z5e.3","depends_on_id":"xenon-host-z5e.2","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-z5e.4","title":"Test and document dev-vps SSH and nested Podman","description":"integration test script","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-22T11:33:34Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-z5e.4","depends_on_id":"xenon-host-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-z5e.4","depends_on_id":"xenon-host-z5e.3","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-z5e.5","title":"Scaffold vps-control package structure","description":"TypeScript, src directories","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-22T11:33:35Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-z5e.5","depends_on_id":"xenon-host-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-z5e.6","title":"Implement SSH connection manager","description":"Target class with connect/exec/close","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-22T11:33:35Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-z5e.6","depends_on_id":"xenon-host-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-z5e.6","depends_on_id":"xenon-host-z5e.5","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-z5e.7","title":"Implement SCP file transfer","description":"scpTo/scpFrom methods","notes":"Implementation completed successfully.\n\n**Changes made:**\n\n1. **File: /Users/jv/workspace/xenota/xenon-host/packages/vps-control/src/vps_control/target.py**\n   - Added asyncio import\n   - Replaced scp_to() stub with upload() method\n   - Replaced scp_from() stub with download() method\n   - Both methods use asyncio.to_thread() to wrap blocking paramiko SFTP calls\n   - Connection validation using self._client.get_transport().is_active()\n   - Proper try/finally blocks ensure sftp.close() is always called\n   - Upload checks local file exists before attempting transfer\n   - Download maps IOError to FileNotFoundError for missing remote files\n   - Added comprehensive docstrings noting \"Implemented via SFTP protocol\"\n\n2. **File: /Users/jv/workspace/xenota/xenon-host/packages/vps-control/tests/test_target.py**\n   - Added imports: tempfile, Path, MagicMock, patch\n   - Added 5 unit tests:\n     - test_upload_missing_local_file - Verifies FileNotFoundError when local file missing\n     - test_download_not_connected - Verifies RuntimeError when not connected\n     - test_upload_not_connected - Verifies RuntimeError when not connected\n     - test_upload_sftp_closes - Verifies SFTP client closure with mocks\n     - test_download_sftp_closes - Verifies SFTP client closure with mocks\n   - Added 3 integration tests (require DEV_VPS=1):\n     - test_upload_and_verify - Upload file and verify with exec(\"cat ...\")\n     - test_download_and_verify - Download file and verify content matches\n     - test_upload_download_roundtrip - Round-trip upload then download\n\n**Test results:**\n- All 7 unit tests PASS\n- 6 integration tests SKIPPED (DEV_VPS not set, expected)\n- No test failures\n\n**Code quality:**\n- Clean, readable implementation\n- Follows existing codebase patterns\n- Proper error handling with meaningful messages\n- SFTP resources properly cleaned up in finally blocks\n- Async operations properly wrapped with asyncio.to_thread()\n- Comprehensive test coverage for all error cases and happy paths\n\nReady for integration testing when DEV_VPS is available.","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-22T11:33:35Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-z5e.7","depends_on_id":"xenon-host-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-z5e.7","depends_on_id":"xenon-host-z5e.6","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-z5e.8","title":"Implement Podman container control via SSH","description":"start/stop/exec/logs","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-22T11:33:35Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-z5e.8","depends_on_id":"xenon-host-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-z5e.8","depends_on_id":"xenon-host-z5e.6","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-z5e.9","title":"Implement security audit tools","description":"checkAuthorizedKeys, checkLoginHistory, etc.","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-22T11:33:36Z","updated_at":"2026-01-07T04:57:43Z","dependencies":[{"issue_id":"xenon-host-z5e.9","depends_on_id":"xenon-host-z5e","type":"parent-child","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"},{"issue_id":"xenon-host-z5e.9","depends_on_id":"xenon-host-z5e.6","type":"blocks","created_at":"2026-02-15T23:04:57Z","created_by":"import","metadata":"{}"}],"work_type":"mutex"}
{"id":"xenon-host-zjt","title":"MVP Awakening Flow","description":"First working prototype - human runs xenon-host locally, goes through CLI awakening, ends with functioning xenon that can converse via LiteLLM.","status":"tombstone","priority":1,"issue_type":"epic","created_at":"2025-12-20T11:21:15Z","updated_at":"2026-01-07T04:57:43Z","work_type":"mutex"}
{"id":"xenon-host-zth","title":"Make scripts/check.sh install/select dev deps before running black/flake8/pytest","description":"scripts/check.sh runs: uv run black --check ., uv run flake8, uv run pytest.\\n\\nIn a fresh checkout, pytest/flake8/black may not exist unless the package dev dependency group is selected/synced. This makes the repo-wide check script flaky/unreliable.\\n\\nFile:\\n- scripts/check.sh\\n\\nAcceptance:\\n- Ensure check script works from a clean clone with a single command (either uv sync --dev per package, or uv run --group dev ..., or explicit tool installs)\\n- Decide whether integration mode should also ensure podman-compose prerequisites","notes":"Updated scripts/check.sh to uv sync --group dev --reinstall and run tools with --group dev; fixed formatting issues uncovered; verified scripts/check.sh passes across all packages.","status":"tombstone","priority":2,"issue_type":"bug","created_at":"2025-12-23T10:43:56Z","updated_at":"2026-01-07T04:57:43Z","work_type":"mutex"}
{"id":"xenota-d76","title":"Add Phosphor Icons to brand design guidelines","description":"Update handbook/docs/branding/brand-guidelines.md to include Phosphor Icons as the official icon library. Add: icon inventory (mission icons, UI icons), usage guidelines, and UnoCSS class names. Icons: ph-dna (Life), ph-rocket-launch (Starshot), ph-globe-hemisphere-west (Earthshot), ph-scales (Prosperity), ph-handshake (Partnership), ph-shield-check (Sovereignty), ph-arrows-clockwise (Flywheel), ph-users-three (Community), ph-lightning (Action).","status":"tombstone","priority":2,"issue_type":"task","created_at":"2026-02-07T22:10:00Z","updated_at":"2026-02-09T11:38:46Z","labels":["brand","documentation"],"work_type":"mutex"}
{"id":"xm-xenota-mono-crew-manifesto","title":"Crew worker manifesto in xenota-mono - human-managed persistent workspace.","description":"Crew worker manifesto in xenota-mono.\n\nrole_type: crew\nrig: xenota-mono","status":"tombstone","priority":2,"issue_type":"agent","created_at":"2026-02-07T08:34:08Z","updated_at":"2026-02-07T08:38:08Z","labels":["gt:agent","rig:xenota-mono","role_type:crew"],"work_type":"mutex"}
{"id":"xm-xenota-mono-crew-nucleus","title":"Crew worker nucleus in xenota-mono - human-managed persistent workspace.","description":"Crew worker nucleus in xenota-mono.\n\nrole_type: crew\nrig: xenota-mono","status":"tombstone","priority":2,"issue_type":"agent","created_at":"2026-02-07T08:34:08Z","updated_at":"2026-02-07T08:38:08Z","labels":["gt:agent","rig:xenota-mono","role_type:crew"],"work_type":"mutex"}
{"id":"xm-xenota-mono-crew-protocol","title":"Crew worker protocol in xenota-mono - human-managed persistent workspace.","description":"Crew worker protocol in xenota-mono.\n\nrole_type: crew\nrig: xenota-mono","status":"tombstone","priority":2,"issue_type":"agent","created_at":"2026-02-07T08:34:09Z","updated_at":"2026-02-07T08:38:08Z","labels":["gt:agent","rig:xenota-mono","role_type:crew"],"work_type":"mutex"}
